{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Label Text classification problem with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a model with Multiple-Outputs and Multiple-Losses in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sqlalchemy import create_engine\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation, Input\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data from database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of real messages that are classified into 36 different classes.\n",
    "The problem conists of a multi-label classfication problem, where one message can be \n",
    "classified into more than 1 class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///data/DisasterResponse.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_table('messages', engine) # Table Message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output Columns Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_columns_all = ['related', 'request', 'offer', 'aid_related',\n",
    "       'medical_help', 'medical_products', 'search_and_rescue', 'security',\n",
    "       'military', 'child_alone', 'water', 'food', 'shelter', 'clothing',\n",
    "       'money', 'missing_people', 'refugees', 'death', 'other_aid',\n",
    "       'infrastructure_related', 'transport', 'buildings', 'electricity',\n",
    "       'tools', 'hospitals', 'shops', 'aid_centers', 'other_infrastructure',\n",
    "       'weather_related', 'floods', 'storm', 'fire', 'earthquake', 'cold',\n",
    "       'other_weather', 'direct_report']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can observe from the graphs below, the dataset is highly imbalanced. Some classes are more balanced than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 36 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[output_columns_all].hist(figsize=(20,20));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Weather update - a cold front from Cuba that could pass over Haiti',\n",
       " 'Is the Hurricane over or is it not over',\n",
       " 'Looking for someone but no name',\n",
       " 'UN reports Leogane 80-90 destroyed. Only Hospital St. Croix functioning. Needs supplies desperately.',\n",
       " 'says: west side of Haiti, rest of the country today and tonight']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df['message'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    \n",
    "    # '@' mention. Even tough @ adds some information to the message, \n",
    "    # this information doesn't add value build the classifcation model\n",
    "    text = re.sub(r'@[A-Za-z0-9_]+','', text)\n",
    "    \n",
    "    # Dealing with URL links\n",
    "    url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    text = re.sub(url_regex,'urlplaceholder', text)\n",
    "    # A lot of url are write as follows: http bit.ly. Apply Regex for these cases\n",
    "    utl_regex_2 = 'http [a-zA-Z]+\\.[a-zA-Z]+'\n",
    "    text = re.sub(utl_regex_2,'urlplaceholder', text)\n",
    "    # Other formats: http : //t.co/ihW64e8Z\n",
    "    utl_regex_3 = 'http \\: //[a-zA-Z]\\.(co|com|pt|ly)/[A-Za-z0-9_]+'\n",
    "    text = re.sub(utl_regex_3,'urlplaceholder', text)\n",
    "    \n",
    "    # Hashtags can provide useful informations. Removing only ``#``\n",
    "    text = re.sub('#',' ', text)\n",
    "    \n",
    "    # Contractions\n",
    "    text = re.sub(r\"what's\", 'what is ', text)\n",
    "    text = re.sub(r\"can't\", 'cannot', text)\n",
    "    text = re.sub(r\"\\'s\",' ', text)\n",
    "    text = re.sub(r\"\\'ve\", ' have ', text)\n",
    "    text = re.sub(r\"n't\", ' not ', text)\n",
    "    text = re.sub(r\"im\", 'i am ', text)\n",
    "    text = re.sub(r\"i'm\", 'i am ', text)\n",
    "    text = re.sub(r\"\\'re\", ' are ', text)\n",
    "    text = re.sub(r\"\\'d\", ' would ', text)\n",
    "    text = re.sub(r\"\\'ll\", ' will ', text)\n",
    "                  \n",
    "    # Operations and special words           \n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub('foof', 'food', text)\n",
    "    text = re.sub('msg', 'message', text)\n",
    "    text = re.sub(' u ', 'you', text)\n",
    "    \n",
    "    # Ponctuation Removal\n",
    "    text = re.sub(r'[^a-zA-Z0-9]', ' ', text)\n",
    "    \n",
    "    text = text.split()\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    text = [tok for tok in text if tok not in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = [lemmatizer.lemmatize(w) for w in text]\n",
    "    return ' '.join(text)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize and Create Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Text\n",
    "df['message'] = df['message'].map(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chossing size of vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(df['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(df['message'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pads sequences to the same length: MAXLEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXLEN = 50\n",
    "X = pad_sequences(sequences, maxlen=MAXLEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[output_columns_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority of the classes are binary, but one of them has 3 different classes. Because of that, \n",
    "the model will be divided into two different types of outputs:\n",
    "    - binary \n",
    "    - sparse category: The output has integer targets, and differently from catergorical crossentropy,\n",
    "    the target doens't need to be one-hot encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the dataset is highly imblanced, I applied a class weight in order to try to balance the model prediction.\n",
    "Keras contains the class_weight paramater, but as related into this [issue](https://github.com/keras-team/keras/issues/8011) on Keras, I came into the same bug. When you apply the class_weight paramter for a Multi Label Classification problem, keras throws the following error: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "560         if sample_weight_mode is None:\n",
    "\n",
    "ValueError: `class_weight` must contain all classes in the data. The classes {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 30, 31, 32, 33, 34, 35, 36} exist in the data but not in `class_weight`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The solution that I came up with was to create multiple outputs, one for every binary class, and another \n",
    "for the sparse category class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_columns_binary = ['request', 'offer', 'aid_related',\n",
    "       'medical_help', 'medical_products', 'search_and_rescue', 'security',\n",
    "       'military', 'child_alone', 'water', 'food', 'shelter', 'clothing',\n",
    "       'money', 'missing_people', 'refugees', 'death', 'other_aid',\n",
    "       'infrastructure_related', 'transport', 'buildings', 'electricity',\n",
    "       'tools', 'hospitals', 'shops', 'aid_centers', 'other_infrastructure',\n",
    "       'weather_related', 'floods', 'storm', 'fire', 'earthquake', 'cold',\n",
    "       'other_weather', 'direct_report']\n",
    "output_columns_categorical = ['related']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For building this model will the Keras functional API and not the common used Sequential() model. This comes from the fact that with his API it's possible to build more complex models, such as multi-output and multi-inputs problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_input = Input(shape=(MAXLEN,), dtype='int32', name='main_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Embedding(vocabulary_size, 50, input_length=MAXLEN)(main_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dropout(0.3)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Conv1D(64, 5, activation='relu')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = MaxPooling1D(pool_size=4)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = LSTM(100)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dropout(0.3)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Dense layer will be create for each of ouput. The corresponding metrics and losses for each output will also be stored into dictionaries.\n",
    "\n",
    "For the binary classes the metric used will be the `binary_accuracy` with the corresponding `binary_crossentropy`. \n",
    "Since there is only two possible class for each output (0 or 1), the `sigmoid` function will be used as the activation function.\n",
    "\n",
    "For the categorical classes the metric used will be the `sparse_categorical_accuracy` with the corresponding `sparse_categorical_crossentropy`. For this output there are 3 possibles outputs: 0, 1 and 2, this way the `softmax` activation function will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_array = []\n",
    "metrics_array = {}\n",
    "loss_array = {}\n",
    "for i, dense_layer in enumerate(output_columns_binary):\n",
    "    name = f'binary_output_{i}'\n",
    "    binary_output = Dense(1, activation='sigmoid', name=name)(x)\n",
    "    output_array.append(binary_output)\n",
    "    metrics_array[name] = 'binary_accuracy'\n",
    "    loss_array[name] = 'binary_crossentropy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code iterates through each of the output binary columns and creates a dense layer, saving \n",
    "the corresponding  metric and loss into a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below applys the same result to the multi class output column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_output = Dense(3, activation='softmax', name='categorical_output')(x)\n",
    "output_array.append(categorical_output)\n",
    "metrics_array['categorical_output'] = 'sparse_categorical_accuracy'\n",
    "loss_array['categorical_output'] = 'sparse_categorical_crossentropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Model(main_input, outputs=[binary_output, categorical_ouput])\n",
    "model = Model(inputs=main_input, outputs=output_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adadelta',\n",
    "              loss=loss_array,\n",
    "              metrics = metrics_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_output = []\n",
    "for col in output_columns_binary:\n",
    "    y_train_output.append(y_train[col])\n",
    "\n",
    "for col in output_columns_categorical:\n",
    "    y_train_output.append(y_train[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_binary = {0: 0.5, 1: 7}\n",
    "weight_categorical = {0: 1.4, 1: 0.43, 2: 7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_weights = {}\n",
    "for i, dense_layer in enumerate(output_columns_binary):\n",
    "    name = f'binary_output_{i}'\n",
    "    classes_weights[name] = weight_binary\n",
    "for i, dense_layer in enumerate(output_columns_categorical):\n",
    "    name = 'categorical_output'\n",
    "    classes_weights[name] = weight_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danieldacosta/.virtualenvs/cor/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "22237/22237 [==============================] - 9s 422us/step - loss: 19.4919 - binary_output_0_loss: 0.9471 - binary_output_1_loss: 0.1608 - binary_output_2_loss: 1.1547 - binary_output_3_loss: 0.7050 - binary_output_4_loss: 0.5659 - binary_output_5_loss: 0.4155 - binary_output_6_loss: 0.3368 - binary_output_7_loss: 0.4492 - binary_output_8_loss: 0.1140 - binary_output_9_loss: 0.6371 - binary_output_10_loss: 0.8204 - binary_output_11_loss: 0.7389 - binary_output_12_loss: 0.3060 - binary_output_13_loss: 0.3753 - binary_output_14_loss: 0.2518 - binary_output_15_loss: 0.4560 - binary_output_16_loss: 0.5361 - binary_output_17_loss: 0.8748 - binary_output_18_loss: 0.6494 - binary_output_19_loss: 0.5379 - binary_output_20_loss: 0.5739 - binary_output_21_loss: 0.3454 - binary_output_22_loss: 0.1957 - binary_output_23_loss: 0.2525 - binary_output_24_loss: 0.1513 - binary_output_25_loss: 0.2592 - binary_output_26_loss: 0.5322 - binary_output_27_loss: 1.0965 - binary_output_28_loss: 0.7071 - binary_output_29_loss: 0.7570 - binary_output_30_loss: 0.2501 - binary_output_31_loss: 0.7679 - binary_output_32_loss: 0.3533 - binary_output_33_loss: 0.5814 - binary_output_34_loss: 0.9869 - categorical_output_loss: 0.6474 - binary_output_0_binary_accuracy: 0.1864 - binary_output_1_binary_accuracy: 0.9698 - binary_output_2_binary_accuracy: 0.4188 - binary_output_3_binary_accuracy: 0.4721 - binary_output_4_binary_accuracy: 0.6859 - binary_output_5_binary_accuracy: 0.9451 - binary_output_6_binary_accuracy: 0.9282 - binary_output_7_binary_accuracy: 0.9095 - binary_output_8_binary_accuracy: 0.9165 - binary_output_9_binary_accuracy: 0.6076 - binary_output_10_binary_accuracy: 0.1990 - binary_output_11_binary_accuracy: 0.2642 - binary_output_12_binary_accuracy: 0.9723 - binary_output_13_binary_accuracy: 0.9223 - binary_output_14_binary_accuracy: 0.9822 - binary_output_15_binary_accuracy: 0.9344 - binary_output_16_binary_accuracy: 0.8273 - binary_output_17_binary_accuracy: 0.1795 - binary_output_18_binary_accuracy: 0.4761 - binary_output_19_binary_accuracy: 0.8448 - binary_output_20_binary_accuracy: 0.7810 - binary_output_21_binary_accuracy: 0.9759 - binary_output_22_binary_accuracy: 0.9360 - binary_output_23_binary_accuracy: 0.9539 - binary_output_24_binary_accuracy: 0.9945 - binary_output_25_binary_accuracy: 0.9379 - binary_output_26_binary_accuracy: 0.7483 - binary_output_27_binary_accuracy: 0.2977 - binary_output_28_binary_accuracy: 0.3842 - binary_output_29_binary_accuracy: 0.2192 - binary_output_30_binary_accuracy: 0.9132 - binary_output_31_binary_accuracy: 0.2361 - binary_output_32_binary_accuracy: 0.9169 - binary_output_33_binary_accuracy: 0.8438 - binary_output_34_binary_accuracy: 0.1952 - categorical_output_sparse_categorical_accuracy: 0.5664\n",
      "Epoch 2/40\n",
      "22237/22237 [==============================] - 7s 315us/step - loss: 18.1002 - binary_output_0_loss: 0.9156 - binary_output_1_loss: 0.1196 - binary_output_2_loss: 0.9712 - binary_output_3_loss: 0.6794 - binary_output_4_loss: 0.5313 - binary_output_5_loss: 0.4035 - binary_output_6_loss: 0.3158 - binary_output_7_loss: 0.4114 - binary_output_8_loss: 0.0259 - binary_output_9_loss: 0.6025 - binary_output_10_loss: 0.7980 - binary_output_11_loss: 0.7141 - binary_output_12_loss: 0.2782 - binary_output_13_loss: 0.3520 - binary_output_14_loss: 0.2347 - binary_output_15_loss: 0.4223 - binary_output_16_loss: 0.5049 - binary_output_17_loss: 0.8523 - binary_output_18_loss: 0.6051 - binary_output_19_loss: 0.5128 - binary_output_20_loss: 0.5382 - binary_output_21_loss: 0.3208 - binary_output_22_loss: 0.1529 - binary_output_23_loss: 0.2213 - binary_output_24_loss: 0.1222 - binary_output_25_loss: 0.2332 - binary_output_26_loss: 0.4920 - binary_output_27_loss: 0.9807 - binary_output_28_loss: 0.6428 - binary_output_29_loss: 0.7261 - binary_output_30_loss: 0.2180 - binary_output_31_loss: 0.7617 - binary_output_32_loss: 0.3240 - binary_output_33_loss: 0.5549 - binary_output_34_loss: 0.9393 - categorical_output_loss: 0.6087 - binary_output_0_binary_accuracy: 0.1719 - binary_output_1_binary_accuracy: 0.9957 - binary_output_2_binary_accuracy: 0.4149 - binary_output_3_binary_accuracy: 0.4735 - binary_output_4_binary_accuracy: 0.7629 - binary_output_5_binary_accuracy: 0.9616 - binary_output_6_binary_accuracy: 0.9813 - binary_output_7_binary_accuracy: 0.8802 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.6117 - binary_output_10_binary_accuracy: 0.1837 - binary_output_11_binary_accuracy: 0.3839 - binary_output_12_binary_accuracy: 0.9846 - binary_output_13_binary_accuracy: 0.9749 - binary_output_14_binary_accuracy: 0.9881 - binary_output_15_binary_accuracy: 0.8895 - binary_output_16_binary_accuracy: 0.7979 - binary_output_17_binary_accuracy: 0.1436 - binary_output_18_binary_accuracy: 0.6114 - binary_output_19_binary_accuracy: 0.8002 - binary_output_20_binary_accuracy: 0.7534 - binary_output_21_binary_accuracy: 0.9781 - binary_output_22_binary_accuracy: 0.9937 - binary_output_23_binary_accuracy: 0.9888 - binary_output_24_binary_accuracy: 0.9954 - binary_output_25_binary_accuracy: 0.9877 - binary_output_26_binary_accuracy: 0.7962 - binary_output_27_binary_accuracy: 0.2797 - binary_output_28_binary_accuracy: 0.5360 - binary_output_29_binary_accuracy: 0.3650 - binary_output_30_binary_accuracy: 0.9893 - binary_output_31_binary_accuracy: 0.1675 - binary_output_32_binary_accuracy: 0.9796 - binary_output_33_binary_accuracy: 0.7293 - binary_output_34_binary_accuracy: 0.1927 - categorical_output_sparse_categorical_accuracy: 0.6173\n",
      "Epoch 3/40\n",
      " 1024/22237 [>.............................] - ETA: 5s - loss: 18.1011 - binary_output_0_loss: 0.9206 - binary_output_1_loss: 0.1532 - binary_output_2_loss: 0.9452 - binary_output_3_loss: 0.7388 - binary_output_4_loss: 0.4977 - binary_output_5_loss: 0.4554 - binary_output_6_loss: 0.2995 - binary_output_7_loss: 0.4617 - binary_output_8_loss: 0.0250 - binary_output_9_loss: 0.5378 - binary_output_10_loss: 0.7684 - binary_output_11_loss: 0.6685 - binary_output_12_loss: 0.2785 - binary_output_13_loss: 0.3142 - binary_output_14_loss: 0.2397 - binary_output_15_loss: 0.4532 - binary_output_16_loss: 0.5375 - binary_output_17_loss: 0.8275 - binary_output_18_loss: 0.6089 - binary_output_19_loss: 0.6281 - binary_output_20_loss: 0.5177 - binary_output_21_loss: 0.2833 - binary_output_22_loss: 0.1205 - binary_output_23_loss: 0.2689 - binary_output_24_loss: 0.1405 - binary_output_25_loss: 0.2208 - binary_output_26_loss: 0.4952 - binary_output_27_loss: 0.9712 - binary_output_28_loss: 0.6647 - binary_output_29_loss: 0.6989 - binary_output_30_loss: 0.1767 - binary_output_31_loss: 0.8303 - binary_output_32_loss: 0.3007 - binary_output_33_loss: 0.5522 - binary_output_34_loss: 0.9272 - categorical_output_loss: 0.5731 - binary_output_0_binary_accuracy: 0.1816 - binary_output_1_binary_accuracy: 0.9941 - binary_output_2_binary_accuracy: 0.4131 - binary_output_3_binary_accuracy: 0.4775 - binary_output_4_binary_accuracy: 0.7686 - binary_output_5_binary_accuracy: 0.9590 - binary_output_6_binary_accuracy: 0.9844 - binary_output_7_binary_accuracy: 0.8311 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.6602 - binary_output_10_binary_accuracy: 0.1973 - binary_output_11_binary_accuracy: 0.4277 - binary_output_12_binary_accuracy: 0.9824 - binary_output_13_binary_accuracy: 0.9639 - binary_output_14_binary_accuracy: 0.9883 - binary_output_15_binary_accuracy: 0.8643 - binary_output_16_binary_accuracy: 0.6943 - binary_output_17_binary_accuracy: 0.1270 - binary_output_18_binary_accuracy: 0.6562 - binary_output_19_binary_accuracy: 0.7500 - binary_output_20_binary_accuracy: 0.7129 - binary_output_21_binary_accuracy: 0.9805 - binary_output_22_binary_accuracy: 0.9961 - binary_output_23_binary_accuracy: 0.9834 - binary_output_24_binary_accuracy: 0.9941 - binary_output_25_binary_accuracy: 0.9863 - binary_output_26_binary_accuracy: 0.7939 - binary_output_27_binary_accuracy: 0.2871 - binary_output_28_binary_accuracy: 0.6211 - binary_output_29_binary_accuracy: 0.4346 - binary_output_30_binary_accuracy: 0.9922 - binary_output_31_binary_accuracy: 0.1680 - binary_output_32_binary_accuracy: 0.9805 - binary_output_33_binary_accuracy: 0.7158 - binary_output_34_binary_accuracy: 0.2051 - categorical_output_sparse_categorical_accuracy: 0.649422237/22237 [==============================] - 7s 306us/step - loss: 17.0462 - binary_output_0_loss: 0.8707 - binary_output_1_loss: 0.1162 - binary_output_2_loss: 0.8910 - binary_output_3_loss: 0.6688 - binary_output_4_loss: 0.4951 - binary_output_5_loss: 0.3935 - binary_output_6_loss: 0.3170 - binary_output_7_loss: 0.4169 - binary_output_8_loss: 0.0188 - binary_output_9_loss: 0.4974 - binary_output_10_loss: 0.6926 - binary_output_11_loss: 0.6012 - binary_output_12_loss: 0.2630 - binary_output_13_loss: 0.3507 - binary_output_14_loss: 0.2353 - binary_output_15_loss: 0.4035 - binary_output_16_loss: 0.4745 - binary_output_17_loss: 0.8376 - binary_output_18_loss: 0.5723 - binary_output_19_loss: 0.4960 - binary_output_20_loss: 0.4771 - binary_output_21_loss: 0.3129 - binary_output_22_loss: 0.1481 - binary_output_23_loss: 0.2173 - binary_output_24_loss: 0.1210 - binary_output_25_loss: 0.2237 - binary_output_26_loss: 0.4701 - binary_output_27_loss: 0.9333 - binary_output_28_loss: 0.5784 - binary_output_29_loss: 0.6883 - binary_output_30_loss: 0.2173 - binary_output_31_loss: 0.7542 - binary_output_32_loss: 0.3138 - binary_output_33_loss: 0.5414 - binary_output_34_loss: 0.8958 - categorical_output_loss: 0.5518 - binary_output_0_binary_accuracy: 0.1744 - binary_output_1_binary_accuracy: 0.9957 - binary_output_2_binary_accuracy: 0.4152 - binary_output_3_binary_accuracy: 0.5405 - binary_output_4_binary_accuracy: 0.7652 - binary_output_5_binary_accuracy: 0.9274 - binary_output_6_binary_accuracy: 0.9805 - binary_output_7_binary_accuracy: 0.8936 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7296 - binary_output_10_binary_accuracy: 0.4768 - binary_output_11_binary_accuracy: 0.6162 - binary_output_12_binary_accuracy: 0.9760 - binary_output_13_binary_accuracy: 0.9603 - binary_output_14_binary_accuracy: 0.9880 - binary_output_15_binary_accuracy: 0.8611 - binary_output_16_binary_accuracy: 0.7788 - binary_output_17_binary_accuracy: 0.1609 - binary_output_18_binary_accuracy: 0.6617 - binary_output_19_binary_accuracy: 0.7792 - binary_output_20_binary_accuracy: 0.7614 - binary_output_21_binary_accuracy: 0.9513 - binary_output_22_binary_accuracy: 0.9937 - binary_output_23_binary_accuracy: 0.9879 - binary_output_24_binary_accuracy: 0.9954 - binary_output_25_binary_accuracy: 0.9824 - binary_output_26_binary_accuracy: 0.7847 - binary_output_27_binary_accuracy: 0.2811 - binary_output_28_binary_accuracy: 0.6628 - binary_output_29_binary_accuracy: 0.5034 - binary_output_30_binary_accuracy: 0.9890 - binary_output_31_binary_accuracy: 0.1863 - binary_output_32_binary_accuracy: 0.9630 - binary_output_33_binary_accuracy: 0.7148 - binary_output_34_binary_accuracy: 0.1944 - categorical_output_sparse_categorical_accuracy: 0.6725\n",
      "Epoch 4/40\n",
      "22237/22237 [==============================] - 7s 324us/step - loss: 16.3196 - binary_output_0_loss: 0.7924 - binary_output_1_loss: 0.1156 - binary_output_2_loss: 0.8599 - binary_output_3_loss: 0.6561 - binary_output_4_loss: 0.4872 - binary_output_5_loss: 0.3812 - binary_output_6_loss: 0.3144 - binary_output_7_loss: 0.3934 - binary_output_8_loss: 0.0128 - binary_output_9_loss: 0.4710 - binary_output_10_loss: 0.6425 - binary_output_11_loss: 0.5317 - binary_output_12_loss: 0.2427 - binary_output_13_loss: 0.3457 - binary_output_14_loss: 0.2304 - binary_output_15_loss: 0.3885 - binary_output_16_loss: 0.4591 - binary_output_17_loss: 0.8229 - binary_output_18_loss: 0.5533 - binary_output_19_loss: 0.4772 - binary_output_20_loss: 0.4479 - binary_output_21_loss: 0.2993 - binary_output_22_loss: 0.1453 - binary_output_23_loss: 0.2098 - binary_output_24_loss: 0.1176 - binary_output_25_loss: 0.2157 - binary_output_26_loss: 0.4536 - binary_output_27_loss: 0.9006 - binary_output_28_loss: 0.5594 - binary_output_29_loss: 0.6621 - binary_output_30_loss: 0.2154 - binary_output_31_loss: 0.7316 - binary_output_32_loss: 0.2936 - binary_output_33_loss: 0.5265 - binary_output_34_loss: 0.8387 - categorical_output_loss: 0.5184 - binary_output_0_binary_accuracy: 0.2953 - binary_output_1_binary_accuracy: 0.9957 - binary_output_2_binary_accuracy: 0.4182 - binary_output_3_binary_accuracy: 0.5335 - binary_output_4_binary_accuracy: 0.7398 - binary_output_5_binary_accuracy: 0.9210 - binary_output_6_binary_accuracy: 0.9812 - binary_output_7_binary_accuracy: 0.9084 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7257 - binary_output_10_binary_accuracy: 0.5958 - binary_output_11_binary_accuracy: 0.6903 - binary_output_12_binary_accuracy: 0.9663 - binary_output_13_binary_accuracy: 0.9448 - binary_output_14_binary_accuracy: 0.9879 - binary_output_15_binary_accuracy: 0.8494 - binary_output_16_binary_accuracy: 0.7625 - binary_output_17_binary_accuracy: 0.2224 - binary_output_18_binary_accuracy: 0.6593 - binary_output_19_binary_accuracy: 0.7656 - binary_output_20_binary_accuracy: 0.7557 - binary_output_21_binary_accuracy: 0.9488 - binary_output_22_binary_accuracy: 0.9931 - binary_output_23_binary_accuracy: 0.9864 - binary_output_24_binary_accuracy: 0.9953 - binary_output_25_binary_accuracy: 0.9736 - binary_output_26_binary_accuracy: 0.7783 - binary_output_27_binary_accuracy: 0.2948 - binary_output_28_binary_accuracy: 0.6661 - binary_output_29_binary_accuracy: 0.5377 - binary_output_30_binary_accuracy: 0.9889 - binary_output_31_binary_accuracy: 0.3249 - binary_output_32_binary_accuracy: 0.9428 - binary_output_33_binary_accuracy: 0.7058 - binary_output_34_binary_accuracy: 0.2618 - categorical_output_sparse_categorical_accuracy: 0.7071\n",
      "Epoch 5/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  512/22237 [..............................] - ETA: 6s - loss: 16.0597 - binary_output_0_loss: 0.8193 - binary_output_1_loss: 0.1136 - binary_output_2_loss: 0.8315 - binary_output_3_loss: 0.5969 - binary_output_4_loss: 0.4852 - binary_output_5_loss: 0.4013 - binary_output_6_loss: 0.3788 - binary_output_7_loss: 0.3800 - binary_output_8_loss: 0.0111 - binary_output_9_loss: 0.5401 - binary_output_10_loss: 0.6530 - binary_output_11_loss: 0.5467 - binary_output_12_loss: 0.2697 - binary_output_13_loss: 0.3624 - binary_output_14_loss: 0.2249 - binary_output_15_loss: 0.3123 - binary_output_16_loss: 0.4308 - binary_output_17_loss: 0.7974 - binary_output_18_loss: 0.5157 - binary_output_19_loss: 0.4679 - binary_output_20_loss: 0.4461 - binary_output_21_loss: 0.2879 - binary_output_22_loss: 0.1058 - binary_output_23_loss: 0.2696 - binary_output_24_loss: 0.1428 - binary_output_25_loss: 0.1751 - binary_output_26_loss: 0.3917 - binary_output_27_loss: 0.8810 - binary_output_28_loss: 0.4488 - binary_output_29_loss: 0.6445 - binary_output_30_loss: 0.1058 - binary_output_31_loss: 0.8006 - binary_output_32_loss: 0.2932 - binary_output_33_loss: 0.5357 - binary_output_34_loss: 0.8452 - categorical_output_loss: 0.5475 - binary_output_0_binary_accuracy: 0.3340 - binary_output_1_binary_accuracy: 0.9961 - binary_output_2_binary_accuracy: 0.4375 - binary_output_3_binary_accuracy: 0.5859 - binary_output_4_binary_accuracy: 0.7695 - binary_output_5_binary_accuracy: 0.9355 - binary_output_6_binary_accuracy: 0.9746 - binary_output_7_binary_accuracy: 0.9219 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7695 - binary_output_10_binary_accuracy: 0.6094 - binary_output_11_binary_accuracy: 0.7031 - binary_output_12_binary_accuracy: 0.9668 - binary_output_13_binary_accuracy: 0.9629 - binary_output_14_binary_accuracy: 0.9863 - binary_output_15_binary_accuracy: 0.8926 - binary_output_16_binary_accuracy: 0.8125 - binary_output_17_binary_accuracy: 0.2773 - binary_output_18_binary_accuracy: 0.7188 - binary_output_19_binary_accuracy: 0.8613 - binary_output_20_binary_accuracy: 0.7969 - binary_output_21_binary_accuracy: 0.9707 - binary_output_22_binary_accuracy: 0.9961 - binary_output_23_binary_accuracy: 0.9844 - binary_output_24_binary_accuracy: 0.9941 - binary_output_25_binary_accuracy: 0.9785 - binary_output_26_binary_accuracy: 0.8340 - binary_output_27_binary_accuracy: 0.3613 - binary_output_28_binary_accuracy: 0.7559 - binary_output_29_binary_accuracy: 0.6328 - binary_output_30_binary_accuracy: 0.9961 - binary_output_31_binary_accuracy: 0.5156 - binary_output_32_binary_accuracy: 0.9590 - binary_output_33_binary_accuracy: 0.7930 - binary_output_34_binary_accuracy: 0.3203 - categorical_output_sparse_categorical_accuracy: 0.6719\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 1024/22237 [>.............................] - ETA: 6s - loss: 16.0319 - binary_output_0_loss: 0.7990 - binary_output_1_loss: 0.1345 - binary_output_2_loss: 0.8622 - binary_output_3_loss: 0.5951 - binary_output_4_loss: 0.4701 - binary_output_5_loss: 0.3900 - binary_output_6_loss: 0.3637 - binary_output_7_loss: 0.4168 - binary_output_8_loss: 0.0123 - binary_output_9_loss: 0.4921 - binary_output_10_loss: 0.6367 - binary_output_11_loss: 0.5313 - binary_output_12_loss: 0.2515 - binary_output_13_loss: 0.3869 - binary_output_14_loss: 0.2213 - binary_output_15_loss: 0.3071 - binary_output_16_loss: 0.4529 - binary_output_17_loss: 0.7994 - binary_output_18_loss: 0.5485 - binary_output_19_loss: 0.4368 - binary_output_20_loss: 0.4464 - binary_output_21_loss: 0.2665 - binary_output_22_loss: 0.1158 - binary_output_23_loss: 0.2470 - binary_output_24_loss: 0.0973 - binary_output_25_loss: 0.2226 - binary_output_26_loss: 0.4254 - binary_output_27_loss: 0.8894 - binary_output_28_loss: 0.4566 - binary_output_29_loss: 0.6728 - binary_output_30_loss: 0.1360 - binary_output_31_loss: 0.7891 - binary_output_32_loss: 0.2681 - binary_output_33_loss: 0.5134 - binary_output_34_loss: 0.8436 - categorical_output_loss: 0.5337 - binary_output_0_binary_accuracy: 0.2939 - binary_output_1_binary_accuracy: 0.9951 - binary_output_2_binary_accuracy: 0.4170 - binary_output_3_binary_accuracy: 0.5410 - binary_output_4_binary_accuracy: 0.7197 - binary_output_5_binary_accuracy: 0.8975 - binary_output_6_binary_accuracy: 0.9756 - binary_output_7_binary_accuracy: 0.9199 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7236 - binary_output_10_binary_accuracy: 0.5469 - binary_output_11_binary_accuracy: 0.6621 - binary_output_12_binary_accuracy: 0.9590 - binary_output_13_binary_accuracy: 0.9512 - binary_output_14_binary_accuracy: 0.9873 - binary_output_15_binary_accuracy: 0.8604 - binary_output_16_binary_accuracy: 0.7646 - binary_output_17_binary_accuracy: 0.2539 - binary_output_18_binary_accuracy: 0.6582 - binary_output_19_binary_accuracy: 0.8008 - binary_output_20_binary_accuracy: 0.7344 - binary_output_21_binary_accuracy: 0.9658 - binary_output_22_binary_accuracy: 0.9961 - binary_output_23_binary_accuracy: 0.9824 - binary_output_24_binary_accuracy: 0.9961 - binary_output_25_binary_accuracy: 0.9707 - binary_output_26_binary_accuracy: 0.7881 - binary_output_27_binary_accuracy: 0.3213 - binary_output_28_binary_accuracy: 0.6865 - binary_output_29_binary_accuracy: 0.5654 - binary_output_30_binary_accuracy: 0.9941 - binary_output_31_binary_accuracy: 0.4355 - binary_output_32_binary_accuracy: 0.9512 - binary_output_33_binary_accuracy: 0.7363 - binary_output_34_binary_accuracy: 0.2842 - categorical_output_sparse_categorical_accuracy: 0.7002"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22237/22237 [==============================] - 6s 271us/step - loss: 15.7802 - binary_output_0_loss: 0.7287 - binary_output_1_loss: 0.1183 - binary_output_2_loss: 0.8343 - binary_output_3_loss: 0.6432 - binary_output_4_loss: 0.4753 - binary_output_5_loss: 0.3692 - binary_output_6_loss: 0.3118 - binary_output_7_loss: 0.3746 - binary_output_8_loss: 0.0096 - binary_output_9_loss: 0.4458 - binary_output_10_loss: 0.5996 - binary_output_11_loss: 0.5028 - binary_output_12_loss: 0.2234 - binary_output_13_loss: 0.3403 - binary_output_14_loss: 0.2240 - binary_output_15_loss: 0.3771 - binary_output_16_loss: 0.4384 - binary_output_17_loss: 0.8083 - binary_output_18_loss: 0.5384 - binary_output_19_loss: 0.4613 - binary_output_20_loss: 0.4313 - binary_output_21_loss: 0.2894 - binary_output_22_loss: 0.1413 - binary_output_23_loss: 0.2042 - binary_output_24_loss: 0.1128 - binary_output_25_loss: 0.2101 - binary_output_26_loss: 0.4418 - binary_output_27_loss: 0.8862 - binary_output_28_loss: 0.5434 - binary_output_29_loss: 0.6448 - binary_output_30_loss: 0.2131 - binary_output_31_loss: 0.7302 - binary_output_32_loss: 0.2798 - binary_output_33_loss: 0.5105 - binary_output_34_loss: 0.7940 - categorical_output_loss: 0.5054 - binary_output_0_binary_accuracy: 0.4334 - binary_output_1_binary_accuracy: 0.9957 - binary_output_2_binary_accuracy: 0.4265 - binary_output_3_binary_accuracy: 0.5353 - binary_output_4_binary_accuracy: 0.7344 - binary_output_5_binary_accuracy: 0.9008 - binary_output_6_binary_accuracy: 0.9810 - binary_output_7_binary_accuracy: 0.8687 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7443 - binary_output_10_binary_accuracy: 0.6316 - binary_output_11_binary_accuracy: 0.7083 - binary_output_12_binary_accuracy: 0.9519 - binary_output_13_binary_accuracy: 0.9396 - binary_output_14_binary_accuracy: 0.9874 - binary_output_15_binary_accuracy: 0.8391 - binary_output_16_binary_accuracy: 0.7705 - binary_output_17_binary_accuracy: 0.2811 - binary_output_18_binary_accuracy: 0.6691 - binary_output_19_binary_accuracy: 0.7824 - binary_output_20_binary_accuracy: 0.7600 - binary_output_21_binary_accuracy: 0.9440 - binary_output_22_binary_accuracy: 0.9933 - binary_output_23_binary_accuracy: 0.9839 - binary_output_24_binary_accuracy: 0.9954 - binary_output_25_binary_accuracy: 0.9723 - binary_output_26_binary_accuracy: 0.7808 - binary_output_27_binary_accuracy: 0.3156 - binary_output_28_binary_accuracy: 0.6759 - binary_output_29_binary_accuracy: 0.5422 - binary_output_30_binary_accuracy: 0.9891 - binary_output_31_binary_accuracy: 0.3674 - binary_output_32_binary_accuracy: 0.9353 - binary_output_33_binary_accuracy: 0.7188 - binary_output_34_binary_accuracy: 0.3571 - categorical_output_sparse_categorical_accuracy: 0.7200\n",
      "Epoch 6/40\n",
      "22237/22237 [==============================] - 6s 256us/step - loss: 15.2166 - binary_output_0_loss: 0.6845 - binary_output_1_loss: 0.1148 - binary_output_2_loss: 0.8086 - binary_output_3_loss: 0.6373 - binary_output_4_loss: 0.4569 - binary_output_5_loss: 0.3654 - binary_output_6_loss: 0.3087 - binary_output_7_loss: 0.3609 - binary_output_8_loss: 0.0078 - binary_output_9_loss: 0.4188 - binary_output_10_loss: 0.5482 - binary_output_11_loss: 0.4741 - binary_output_12_loss: 0.2104 - binary_output_13_loss: 0.3353 - binary_output_14_loss: 0.2197 - binary_output_15_loss: 0.3653 - binary_output_16_loss: 0.4211 - binary_output_17_loss: 0.7919 - binary_output_18_loss: 0.5170 - binary_output_19_loss: 0.4479 - binary_output_20_loss: 0.4138 - binary_output_21_loss: 0.2829 - binary_output_22_loss: 0.1418 - binary_output_23_loss: 0.2057 - binary_output_24_loss: 0.1087 - binary_output_25_loss: 0.2029 - binary_output_26_loss: 0.4242 - binary_output_27_loss: 0.8421 - binary_output_28_loss: 0.5202 - binary_output_29_loss: 0.6178 - binary_output_30_loss: 0.2084 - binary_output_31_loss: 0.7078 - binary_output_32_loss: 0.2692 - binary_output_33_loss: 0.5035 - binary_output_34_loss: 0.7701 - categorical_output_loss: 0.4888 - binary_output_0_binary_accuracy: 0.5520 - binary_output_1_binary_accuracy: 0.9957 - binary_output_2_binary_accuracy: 0.4478 - binary_output_3_binary_accuracy: 0.5400 - binary_output_4_binary_accuracy: 0.7385 - binary_output_5_binary_accuracy: 0.8933 - binary_output_6_binary_accuracy: 0.9806 - binary_output_7_binary_accuracy: 0.8485 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7768 - binary_output_10_binary_accuracy: 0.6941 - binary_output_11_binary_accuracy: 0.7372 - binary_output_12_binary_accuracy: 0.9469 - binary_output_13_binary_accuracy: 0.9369 - binary_output_14_binary_accuracy: 0.9861 - binary_output_15_binary_accuracy: 0.8404 - binary_output_16_binary_accuracy: 0.7884 - binary_output_17_binary_accuracy: 0.3378 - binary_output_18_binary_accuracy: 0.6836 - binary_output_19_binary_accuracy: 0.7808 - binary_output_20_binary_accuracy: 0.7682 - binary_output_21_binary_accuracy: 0.9356 - binary_output_22_binary_accuracy: 0.9929 - binary_output_23_binary_accuracy: 0.9807 - binary_output_24_binary_accuracy: 0.9953 - binary_output_25_binary_accuracy: 0.9723 - binary_output_26_binary_accuracy: 0.7871 - binary_output_27_binary_accuracy: 0.3551 - binary_output_28_binary_accuracy: 0.6967 - binary_output_29_binary_accuracy: 0.5873 - binary_output_30_binary_accuracy: 0.9886 - binary_output_31_binary_accuracy: 0.4065 - binary_output_32_binary_accuracy: 0.9242 - binary_output_33_binary_accuracy: 0.7199 - binary_output_34_binary_accuracy: 0.4166 - categorical_output_sparse_categorical_accuracy: 0.7431\n",
      "Epoch 7/40\n",
      " 1024/22237 [>.............................] - ETA: 5s - loss: 14.4397 - binary_output_0_loss: 0.6796 - binary_output_1_loss: 0.0539 - binary_output_2_loss: 0.8229 - binary_output_3_loss: 0.5881 - binary_output_4_loss: 0.4389 - binary_output_5_loss: 0.3296 - binary_output_6_loss: 0.3742 - binary_output_7_loss: 0.4151 - binary_output_8_loss: 0.0056 - binary_output_9_loss: 0.3221 - binary_output_10_loss: 0.5126 - binary_output_11_loss: 0.4361 - binary_output_12_loss: 0.1723 - binary_output_13_loss: 0.3634 - binary_output_14_loss: 0.2581 - binary_output_15_loss: 0.2993 - binary_output_16_loss: 0.3954 - binary_output_17_loss: 0.8035 - binary_output_18_loss: 0.4693 - binary_output_19_loss: 0.3619 - binary_output_20_loss: 0.3598 - binary_output_21_loss: 0.2890 - binary_output_22_loss: 0.1622 - binary_output_23_loss: 0.1366 - binary_output_24_loss: 0.0583 - binary_output_25_loss: 0.1409 - binary_output_26_loss: 0.4100 - binary_output_27_loss: 0.8008 - binary_output_28_loss: 0.4356 - binary_output_29_loss: 0.6072 - binary_output_30_loss: 0.1650 - binary_output_31_loss: 0.7456 - binary_output_32_loss: 0.2431 - binary_output_33_loss: 0.4924 - binary_output_34_loss: 0.8242 - categorical_output_loss: 0.4669 - binary_output_0_binary_accuracy: 0.5596 - binary_output_1_binary_accuracy: 0.9990 - binary_output_2_binary_accuracy: 0.4385 - binary_output_3_binary_accuracy: 0.5811 - binary_output_4_binary_accuracy: 0.8047 - binary_output_5_binary_accuracy: 0.9082 - binary_output_6_binary_accuracy: 0.9746 - binary_output_7_binary_accuracy: 0.8770 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8242 - binary_output_10_binary_accuracy: 0.7676 - binary_output_11_binary_accuracy: 0.7734 - binary_output_12_binary_accuracy: 0.9531 - binary_output_13_binary_accuracy: 0.9629 - binary_output_14_binary_accuracy: 0.9785 - binary_output_15_binary_accuracy: 0.8623 - binary_output_16_binary_accuracy: 0.7910 - binary_output_17_binary_accuracy: 0.4209 - binary_output_18_binary_accuracy: 0.7412 - binary_output_19_binary_accuracy: 0.8008 - binary_output_20_binary_accuracy: 0.8135 - binary_output_21_binary_accuracy: 0.9443 - binary_output_22_binary_accuracy: 0.9932 - binary_output_23_binary_accuracy: 0.9893 - binary_output_24_binary_accuracy: 0.9980 - binary_output_25_binary_accuracy: 0.9854 - binary_output_26_binary_accuracy: 0.8252 - binary_output_27_binary_accuracy: 0.3857 - binary_output_28_binary_accuracy: 0.7373 - binary_output_29_binary_accuracy: 0.6191 - binary_output_30_binary_accuracy: 0.9902 - binary_output_31_binary_accuracy: 0.4590 - binary_output_32_binary_accuracy: 0.9229 - binary_output_33_binary_accuracy: 0.7344 - binary_output_34_binary_accuracy: 0.4443 - categorical_output_sparse_categorical_accuracy: 0.729522237/22237 [==============================] - 5s 244us/step - loss: 14.7879 - binary_output_0_loss: 0.6628 - binary_output_1_loss: 0.1138 - binary_output_2_loss: 0.7947 - binary_output_3_loss: 0.6294 - binary_output_4_loss: 0.4391 - binary_output_5_loss: 0.3578 - binary_output_6_loss: 0.3012 - binary_output_7_loss: 0.3519 - binary_output_8_loss: 0.0062 - binary_output_9_loss: 0.4001 - binary_output_10_loss: 0.5147 - binary_output_11_loss: 0.4532 - binary_output_12_loss: 0.1979 - binary_output_13_loss: 0.3312 - binary_output_14_loss: 0.2188 - binary_output_15_loss: 0.3668 - binary_output_16_loss: 0.4152 - binary_output_17_loss: 0.7828 - binary_output_18_loss: 0.5027 - binary_output_19_loss: 0.4392 - binary_output_20_loss: 0.3968 - binary_output_21_loss: 0.2747 - binary_output_22_loss: 0.1412 - binary_output_23_loss: 0.1996 - binary_output_24_loss: 0.1095 - binary_output_25_loss: 0.2036 - binary_output_26_loss: 0.4095 - binary_output_27_loss: 0.7911 - binary_output_28_loss: 0.5005 - binary_output_29_loss: 0.5917 - binary_output_30_loss: 0.2007 - binary_output_31_loss: 0.6684 - binary_output_32_loss: 0.2593 - binary_output_33_loss: 0.4933 - binary_output_34_loss: 0.7620 - categorical_output_loss: 0.4881 - binary_output_0_binary_accuracy: 0.5920 - binary_output_1_binary_accuracy: 0.9957 - binary_output_2_binary_accuracy: 0.4670 - binary_output_3_binary_accuracy: 0.5489 - binary_output_4_binary_accuracy: 0.7562 - binary_output_5_binary_accuracy: 0.8849 - binary_output_6_binary_accuracy: 0.9796 - binary_output_7_binary_accuracy: 0.8622 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7982 - binary_output_10_binary_accuracy: 0.7339 - binary_output_11_binary_accuracy: 0.7443 - binary_output_12_binary_accuracy: 0.9351 - binary_output_13_binary_accuracy: 0.9513 - binary_output_14_binary_accuracy: 0.9837 - binary_output_15_binary_accuracy: 0.8260 - binary_output_16_binary_accuracy: 0.7903 - binary_output_17_binary_accuracy: 0.3840 - binary_output_18_binary_accuracy: 0.6917 - binary_output_19_binary_accuracy: 0.7801 - binary_output_20_binary_accuracy: 0.7754 - binary_output_21_binary_accuracy: 0.9267 - binary_output_22_binary_accuracy: 0.9933 - binary_output_23_binary_accuracy: 0.9808 - binary_output_24_binary_accuracy: 0.9948 - binary_output_25_binary_accuracy: 0.9706 - binary_output_26_binary_accuracy: 0.7861 - binary_output_27_binary_accuracy: 0.4024 - binary_output_28_binary_accuracy: 0.7242 - binary_output_29_binary_accuracy: 0.6239 - binary_output_30_binary_accuracy: 0.9885 - binary_output_31_binary_accuracy: 0.5386 - binary_output_32_binary_accuracy: 0.9119 - binary_output_33_binary_accuracy: 0.7112 - binary_output_34_binary_accuracy: 0.4503 - categorical_output_sparse_categorical_accuracy: 0.7488\n",
      "Epoch 8/40\n",
      "22237/22237 [==============================] - 6s 251us/step - loss: 14.3532 - binary_output_0_loss: 0.6509 - binary_output_1_loss: 0.1085 - binary_output_2_loss: 0.7781 - binary_output_3_loss: 0.6140 - binary_output_4_loss: 0.4180 - binary_output_5_loss: 0.3524 - binary_output_6_loss: 0.2979 - binary_output_7_loss: 0.3382 - binary_output_8_loss: 0.0049 - binary_output_9_loss: 0.3966 - binary_output_10_loss: 0.4937 - binary_output_11_loss: 0.4368 - binary_output_12_loss: 0.1877 - binary_output_13_loss: 0.3195 - binary_output_14_loss: 0.2120 - binary_output_15_loss: 0.3550 - binary_output_16_loss: 0.4080 - binary_output_17_loss: 0.7765 - binary_output_18_loss: 0.4861 - binary_output_19_loss: 0.4347 - binary_output_20_loss: 0.3828 - binary_output_21_loss: 0.2753 - binary_output_22_loss: 0.1369 - binary_output_23_loss: 0.1947 - binary_output_24_loss: 0.1090 - binary_output_25_loss: 0.1972 - binary_output_26_loss: 0.3970 - binary_output_27_loss: 0.7406 - binary_output_28_loss: 0.4892 - binary_output_29_loss: 0.5626 - binary_output_30_loss: 0.2007 - binary_output_31_loss: 0.6254 - binary_output_32_loss: 0.2514 - binary_output_33_loss: 0.4847 - binary_output_34_loss: 0.7503 - categorical_output_loss: 0.4779 - binary_output_0_binary_accuracy: 0.6137 - binary_output_1_binary_accuracy: 0.9956 - binary_output_2_binary_accuracy: 0.4871 - binary_output_3_binary_accuracy: 0.5483 - binary_output_4_binary_accuracy: 0.7862 - binary_output_5_binary_accuracy: 0.8820 - binary_output_6_binary_accuracy: 0.9785 - binary_output_7_binary_accuracy: 0.8587 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7936 - binary_output_10_binary_accuracy: 0.7469 - binary_output_11_binary_accuracy: 0.7605 - binary_output_12_binary_accuracy: 0.9331 - binary_output_13_binary_accuracy: 0.9371 - binary_output_14_binary_accuracy: 0.9837 - binary_output_15_binary_accuracy: 0.8307 - binary_output_16_binary_accuracy: 0.7897 - binary_output_17_binary_accuracy: 0.4082 - binary_output_18_binary_accuracy: 0.7048 - binary_output_19_binary_accuracy: 0.7771 - binary_output_20_binary_accuracy: 0.7801 - binary_output_21_binary_accuracy: 0.9334 - binary_output_22_binary_accuracy: 0.9929 - binary_output_23_binary_accuracy: 0.9814 - binary_output_24_binary_accuracy: 0.9940 - binary_output_25_binary_accuracy: 0.9691 - binary_output_26_binary_accuracy: 0.7875 - binary_output_27_binary_accuracy: 0.4688 - binary_output_28_binary_accuracy: 0.7265 - binary_output_29_binary_accuracy: 0.6713 - binary_output_30_binary_accuracy: 0.9861 - binary_output_31_binary_accuracy: 0.6177 - binary_output_32_binary_accuracy: 0.9096 - binary_output_33_binary_accuracy: 0.7144 - binary_output_34_binary_accuracy: 0.4680 - categorical_output_sparse_categorical_accuracy: 0.7563\n",
      "Epoch 9/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  512/22237 [..............................] - ETA: 5s - loss: 14.9521 - binary_output_0_loss: 0.6515 - binary_output_1_loss: 0.0315 - binary_output_2_loss: 0.7756 - binary_output_3_loss: 0.7332 - binary_output_4_loss: 0.4511 - binary_output_5_loss: 0.3551 - binary_output_6_loss: 0.3188 - binary_output_7_loss: 0.2384 - binary_output_8_loss: 0.0042 - binary_output_9_loss: 0.3431 - binary_output_10_loss: 0.4678 - binary_output_11_loss: 0.4755 - binary_output_12_loss: 0.2766 - binary_output_13_loss: 0.4246 - binary_output_14_loss: 0.2982 - binary_output_15_loss: 0.4450 - binary_output_16_loss: 0.3774 - binary_output_17_loss: 0.7702 - binary_output_18_loss: 0.5621 - binary_output_19_loss: 0.4211 - binary_output_20_loss: 0.4211 - binary_output_21_loss: 0.2288 - binary_output_22_loss: 0.1728 - binary_output_23_loss: 0.2937 - binary_output_24_loss: 0.1411 - binary_output_25_loss: 0.2833 - binary_output_26_loss: 0.4214 - binary_output_27_loss: 0.7539 - binary_output_28_loss: 0.4386 - binary_output_29_loss: 0.4695 - binary_output_30_loss: 0.2997 - binary_output_31_loss: 0.5893 - binary_output_32_loss: 0.2646 - binary_output_33_loss: 0.5759 - binary_output_34_loss: 0.7236 - categorical_output_loss: 0.4540 - binary_output_0_binary_accuracy: 0.5098 - binary_output_1_binary_accuracy: 1.0000 - binary_output_2_binary_accuracy: 0.4980 - binary_output_3_binary_accuracy: 0.5449 - binary_output_4_binary_accuracy: 0.7344 - binary_output_5_binary_accuracy: 0.9141 - binary_output_6_binary_accuracy: 0.9824 - binary_output_7_binary_accuracy: 0.9531 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7617 - binary_output_10_binary_accuracy: 0.6738 - binary_output_11_binary_accuracy: 0.7363 - binary_output_12_binary_accuracy: 0.9160 - binary_output_13_binary_accuracy: 0.9395 - binary_output_14_binary_accuracy: 0.9805 - binary_output_15_binary_accuracy: 0.8652 - binary_output_16_binary_accuracy: 0.8125 - binary_output_17_binary_accuracy: 0.3711 - binary_output_18_binary_accuracy: 0.7168 - binary_output_19_binary_accuracy: 0.8105 - binary_output_20_binary_accuracy: 0.7988 - binary_output_21_binary_accuracy: 0.9414 - binary_output_22_binary_accuracy: 0.9922 - binary_output_23_binary_accuracy: 0.9785 - binary_output_24_binary_accuracy: 0.9902 - binary_output_25_binary_accuracy: 0.9570 - binary_output_26_binary_accuracy: 0.8086 - binary_output_27_binary_accuracy: 0.5605 - binary_output_28_binary_accuracy: 0.7422 - binary_output_29_binary_accuracy: 0.7461 - binary_output_30_binary_accuracy: 0.9844 - binary_output_31_binary_accuracy: 0.6289 - binary_output_32_binary_accuracy: 0.9199 - binary_output_33_binary_accuracy: 0.7520 - binary_output_34_binary_accuracy: 0.3613 - categorical_output_sparse_categorical_accuracy: 0.7656\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 1024/22237 [>.............................] - ETA: 5s - loss: 14.8703 - binary_output_0_loss: 0.6461 - binary_output_1_loss: 0.0587 - binary_output_2_loss: 0.7972 - binary_output_3_loss: 0.6686 - binary_output_4_loss: 0.4117 - binary_output_5_loss: 0.3793 - binary_output_6_loss: 0.3243 - binary_output_7_loss: 0.3126 - binary_output_8_loss: 0.0051 - binary_output_9_loss: 0.3461 - binary_output_10_loss: 0.4772 - binary_output_11_loss: 0.4443 - binary_output_12_loss: 0.2270 - binary_output_13_loss: 0.3946 - binary_output_14_loss: 0.2692 - binary_output_15_loss: 0.4339 - binary_output_16_loss: 0.4146 - binary_output_17_loss: 0.7793 - binary_output_18_loss: 0.5410 - binary_output_19_loss: 0.4257 - binary_output_20_loss: 0.4182 - binary_output_21_loss: 0.2741 - binary_output_22_loss: 0.1311 - binary_output_23_loss: 0.3033 - binary_output_24_loss: 0.1543 - binary_output_25_loss: 0.2315 - binary_output_26_loss: 0.4100 - binary_output_27_loss: 0.7426 - binary_output_28_loss: 0.4496 - binary_output_29_loss: 0.5068 - binary_output_30_loss: 0.3473 - binary_output_31_loss: 0.5825 - binary_output_32_loss: 0.2507 - binary_output_33_loss: 0.5395 - binary_output_34_loss: 0.7184 - categorical_output_loss: 0.4539 - binary_output_0_binary_accuracy: 0.5723 - binary_output_1_binary_accuracy: 0.9971 - binary_output_2_binary_accuracy: 0.4863 - binary_output_3_binary_accuracy: 0.5049 - binary_output_4_binary_accuracy: 0.7422 - binary_output_5_binary_accuracy: 0.8818 - binary_output_6_binary_accuracy: 0.9736 - binary_output_7_binary_accuracy: 0.9014 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7793 - binary_output_10_binary_accuracy: 0.6973 - binary_output_11_binary_accuracy: 0.7275 - binary_output_12_binary_accuracy: 0.9111 - binary_output_13_binary_accuracy: 0.9307 - binary_output_14_binary_accuracy: 0.9814 - binary_output_15_binary_accuracy: 0.8291 - binary_output_16_binary_accuracy: 0.7773 - binary_output_17_binary_accuracy: 0.3613 - binary_output_18_binary_accuracy: 0.6611 - binary_output_19_binary_accuracy: 0.7588 - binary_output_20_binary_accuracy: 0.7598 - binary_output_21_binary_accuracy: 0.9121 - binary_output_22_binary_accuracy: 0.9941 - binary_output_23_binary_accuracy: 0.9746 - binary_output_24_binary_accuracy: 0.9883 - binary_output_25_binary_accuracy: 0.9531 - binary_output_26_binary_accuracy: 0.7676 - binary_output_27_binary_accuracy: 0.4854 - binary_output_28_binary_accuracy: 0.6904 - binary_output_29_binary_accuracy: 0.6875 - binary_output_30_binary_accuracy: 0.9785 - binary_output_31_binary_accuracy: 0.5977 - binary_output_32_binary_accuracy: 0.8926 - binary_output_33_binary_accuracy: 0.6797 - binary_output_34_binary_accuracy: 0.4160 - categorical_output_sparse_categorical_accuracy: 0.7695"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22237/22237 [==============================] - 5s 246us/step - loss: 13.9788 - binary_output_0_loss: 0.6339 - binary_output_1_loss: 0.1097 - binary_output_2_loss: 0.7611 - binary_output_3_loss: 0.5990 - binary_output_4_loss: 0.4075 - binary_output_5_loss: 0.3444 - binary_output_6_loss: 0.2922 - binary_output_7_loss: 0.3277 - binary_output_8_loss: 0.0040 - binary_output_9_loss: 0.3872 - binary_output_10_loss: 0.4832 - binary_output_11_loss: 0.4238 - binary_output_12_loss: 0.1809 - binary_output_13_loss: 0.3209 - binary_output_14_loss: 0.2069 - binary_output_15_loss: 0.3577 - binary_output_16_loss: 0.4071 - binary_output_17_loss: 0.7647 - binary_output_18_loss: 0.4738 - binary_output_19_loss: 0.4261 - binary_output_20_loss: 0.3693 - binary_output_21_loss: 0.2666 - binary_output_22_loss: 0.1357 - binary_output_23_loss: 0.1900 - binary_output_24_loss: 0.1062 - binary_output_25_loss: 0.1902 - binary_output_26_loss: 0.3877 - binary_output_27_loss: 0.6981 - binary_output_28_loss: 0.4807 - binary_output_29_loss: 0.5400 - binary_output_30_loss: 0.1956 - binary_output_31_loss: 0.5873 - binary_output_32_loss: 0.2506 - binary_output_33_loss: 0.4751 - binary_output_34_loss: 0.7298 - categorical_output_loss: 0.4714 - binary_output_0_binary_accuracy: 0.6217 - binary_output_1_binary_accuracy: 0.9957 - binary_output_2_binary_accuracy: 0.5112 - binary_output_3_binary_accuracy: 0.5640 - binary_output_4_binary_accuracy: 0.7895 - binary_output_5_binary_accuracy: 0.8895 - binary_output_6_binary_accuracy: 0.9780 - binary_output_7_binary_accuracy: 0.8726 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7928 - binary_output_10_binary_accuracy: 0.7451 - binary_output_11_binary_accuracy: 0.7741 - binary_output_12_binary_accuracy: 0.9373 - binary_output_13_binary_accuracy: 0.9397 - binary_output_14_binary_accuracy: 0.9834 - binary_output_15_binary_accuracy: 0.8421 - binary_output_16_binary_accuracy: 0.7886 - binary_output_17_binary_accuracy: 0.4226 - binary_output_18_binary_accuracy: 0.7116 - binary_output_19_binary_accuracy: 0.7730 - binary_output_20_binary_accuracy: 0.7872 - binary_output_21_binary_accuracy: 0.9199 - binary_output_22_binary_accuracy: 0.9929 - binary_output_23_binary_accuracy: 0.9815 - binary_output_24_binary_accuracy: 0.9937 - binary_output_25_binary_accuracy: 0.9667 - binary_output_26_binary_accuracy: 0.7935 - binary_output_27_binary_accuracy: 0.5245 - binary_output_28_binary_accuracy: 0.7336 - binary_output_29_binary_accuracy: 0.6942 - binary_output_30_binary_accuracy: 0.9869 - binary_output_31_binary_accuracy: 0.6542 - binary_output_32_binary_accuracy: 0.9002 - binary_output_33_binary_accuracy: 0.7175 - binary_output_34_binary_accuracy: 0.4871 - categorical_output_sparse_categorical_accuracy: 0.7592\n",
      "Epoch 10/40\n",
      "22237/22237 [==============================] - 5s 247us/step - loss: 13.6261 - binary_output_0_loss: 0.6182 - binary_output_1_loss: 0.1052 - binary_output_2_loss: 0.7497 - binary_output_3_loss: 0.5801 - binary_output_4_loss: 0.3929 - binary_output_5_loss: 0.3400 - binary_output_6_loss: 0.2891 - binary_output_7_loss: 0.3198 - binary_output_8_loss: 0.0033 - binary_output_9_loss: 0.3746 - binary_output_10_loss: 0.4765 - binary_output_11_loss: 0.4094 - binary_output_12_loss: 0.1749 - binary_output_13_loss: 0.3139 - binary_output_14_loss: 0.2035 - binary_output_15_loss: 0.3432 - binary_output_16_loss: 0.4003 - binary_output_17_loss: 0.7519 - binary_output_18_loss: 0.4621 - binary_output_19_loss: 0.4205 - binary_output_20_loss: 0.3539 - binary_output_21_loss: 0.2674 - binary_output_22_loss: 0.1322 - binary_output_23_loss: 0.1863 - binary_output_24_loss: 0.1047 - binary_output_25_loss: 0.1870 - binary_output_26_loss: 0.3757 - binary_output_27_loss: 0.6644 - binary_output_28_loss: 0.4627 - binary_output_29_loss: 0.5138 - binary_output_30_loss: 0.1925 - binary_output_31_loss: 0.5600 - binary_output_32_loss: 0.2480 - binary_output_33_loss: 0.4659 - binary_output_34_loss: 0.7176 - categorical_output_loss: 0.4675 - binary_output_0_binary_accuracy: 0.6257 - binary_output_1_binary_accuracy: 0.9956 - binary_output_2_binary_accuracy: 0.5203 - binary_output_3_binary_accuracy: 0.6076 - binary_output_4_binary_accuracy: 0.7875 - binary_output_5_binary_accuracy: 0.8708 - binary_output_6_binary_accuracy: 0.9764 - binary_output_7_binary_accuracy: 0.8696 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7954 - binary_output_10_binary_accuracy: 0.7429 - binary_output_11_binary_accuracy: 0.7807 - binary_output_12_binary_accuracy: 0.9352 - binary_output_13_binary_accuracy: 0.9332 - binary_output_14_binary_accuracy: 0.9840 - binary_output_15_binary_accuracy: 0.8374 - binary_output_16_binary_accuracy: 0.7805 - binary_output_17_binary_accuracy: 0.4430 - binary_output_18_binary_accuracy: 0.7223 - binary_output_19_binary_accuracy: 0.7771 - binary_output_20_binary_accuracy: 0.7964 - binary_output_21_binary_accuracy: 0.9260 - binary_output_22_binary_accuracy: 0.9928 - binary_output_23_binary_accuracy: 0.9812 - binary_output_24_binary_accuracy: 0.9936 - binary_output_25_binary_accuracy: 0.9648 - binary_output_26_binary_accuracy: 0.7948 - binary_output_27_binary_accuracy: 0.5628 - binary_output_28_binary_accuracy: 0.7439 - binary_output_29_binary_accuracy: 0.7131 - binary_output_30_binary_accuracy: 0.9866 - binary_output_31_binary_accuracy: 0.6763 - binary_output_32_binary_accuracy: 0.9040 - binary_output_33_binary_accuracy: 0.7137 - binary_output_34_binary_accuracy: 0.5037 - categorical_output_sparse_categorical_accuracy: 0.7604\n",
      "Epoch 11/40\n",
      " 1024/22237 [>.............................] - ETA: 5s - loss: 13.3954 - binary_output_0_loss: 0.6233 - binary_output_1_loss: 0.0852 - binary_output_2_loss: 0.7176 - binary_output_3_loss: 0.6010 - binary_output_4_loss: 0.3867 - binary_output_5_loss: 0.3609 - binary_output_6_loss: 0.3220 - binary_output_7_loss: 0.2927 - binary_output_8_loss: 0.0031 - binary_output_9_loss: 0.3716 - binary_output_10_loss: 0.4477 - binary_output_11_loss: 0.4089 - binary_output_12_loss: 0.1685 - binary_output_13_loss: 0.2673 - binary_output_14_loss: 0.1827 - binary_output_15_loss: 0.3721 - binary_output_16_loss: 0.4495 - binary_output_17_loss: 0.7349 - binary_output_18_loss: 0.4511 - binary_output_19_loss: 0.4259 - binary_output_20_loss: 0.3077 - binary_output_21_loss: 0.3083 - binary_output_22_loss: 0.1591 - binary_output_23_loss: 0.1752 - binary_output_24_loss: 0.0786 - binary_output_25_loss: 0.1777 - binary_output_26_loss: 0.3747 - binary_output_27_loss: 0.6545 - binary_output_28_loss: 0.4751 - binary_output_29_loss: 0.5284 - binary_output_30_loss: 0.1627 - binary_output_31_loss: 0.5051 - binary_output_32_loss: 0.2168 - binary_output_33_loss: 0.4233 - binary_output_34_loss: 0.7270 - categorical_output_loss: 0.4486 - binary_output_0_binary_accuracy: 0.6475 - binary_output_1_binary_accuracy: 0.9971 - binary_output_2_binary_accuracy: 0.5508 - binary_output_3_binary_accuracy: 0.6299 - binary_output_4_binary_accuracy: 0.7979 - binary_output_5_binary_accuracy: 0.8613 - binary_output_6_binary_accuracy: 0.9736 - binary_output_7_binary_accuracy: 0.8916 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8252 - binary_output_10_binary_accuracy: 0.7432 - binary_output_11_binary_accuracy: 0.8018 - binary_output_12_binary_accuracy: 0.9385 - binary_output_13_binary_accuracy: 0.9238 - binary_output_14_binary_accuracy: 0.9844 - binary_output_15_binary_accuracy: 0.8223 - binary_output_16_binary_accuracy: 0.7793 - binary_output_17_binary_accuracy: 0.4268 - binary_output_18_binary_accuracy: 0.7373 - binary_output_19_binary_accuracy: 0.7539 - binary_output_20_binary_accuracy: 0.7979 - binary_output_21_binary_accuracy: 0.9014 - binary_output_22_binary_accuracy: 0.9912 - binary_output_23_binary_accuracy: 0.9766 - binary_output_24_binary_accuracy: 0.9971 - binary_output_25_binary_accuracy: 0.9492 - binary_output_26_binary_accuracy: 0.7969 - binary_output_27_binary_accuracy: 0.5596 - binary_output_28_binary_accuracy: 0.7236 - binary_output_29_binary_accuracy: 0.7012 - binary_output_30_binary_accuracy: 0.9854 - binary_output_31_binary_accuracy: 0.6895 - binary_output_32_binary_accuracy: 0.9072 - binary_output_33_binary_accuracy: 0.7402 - binary_output_34_binary_accuracy: 0.5146 - categorical_output_sparse_categorical_accuracy: 0.750022237/22237 [==============================] - 5s 247us/step - loss: 13.2864 - binary_output_0_loss: 0.5911 - binary_output_1_loss: 0.1057 - binary_output_2_loss: 0.7280 - binary_output_3_loss: 0.5739 - binary_output_4_loss: 0.3820 - binary_output_5_loss: 0.3334 - binary_output_6_loss: 0.2845 - binary_output_7_loss: 0.3029 - binary_output_8_loss: 0.0026 - binary_output_9_loss: 0.3659 - binary_output_10_loss: 0.4696 - binary_output_11_loss: 0.4060 - binary_output_12_loss: 0.1654 - binary_output_13_loss: 0.3094 - binary_output_14_loss: 0.2012 - binary_output_15_loss: 0.3357 - binary_output_16_loss: 0.3929 - binary_output_17_loss: 0.7415 - binary_output_18_loss: 0.4503 - binary_output_19_loss: 0.4116 - binary_output_20_loss: 0.3500 - binary_output_21_loss: 0.2574 - binary_output_22_loss: 0.1303 - binary_output_23_loss: 0.1843 - binary_output_24_loss: 0.1033 - binary_output_25_loss: 0.1766 - binary_output_26_loss: 0.3710 - binary_output_27_loss: 0.6365 - binary_output_28_loss: 0.4530 - binary_output_29_loss: 0.4970 - binary_output_30_loss: 0.1886 - binary_output_31_loss: 0.5353 - binary_output_32_loss: 0.2404 - binary_output_33_loss: 0.4536 - binary_output_34_loss: 0.6948 - categorical_output_loss: 0.4607 - binary_output_0_binary_accuracy: 0.6413 - binary_output_1_binary_accuracy: 0.9955 - binary_output_2_binary_accuracy: 0.5498 - binary_output_3_binary_accuracy: 0.6112 - binary_output_4_binary_accuracy: 0.7957 - binary_output_5_binary_accuracy: 0.8730 - binary_output_6_binary_accuracy: 0.9749 - binary_output_7_binary_accuracy: 0.8802 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8007 - binary_output_10_binary_accuracy: 0.7455 - binary_output_11_binary_accuracy: 0.7844 - binary_output_12_binary_accuracy: 0.9426 - binary_output_13_binary_accuracy: 0.9214 - binary_output_14_binary_accuracy: 0.9819 - binary_output_15_binary_accuracy: 0.8423 - binary_output_16_binary_accuracy: 0.7880 - binary_output_17_binary_accuracy: 0.4511 - binary_output_18_binary_accuracy: 0.7353 - binary_output_19_binary_accuracy: 0.7765 - binary_output_20_binary_accuracy: 0.8001 - binary_output_21_binary_accuracy: 0.9197 - binary_output_22_binary_accuracy: 0.9915 - binary_output_23_binary_accuracy: 0.9786 - binary_output_24_binary_accuracy: 0.9937 - binary_output_25_binary_accuracy: 0.9611 - binary_output_26_binary_accuracy: 0.7968 - binary_output_27_binary_accuracy: 0.5901 - binary_output_28_binary_accuracy: 0.7479 - binary_output_29_binary_accuracy: 0.7249 - binary_output_30_binary_accuracy: 0.9842 - binary_output_31_binary_accuracy: 0.6871 - binary_output_32_binary_accuracy: 0.9024 - binary_output_33_binary_accuracy: 0.7230 - binary_output_34_binary_accuracy: 0.5193 - categorical_output_sparse_categorical_accuracy: 0.7647\n",
      "Epoch 12/40\n",
      "22237/22237 [==============================] - 6s 249us/step - loss: 13.0105 - binary_output_0_loss: 0.5812 - binary_output_1_loss: 0.1020 - binary_output_2_loss: 0.7098 - binary_output_3_loss: 0.5636 - binary_output_4_loss: 0.3738 - binary_output_5_loss: 0.3285 - binary_output_6_loss: 0.2829 - binary_output_7_loss: 0.2865 - binary_output_8_loss: 0.0023 - binary_output_9_loss: 0.3666 - binary_output_10_loss: 0.4652 - binary_output_11_loss: 0.3977 - binary_output_12_loss: 0.1640 - binary_output_13_loss: 0.3035 - binary_output_14_loss: 0.2006 - binary_output_15_loss: 0.3318 - binary_output_16_loss: 0.3911 - binary_output_17_loss: 0.7329 - binary_output_18_loss: 0.4362 - binary_output_19_loss: 0.4036 - binary_output_20_loss: 0.3420 - binary_output_21_loss: 0.2555 - binary_output_22_loss: 0.1312 - binary_output_23_loss: 0.1757 - binary_output_24_loss: 0.1024 - binary_output_25_loss: 0.1750 - binary_output_26_loss: 0.3584 - binary_output_27_loss: 0.6101 - binary_output_28_loss: 0.4397 - binary_output_29_loss: 0.4840 - binary_output_30_loss: 0.1860 - binary_output_31_loss: 0.5033 - binary_output_32_loss: 0.2383 - binary_output_33_loss: 0.4491 - binary_output_34_loss: 0.6853 - categorical_output_loss: 0.4551 - binary_output_0_binary_accuracy: 0.6538 - binary_output_1_binary_accuracy: 0.9955 - binary_output_2_binary_accuracy: 0.5697 - binary_output_3_binary_accuracy: 0.6285 - binary_output_4_binary_accuracy: 0.7954 - binary_output_5_binary_accuracy: 0.8737 - binary_output_6_binary_accuracy: 0.9659 - binary_output_7_binary_accuracy: 0.8847 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7985 - binary_output_10_binary_accuracy: 0.7441 - binary_output_11_binary_accuracy: 0.7873 - binary_output_12_binary_accuracy: 0.9422 - binary_output_13_binary_accuracy: 0.9186 - binary_output_14_binary_accuracy: 0.9812 - binary_output_15_binary_accuracy: 0.8475 - binary_output_16_binary_accuracy: 0.7899 - binary_output_17_binary_accuracy: 0.4651 - binary_output_18_binary_accuracy: 0.7337 - binary_output_19_binary_accuracy: 0.7801 - binary_output_20_binary_accuracy: 0.8055 - binary_output_21_binary_accuracy: 0.9199 - binary_output_22_binary_accuracy: 0.9912 - binary_output_23_binary_accuracy: 0.9738 - binary_output_24_binary_accuracy: 0.9936 - binary_output_25_binary_accuracy: 0.9626 - binary_output_26_binary_accuracy: 0.8015 - binary_output_27_binary_accuracy: 0.6150 - binary_output_28_binary_accuracy: 0.7492 - binary_output_29_binary_accuracy: 0.7250 - binary_output_30_binary_accuracy: 0.9838 - binary_output_31_binary_accuracy: 0.6981 - binary_output_32_binary_accuracy: 0.9061 - binary_output_33_binary_accuracy: 0.7224 - binary_output_34_binary_accuracy: 0.5390 - categorical_output_sparse_categorical_accuracy: 0.7699\n",
      "Epoch 13/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  512/22237 [..............................] - ETA: 5s - loss: 12.8533 - binary_output_0_loss: 0.5503 - binary_output_1_loss: 0.0578 - binary_output_2_loss: 0.6556 - binary_output_3_loss: 0.4456 - binary_output_4_loss: 0.4163 - binary_output_5_loss: 0.3193 - binary_output_6_loss: 0.2608 - binary_output_7_loss: 0.2801 - binary_output_8_loss: 0.0017 - binary_output_9_loss: 0.4345 - binary_output_10_loss: 0.4155 - binary_output_11_loss: 0.4066 - binary_output_12_loss: 0.1501 - binary_output_13_loss: 0.3860 - binary_output_14_loss: 0.2040 - binary_output_15_loss: 0.2971 - binary_output_16_loss: 0.4010 - binary_output_17_loss: 0.7363 - binary_output_18_loss: 0.4940 - binary_output_19_loss: 0.3341 - binary_output_20_loss: 0.3854 - binary_output_21_loss: 0.3046 - binary_output_22_loss: 0.0841 - binary_output_23_loss: 0.2279 - binary_output_24_loss: 0.1553 - binary_output_25_loss: 0.1866 - binary_output_26_loss: 0.4183 - binary_output_27_loss: 0.6011 - binary_output_28_loss: 0.3095 - binary_output_29_loss: 0.4955 - binary_output_30_loss: 0.1047 - binary_output_31_loss: 0.5186 - binary_output_32_loss: 0.2621 - binary_output_33_loss: 0.3934 - binary_output_34_loss: 0.6624 - categorical_output_loss: 0.4972 - binary_output_0_binary_accuracy: 0.6562 - binary_output_1_binary_accuracy: 0.9980 - binary_output_2_binary_accuracy: 0.5703 - binary_output_3_binary_accuracy: 0.6172 - binary_output_4_binary_accuracy: 0.7832 - binary_output_5_binary_accuracy: 0.9082 - binary_output_6_binary_accuracy: 0.9727 - binary_output_7_binary_accuracy: 0.8867 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7969 - binary_output_10_binary_accuracy: 0.7480 - binary_output_11_binary_accuracy: 0.8184 - binary_output_12_binary_accuracy: 0.9570 - binary_output_13_binary_accuracy: 0.9395 - binary_output_14_binary_accuracy: 0.9844 - binary_output_15_binary_accuracy: 0.8691 - binary_output_16_binary_accuracy: 0.8477 - binary_output_17_binary_accuracy: 0.4512 - binary_output_18_binary_accuracy: 0.8223 - binary_output_19_binary_accuracy: 0.8359 - binary_output_20_binary_accuracy: 0.8516 - binary_output_21_binary_accuracy: 0.9473 - binary_output_22_binary_accuracy: 0.9902 - binary_output_23_binary_accuracy: 0.9668 - binary_output_24_binary_accuracy: 0.9863 - binary_output_25_binary_accuracy: 0.9727 - binary_output_26_binary_accuracy: 0.8633 - binary_output_27_binary_accuracy: 0.7285 - binary_output_28_binary_accuracy: 0.8301 - binary_output_29_binary_accuracy: 0.8145 - binary_output_30_binary_accuracy: 0.9883 - binary_output_31_binary_accuracy: 0.8145 - binary_output_32_binary_accuracy: 0.9238 - binary_output_33_binary_accuracy: 0.7773 - binary_output_34_binary_accuracy: 0.5508 - categorical_output_sparse_categorical_accuracy: 0.7305\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 1024/22237 [>.............................] - ETA: 5s - loss: 12.8093 - binary_output_0_loss: 0.5793 - binary_output_1_loss: 0.0963 - binary_output_2_loss: 0.6761 - binary_output_3_loss: 0.4944 - binary_output_4_loss: 0.3758 - binary_output_5_loss: 0.3267 - binary_output_6_loss: 0.2741 - binary_output_7_loss: 0.2495 - binary_output_8_loss: 0.0020 - binary_output_9_loss: 0.3728 - binary_output_10_loss: 0.4297 - binary_output_11_loss: 0.3778 - binary_output_12_loss: 0.1924 - binary_output_13_loss: 0.3143 - binary_output_14_loss: 0.1951 - binary_output_15_loss: 0.3092 - binary_output_16_loss: 0.3996 - binary_output_17_loss: 0.7567 - binary_output_18_loss: 0.4697 - binary_output_19_loss: 0.3693 - binary_output_20_loss: 0.3469 - binary_output_21_loss: 0.3152 - binary_output_22_loss: 0.1562 - binary_output_23_loss: 0.2095 - binary_output_24_loss: 0.1087 - binary_output_25_loss: 0.1526 - binary_output_26_loss: 0.4112 - binary_output_27_loss: 0.5980 - binary_output_28_loss: 0.3638 - binary_output_29_loss: 0.4832 - binary_output_30_loss: 0.1280 - binary_output_31_loss: 0.4986 - binary_output_32_loss: 0.2503 - binary_output_33_loss: 0.4263 - binary_output_34_loss: 0.6722 - categorical_output_loss: 0.4279 - binary_output_0_binary_accuracy: 0.6826 - binary_output_1_binary_accuracy: 0.9951 - binary_output_2_binary_accuracy: 0.5771 - binary_output_3_binary_accuracy: 0.6064 - binary_output_4_binary_accuracy: 0.7656 - binary_output_5_binary_accuracy: 0.8760 - binary_output_6_binary_accuracy: 0.9648 - binary_output_7_binary_accuracy: 0.8740 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7979 - binary_output_10_binary_accuracy: 0.7461 - binary_output_11_binary_accuracy: 0.7871 - binary_output_12_binary_accuracy: 0.9414 - binary_output_13_binary_accuracy: 0.9209 - binary_output_14_binary_accuracy: 0.9795 - binary_output_15_binary_accuracy: 0.8369 - binary_output_16_binary_accuracy: 0.8027 - binary_output_17_binary_accuracy: 0.4463 - binary_output_18_binary_accuracy: 0.7500 - binary_output_19_binary_accuracy: 0.7842 - binary_output_20_binary_accuracy: 0.7949 - binary_output_21_binary_accuracy: 0.9082 - binary_output_22_binary_accuracy: 0.9844 - binary_output_23_binary_accuracy: 0.9609 - binary_output_24_binary_accuracy: 0.9912 - binary_output_25_binary_accuracy: 0.9697 - binary_output_26_binary_accuracy: 0.8125 - binary_output_27_binary_accuracy: 0.6592 - binary_output_28_binary_accuracy: 0.7812 - binary_output_29_binary_accuracy: 0.7695 - binary_output_30_binary_accuracy: 0.9795 - binary_output_31_binary_accuracy: 0.7461 - binary_output_32_binary_accuracy: 0.8955 - binary_output_33_binary_accuracy: 0.7285 - binary_output_34_binary_accuracy: 0.5557 - categorical_output_sparse_categorical_accuracy: 0.7656"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22237/22237 [==============================] - 5s 246us/step - loss: 12.7659 - binary_output_0_loss: 0.5775 - binary_output_1_loss: 0.0976 - binary_output_2_loss: 0.6977 - binary_output_3_loss: 0.5552 - binary_output_4_loss: 0.3677 - binary_output_5_loss: 0.3212 - binary_output_6_loss: 0.2730 - binary_output_7_loss: 0.2756 - binary_output_8_loss: 0.0019 - binary_output_9_loss: 0.3646 - binary_output_10_loss: 0.4569 - binary_output_11_loss: 0.3947 - binary_output_12_loss: 0.1561 - binary_output_13_loss: 0.2990 - binary_output_14_loss: 0.1946 - binary_output_15_loss: 0.3300 - binary_output_16_loss: 0.3851 - binary_output_17_loss: 0.7261 - binary_output_18_loss: 0.4292 - binary_output_19_loss: 0.3951 - binary_output_20_loss: 0.3375 - binary_output_21_loss: 0.2472 - binary_output_22_loss: 0.1289 - binary_output_23_loss: 0.1705 - binary_output_24_loss: 0.1024 - binary_output_25_loss: 0.1697 - binary_output_26_loss: 0.3538 - binary_output_27_loss: 0.5940 - binary_output_28_loss: 0.4331 - binary_output_29_loss: 0.4694 - binary_output_30_loss: 0.1821 - binary_output_31_loss: 0.5013 - binary_output_32_loss: 0.2358 - binary_output_33_loss: 0.4421 - binary_output_34_loss: 0.6694 - categorical_output_loss: 0.4462 - binary_output_0_binary_accuracy: 0.6569 - binary_output_1_binary_accuracy: 0.9952 - binary_output_2_binary_accuracy: 0.5794 - binary_output_3_binary_accuracy: 0.6321 - binary_output_4_binary_accuracy: 0.8018 - binary_output_5_binary_accuracy: 0.8718 - binary_output_6_binary_accuracy: 0.9642 - binary_output_7_binary_accuracy: 0.8878 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8009 - binary_output_10_binary_accuracy: 0.7467 - binary_output_11_binary_accuracy: 0.7864 - binary_output_12_binary_accuracy: 0.9463 - binary_output_13_binary_accuracy: 0.9168 - binary_output_14_binary_accuracy: 0.9785 - binary_output_15_binary_accuracy: 0.8436 - binary_output_16_binary_accuracy: 0.7944 - binary_output_17_binary_accuracy: 0.4698 - binary_output_18_binary_accuracy: 0.7465 - binary_output_19_binary_accuracy: 0.7826 - binary_output_20_binary_accuracy: 0.8085 - binary_output_21_binary_accuracy: 0.9147 - binary_output_22_binary_accuracy: 0.9909 - binary_output_23_binary_accuracy: 0.9712 - binary_output_24_binary_accuracy: 0.9933 - binary_output_25_binary_accuracy: 0.9593 - binary_output_26_binary_accuracy: 0.8038 - binary_output_27_binary_accuracy: 0.6390 - binary_output_28_binary_accuracy: 0.7594 - binary_output_29_binary_accuracy: 0.7362 - binary_output_30_binary_accuracy: 0.9808 - binary_output_31_binary_accuracy: 0.7151 - binary_output_32_binary_accuracy: 0.8991 - binary_output_33_binary_accuracy: 0.7250 - binary_output_34_binary_accuracy: 0.5493 - categorical_output_sparse_categorical_accuracy: 0.7725\n",
      "Epoch 14/40\n",
      "22237/22237 [==============================] - 5s 247us/step - loss: 12.4843 - binary_output_0_loss: 0.5573 - binary_output_1_loss: 0.0987 - binary_output_2_loss: 0.6744 - binary_output_3_loss: 0.5443 - binary_output_4_loss: 0.3612 - binary_output_5_loss: 0.3151 - binary_output_6_loss: 0.2727 - binary_output_7_loss: 0.2589 - binary_output_8_loss: 0.0017 - binary_output_9_loss: 0.3588 - binary_output_10_loss: 0.4512 - binary_output_11_loss: 0.3858 - binary_output_12_loss: 0.1554 - binary_output_13_loss: 0.2917 - binary_output_14_loss: 0.1932 - binary_output_15_loss: 0.3165 - binary_output_16_loss: 0.3762 - binary_output_17_loss: 0.7096 - binary_output_18_loss: 0.4124 - binary_output_19_loss: 0.3910 - binary_output_20_loss: 0.3308 - binary_output_21_loss: 0.2430 - binary_output_22_loss: 0.1267 - binary_output_23_loss: 0.1631 - binary_output_24_loss: 0.0976 - binary_output_25_loss: 0.1676 - binary_output_26_loss: 0.3446 - binary_output_27_loss: 0.5720 - binary_output_28_loss: 0.4286 - binary_output_29_loss: 0.4600 - binary_output_30_loss: 0.1767 - binary_output_31_loss: 0.4850 - binary_output_32_loss: 0.2279 - binary_output_33_loss: 0.4356 - binary_output_34_loss: 0.6573 - categorical_output_loss: 0.4409 - binary_output_0_binary_accuracy: 0.6688 - binary_output_1_binary_accuracy: 0.9952 - binary_output_2_binary_accuracy: 0.6009 - binary_output_3_binary_accuracy: 0.6343 - binary_output_4_binary_accuracy: 0.8027 - binary_output_5_binary_accuracy: 0.8694 - binary_output_6_binary_accuracy: 0.9561 - binary_output_7_binary_accuracy: 0.8951 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7977 - binary_output_10_binary_accuracy: 0.7462 - binary_output_11_binary_accuracy: 0.7915 - binary_output_12_binary_accuracy: 0.9473 - binary_output_13_binary_accuracy: 0.9137 - binary_output_14_binary_accuracy: 0.9773 - binary_output_15_binary_accuracy: 0.8424 - binary_output_16_binary_accuracy: 0.7960 - binary_output_17_binary_accuracy: 0.4839 - binary_output_18_binary_accuracy: 0.7558 - binary_output_19_binary_accuracy: 0.7848 - binary_output_20_binary_accuracy: 0.8078 - binary_output_21_binary_accuracy: 0.9202 - binary_output_22_binary_accuracy: 0.9898 - binary_output_23_binary_accuracy: 0.9727 - binary_output_24_binary_accuracy: 0.9926 - binary_output_25_binary_accuracy: 0.9608 - binary_output_26_binary_accuracy: 0.8046 - binary_output_27_binary_accuracy: 0.6549 - binary_output_28_binary_accuracy: 0.7585 - binary_output_29_binary_accuracy: 0.7359 - binary_output_30_binary_accuracy: 0.9817 - binary_output_31_binary_accuracy: 0.7155 - binary_output_32_binary_accuracy: 0.8963 - binary_output_33_binary_accuracy: 0.7209 - binary_output_34_binary_accuracy: 0.5645 - categorical_output_sparse_categorical_accuracy: 0.7731\n",
      "Epoch 15/40\n",
      " 1024/22237 [>.............................] - ETA: 5s - loss: 12.1901 - binary_output_0_loss: 0.5308 - binary_output_1_loss: 0.1104 - binary_output_2_loss: 0.6337 - binary_output_3_loss: 0.5364 - binary_output_4_loss: 0.3609 - binary_output_5_loss: 0.3171 - binary_output_6_loss: 0.2323 - binary_output_7_loss: 0.2135 - binary_output_8_loss: 0.0016 - binary_output_9_loss: 0.3190 - binary_output_10_loss: 0.4753 - binary_output_11_loss: 0.4360 - binary_output_12_loss: 0.1663 - binary_output_13_loss: 0.2806 - binary_output_14_loss: 0.1946 - binary_output_15_loss: 0.3334 - binary_output_16_loss: 0.3311 - binary_output_17_loss: 0.6821 - binary_output_18_loss: 0.3720 - binary_output_19_loss: 0.4337 - binary_output_20_loss: 0.3343 - binary_output_21_loss: 0.2582 - binary_output_22_loss: 0.1214 - binary_output_23_loss: 0.2105 - binary_output_24_loss: 0.0921 - binary_output_25_loss: 0.1780 - binary_output_26_loss: 0.2587 - binary_output_27_loss: 0.5697 - binary_output_28_loss: 0.4134 - binary_output_29_loss: 0.4428 - binary_output_30_loss: 0.1306 - binary_output_31_loss: 0.4436 - binary_output_32_loss: 0.1921 - binary_output_33_loss: 0.3859 - binary_output_34_loss: 0.6620 - categorical_output_loss: 0.5362 - binary_output_0_binary_accuracy: 0.6807 - binary_output_1_binary_accuracy: 0.9941 - binary_output_2_binary_accuracy: 0.6201 - binary_output_3_binary_accuracy: 0.6279 - binary_output_4_binary_accuracy: 0.7881 - binary_output_5_binary_accuracy: 0.8799 - binary_output_6_binary_accuracy: 0.9648 - binary_output_7_binary_accuracy: 0.8955 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7773 - binary_output_10_binary_accuracy: 0.7480 - binary_output_11_binary_accuracy: 0.7861 - binary_output_12_binary_accuracy: 0.9580 - binary_output_13_binary_accuracy: 0.9072 - binary_output_14_binary_accuracy: 0.9668 - binary_output_15_binary_accuracy: 0.8516 - binary_output_16_binary_accuracy: 0.8242 - binary_output_17_binary_accuracy: 0.5293 - binary_output_18_binary_accuracy: 0.7773 - binary_output_19_binary_accuracy: 0.7842 - binary_output_20_binary_accuracy: 0.8350 - binary_output_21_binary_accuracy: 0.9043 - binary_output_22_binary_accuracy: 0.9883 - binary_output_23_binary_accuracy: 0.9639 - binary_output_24_binary_accuracy: 0.9912 - binary_output_25_binary_accuracy: 0.9600 - binary_output_26_binary_accuracy: 0.8271 - binary_output_27_binary_accuracy: 0.6699 - binary_output_28_binary_accuracy: 0.7812 - binary_output_29_binary_accuracy: 0.7842 - binary_output_30_binary_accuracy: 0.9814 - binary_output_31_binary_accuracy: 0.7627 - binary_output_32_binary_accuracy: 0.9092 - binary_output_33_binary_accuracy: 0.7539 - binary_output_34_binary_accuracy: 0.5918 - categorical_output_sparse_categorical_accuracy: 0.774422237/22237 [==============================] - 6s 251us/step - loss: 12.2860 - binary_output_0_loss: 0.5533 - binary_output_1_loss: 0.0973 - binary_output_2_loss: 0.6628 - binary_output_3_loss: 0.5374 - binary_output_4_loss: 0.3538 - binary_output_5_loss: 0.3073 - binary_output_6_loss: 0.2653 - binary_output_7_loss: 0.2478 - binary_output_8_loss: 0.0015 - binary_output_9_loss: 0.3572 - binary_output_10_loss: 0.4480 - binary_output_11_loss: 0.3797 - binary_output_12_loss: 0.1501 - binary_output_13_loss: 0.2880 - binary_output_14_loss: 0.1892 - binary_output_15_loss: 0.3148 - binary_output_16_loss: 0.3773 - binary_output_17_loss: 0.7022 - binary_output_18_loss: 0.4041 - binary_output_19_loss: 0.3758 - binary_output_20_loss: 0.3238 - binary_output_21_loss: 0.2413 - binary_output_22_loss: 0.1251 - binary_output_23_loss: 0.1656 - binary_output_24_loss: 0.0997 - binary_output_25_loss: 0.1608 - binary_output_26_loss: 0.3340 - binary_output_27_loss: 0.5519 - binary_output_28_loss: 0.4149 - binary_output_29_loss: 0.4513 - binary_output_30_loss: 0.1720 - binary_output_31_loss: 0.4734 - binary_output_32_loss: 0.2274 - binary_output_33_loss: 0.4271 - binary_output_34_loss: 0.6472 - categorical_output_loss: 0.4362 - binary_output_0_binary_accuracy: 0.6773 - binary_output_1_binary_accuracy: 0.9944 - binary_output_2_binary_accuracy: 0.6080 - binary_output_3_binary_accuracy: 0.6376 - binary_output_4_binary_accuracy: 0.8027 - binary_output_5_binary_accuracy: 0.8640 - binary_output_6_binary_accuracy: 0.9483 - binary_output_7_binary_accuracy: 0.9006 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7982 - binary_output_10_binary_accuracy: 0.7472 - binary_output_11_binary_accuracy: 0.7913 - binary_output_12_binary_accuracy: 0.9534 - binary_output_13_binary_accuracy: 0.9068 - binary_output_14_binary_accuracy: 0.9711 - binary_output_15_binary_accuracy: 0.8418 - binary_output_16_binary_accuracy: 0.8087 - binary_output_17_binary_accuracy: 0.4948 - binary_output_18_binary_accuracy: 0.7632 - binary_output_19_binary_accuracy: 0.7956 - binary_output_20_binary_accuracy: 0.8163 - binary_output_21_binary_accuracy: 0.9099 - binary_output_22_binary_accuracy: 0.9898 - binary_output_23_binary_accuracy: 0.9667 - binary_output_24_binary_accuracy: 0.9922 - binary_output_25_binary_accuracy: 0.9563 - binary_output_26_binary_accuracy: 0.8121 - binary_output_27_binary_accuracy: 0.6672 - binary_output_28_binary_accuracy: 0.7637 - binary_output_29_binary_accuracy: 0.7484 - binary_output_30_binary_accuracy: 0.9774 - binary_output_31_binary_accuracy: 0.7246 - binary_output_32_binary_accuracy: 0.8989 - binary_output_33_binary_accuracy: 0.7265 - binary_output_34_binary_accuracy: 0.5664 - categorical_output_sparse_categorical_accuracy: 0.7759\n",
      "Epoch 16/40\n",
      "22237/22237 [==============================] - 6s 255us/step - loss: 12.0854 - binary_output_0_loss: 0.5346 - binary_output_1_loss: 0.0944 - binary_output_2_loss: 0.6443 - binary_output_3_loss: 0.5321 - binary_output_4_loss: 0.3496 - binary_output_5_loss: 0.3096 - binary_output_6_loss: 0.2603 - binary_output_7_loss: 0.2376 - binary_output_8_loss: 0.0013 - binary_output_9_loss: 0.3494 - binary_output_10_loss: 0.4489 - binary_output_11_loss: 0.3773 - binary_output_12_loss: 0.1436 - binary_output_13_loss: 0.2817 - binary_output_14_loss: 0.1862 - binary_output_15_loss: 0.3108 - binary_output_16_loss: 0.3706 - binary_output_17_loss: 0.6947 - binary_output_18_loss: 0.4006 - binary_output_19_loss: 0.3753 - binary_output_20_loss: 0.3243 - binary_output_21_loss: 0.2335 - binary_output_22_loss: 0.1231 - binary_output_23_loss: 0.1610 - binary_output_24_loss: 0.0936 - binary_output_25_loss: 0.1675 - binary_output_26_loss: 0.3332 - binary_output_27_loss: 0.5409 - binary_output_28_loss: 0.4102 - binary_output_29_loss: 0.4392 - binary_output_30_loss: 0.1681 - binary_output_31_loss: 0.4714 - binary_output_32_loss: 0.2242 - binary_output_33_loss: 0.4250 - binary_output_34_loss: 0.6365 - categorical_output_loss: 0.4313 - binary_output_0_binary_accuracy: 0.6834 - binary_output_1_binary_accuracy: 0.9946 - binary_output_2_binary_accuracy: 0.6258 - binary_output_3_binary_accuracy: 0.6431 - binary_output_4_binary_accuracy: 0.8127 - binary_output_5_binary_accuracy: 0.8678 - binary_output_6_binary_accuracy: 0.9469 - binary_output_7_binary_accuracy: 0.9070 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8075 - binary_output_10_binary_accuracy: 0.7456 - binary_output_11_binary_accuracy: 0.7950 - binary_output_12_binary_accuracy: 0.9516 - binary_output_13_binary_accuracy: 0.9053 - binary_output_14_binary_accuracy: 0.9759 - binary_output_15_binary_accuracy: 0.8468 - binary_output_16_binary_accuracy: 0.8042 - binary_output_17_binary_accuracy: 0.5031 - binary_output_18_binary_accuracy: 0.7616 - binary_output_19_binary_accuracy: 0.7943 - binary_output_20_binary_accuracy: 0.8178 - binary_output_21_binary_accuracy: 0.9165 - binary_output_22_binary_accuracy: 0.9900 - binary_output_23_binary_accuracy: 0.9645 - binary_output_24_binary_accuracy: 0.9924 - binary_output_25_binary_accuracy: 0.9578 - binary_output_26_binary_accuracy: 0.8074 - binary_output_27_binary_accuracy: 0.6767 - binary_output_28_binary_accuracy: 0.7668 - binary_output_29_binary_accuracy: 0.7501 - binary_output_30_binary_accuracy: 0.9776 - binary_output_31_binary_accuracy: 0.7255 - binary_output_32_binary_accuracy: 0.8970 - binary_output_33_binary_accuracy: 0.7243 - binary_output_34_binary_accuracy: 0.5874 - categorical_output_sparse_categorical_accuracy: 0.7751\n",
      "Epoch 17/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  512/22237 [..............................] - ETA: 5s - loss: 12.6648 - binary_output_0_loss: 0.5923 - binary_output_1_loss: 0.1505 - binary_output_2_loss: 0.6270 - binary_output_3_loss: 0.4833 - binary_output_4_loss: 0.2623 - binary_output_5_loss: 0.4285 - binary_output_6_loss: 0.2510 - binary_output_7_loss: 0.1773 - binary_output_8_loss: 0.0018 - binary_output_9_loss: 0.3059 - binary_output_10_loss: 0.4681 - binary_output_11_loss: 0.4946 - binary_output_12_loss: 0.1949 - binary_output_13_loss: 0.4208 - binary_output_14_loss: 0.1820 - binary_output_15_loss: 0.3015 - binary_output_16_loss: 0.3975 - binary_output_17_loss: 0.6604 - binary_output_18_loss: 0.4055 - binary_output_19_loss: 0.4683 - binary_output_20_loss: 0.3623 - binary_output_21_loss: 0.3429 - binary_output_22_loss: 0.1735 - binary_output_23_loss: 0.2368 - binary_output_24_loss: 0.0386 - binary_output_25_loss: 0.1411 - binary_output_26_loss: 0.3403 - binary_output_27_loss: 0.5324 - binary_output_28_loss: 0.4751 - binary_output_29_loss: 0.3988 - binary_output_30_loss: 0.1851 - binary_output_31_loss: 0.4885 - binary_output_32_loss: 0.2255 - binary_output_33_loss: 0.4018 - binary_output_34_loss: 0.6747 - categorical_output_loss: 0.3741 - binary_output_0_binary_accuracy: 0.6035 - binary_output_1_binary_accuracy: 0.9922 - binary_output_2_binary_accuracy: 0.6113 - binary_output_3_binary_accuracy: 0.6289 - binary_output_4_binary_accuracy: 0.7891 - binary_output_5_binary_accuracy: 0.8145 - binary_output_6_binary_accuracy: 0.9453 - binary_output_7_binary_accuracy: 0.9375 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8047 - binary_output_10_binary_accuracy: 0.7168 - binary_output_11_binary_accuracy: 0.7480 - binary_output_12_binary_accuracy: 0.9531 - binary_output_13_binary_accuracy: 0.9199 - binary_output_14_binary_accuracy: 0.9609 - binary_output_15_binary_accuracy: 0.8008 - binary_output_16_binary_accuracy: 0.7871 - binary_output_17_binary_accuracy: 0.4668 - binary_output_18_binary_accuracy: 0.7207 - binary_output_19_binary_accuracy: 0.7734 - binary_output_20_binary_accuracy: 0.7754 - binary_output_21_binary_accuracy: 0.8711 - binary_output_22_binary_accuracy: 0.9902 - binary_output_23_binary_accuracy: 0.9551 - binary_output_24_binary_accuracy: 0.9980 - binary_output_25_binary_accuracy: 0.9316 - binary_output_26_binary_accuracy: 0.7793 - binary_output_27_binary_accuracy: 0.6699 - binary_output_28_binary_accuracy: 0.7559 - binary_output_29_binary_accuracy: 0.7812 - binary_output_30_binary_accuracy: 0.9766 - binary_output_31_binary_accuracy: 0.6523 - binary_output_32_binary_accuracy: 0.8770 - binary_output_33_binary_accuracy: 0.7031 - binary_output_34_binary_accuracy: 0.5410 - categorical_output_sparse_categorical_accuracy: 0.8008\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 1024/22237 [>.............................] - ETA: 5s - loss: 12.3584 - binary_output_0_loss: 0.5619 - binary_output_1_loss: 0.0990 - binary_output_2_loss: 0.6233 - binary_output_3_loss: 0.5332 - binary_output_4_loss: 0.3392 - binary_output_5_loss: 0.4058 - binary_output_6_loss: 0.3228 - binary_output_7_loss: 0.1985 - binary_output_8_loss: 0.0016 - binary_output_9_loss: 0.3593 - binary_output_10_loss: 0.4237 - binary_output_11_loss: 0.4482 - binary_output_12_loss: 0.1856 - binary_output_13_loss: 0.3221 - binary_output_14_loss: 0.1902 - binary_output_15_loss: 0.2893 - binary_output_16_loss: 0.3675 - binary_output_17_loss: 0.6706 - binary_output_18_loss: 0.3929 - binary_output_19_loss: 0.4239 - binary_output_20_loss: 0.3438 - binary_output_21_loss: 0.2690 - binary_output_22_loss: 0.2206 - binary_output_23_loss: 0.2087 - binary_output_24_loss: 0.0781 - binary_output_25_loss: 0.1397 - binary_output_26_loss: 0.3182 - binary_output_27_loss: 0.5134 - binary_output_28_loss: 0.4244 - binary_output_29_loss: 0.4092 - binary_output_30_loss: 0.1781 - binary_output_31_loss: 0.4640 - binary_output_32_loss: 0.1975 - binary_output_33_loss: 0.3884 - binary_output_34_loss: 0.6671 - categorical_output_loss: 0.3796 - binary_output_0_binary_accuracy: 0.6230 - binary_output_1_binary_accuracy: 0.9941 - binary_output_2_binary_accuracy: 0.6309 - binary_output_3_binary_accuracy: 0.6621 - binary_output_4_binary_accuracy: 0.8057 - binary_output_5_binary_accuracy: 0.8438 - binary_output_6_binary_accuracy: 0.9434 - binary_output_7_binary_accuracy: 0.9297 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8174 - binary_output_10_binary_accuracy: 0.7412 - binary_output_11_binary_accuracy: 0.7627 - binary_output_12_binary_accuracy: 0.9521 - binary_output_13_binary_accuracy: 0.9277 - binary_output_14_binary_accuracy: 0.9658 - binary_output_15_binary_accuracy: 0.8242 - binary_output_16_binary_accuracy: 0.7969 - binary_output_17_binary_accuracy: 0.4854 - binary_output_18_binary_accuracy: 0.7363 - binary_output_19_binary_accuracy: 0.7900 - binary_output_20_binary_accuracy: 0.7979 - binary_output_21_binary_accuracy: 0.8887 - binary_output_22_binary_accuracy: 0.9854 - binary_output_23_binary_accuracy: 0.9629 - binary_output_24_binary_accuracy: 0.9951 - binary_output_25_binary_accuracy: 0.9424 - binary_output_26_binary_accuracy: 0.7949 - binary_output_27_binary_accuracy: 0.6836 - binary_output_28_binary_accuracy: 0.7725 - binary_output_29_binary_accuracy: 0.7744 - binary_output_30_binary_accuracy: 0.9766 - binary_output_31_binary_accuracy: 0.6816 - binary_output_32_binary_accuracy: 0.8916 - binary_output_33_binary_accuracy: 0.7178 - binary_output_34_binary_accuracy: 0.5352 - categorical_output_sparse_categorical_accuracy: 0.7891"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22237/22237 [==============================] - 5s 246us/step - loss: 11.8216 - binary_output_0_loss: 0.5245 - binary_output_1_loss: 0.0926 - binary_output_2_loss: 0.6285 - binary_output_3_loss: 0.5253 - binary_output_4_loss: 0.3388 - binary_output_5_loss: 0.2965 - binary_output_6_loss: 0.2536 - binary_output_7_loss: 0.2308 - binary_output_8_loss: 0.0011 - binary_output_9_loss: 0.3489 - binary_output_10_loss: 0.4388 - binary_output_11_loss: 0.3721 - binary_output_12_loss: 0.1411 - binary_output_13_loss: 0.2773 - binary_output_14_loss: 0.1778 - binary_output_15_loss: 0.3067 - binary_output_16_loss: 0.3647 - binary_output_17_loss: 0.6902 - binary_output_18_loss: 0.3825 - binary_output_19_loss: 0.3680 - binary_output_20_loss: 0.3164 - binary_output_21_loss: 0.2346 - binary_output_22_loss: 0.1183 - binary_output_23_loss: 0.1536 - binary_output_24_loss: 0.0926 - binary_output_25_loss: 0.1587 - binary_output_26_loss: 0.3206 - binary_output_27_loss: 0.5182 - binary_output_28_loss: 0.4025 - binary_output_29_loss: 0.4351 - binary_output_30_loss: 0.1669 - binary_output_31_loss: 0.4583 - binary_output_32_loss: 0.2164 - binary_output_33_loss: 0.4178 - binary_output_34_loss: 0.6341 - categorical_output_loss: 0.4184 - binary_output_0_binary_accuracy: 0.6878 - binary_output_1_binary_accuracy: 0.9940 - binary_output_2_binary_accuracy: 0.6366 - binary_output_3_binary_accuracy: 0.6476 - binary_output_4_binary_accuracy: 0.8107 - binary_output_5_binary_accuracy: 0.8660 - binary_output_6_binary_accuracy: 0.9399 - binary_output_7_binary_accuracy: 0.9091 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8035 - binary_output_10_binary_accuracy: 0.7467 - binary_output_11_binary_accuracy: 0.7937 - binary_output_12_binary_accuracy: 0.9537 - binary_output_13_binary_accuracy: 0.9148 - binary_output_14_binary_accuracy: 0.9699 - binary_output_15_binary_accuracy: 0.8435 - binary_output_16_binary_accuracy: 0.8066 - binary_output_17_binary_accuracy: 0.5142 - binary_output_18_binary_accuracy: 0.7741 - binary_output_19_binary_accuracy: 0.7985 - binary_output_20_binary_accuracy: 0.8161 - binary_output_21_binary_accuracy: 0.9090 - binary_output_22_binary_accuracy: 0.9901 - binary_output_23_binary_accuracy: 0.9645 - binary_output_24_binary_accuracy: 0.9924 - binary_output_25_binary_accuracy: 0.9546 - binary_output_26_binary_accuracy: 0.8165 - binary_output_27_binary_accuracy: 0.6941 - binary_output_28_binary_accuracy: 0.7738 - binary_output_29_binary_accuracy: 0.7550 - binary_output_30_binary_accuracy: 0.9739 - binary_output_31_binary_accuracy: 0.7269 - binary_output_32_binary_accuracy: 0.8965 - binary_output_33_binary_accuracy: 0.7295 - binary_output_34_binary_accuracy: 0.5876 - categorical_output_sparse_categorical_accuracy: 0.7780\n",
      "Epoch 18/40\n",
      "22237/22237 [==============================] - 5s 244us/step - loss: 11.6604 - binary_output_0_loss: 0.5182 - binary_output_1_loss: 0.0945 - binary_output_2_loss: 0.6128 - binary_output_3_loss: 0.5170 - binary_output_4_loss: 0.3388 - binary_output_5_loss: 0.2970 - binary_output_6_loss: 0.2473 - binary_output_7_loss: 0.2180 - binary_output_8_loss: 0.0011 - binary_output_9_loss: 0.3394 - binary_output_10_loss: 0.4300 - binary_output_11_loss: 0.3622 - binary_output_12_loss: 0.1352 - binary_output_13_loss: 0.2761 - binary_output_14_loss: 0.1757 - binary_output_15_loss: 0.2953 - binary_output_16_loss: 0.3572 - binary_output_17_loss: 0.6855 - binary_output_18_loss: 0.3810 - binary_output_19_loss: 0.3640 - binary_output_20_loss: 0.3122 - binary_output_21_loss: 0.2292 - binary_output_22_loss: 0.1187 - binary_output_23_loss: 0.1516 - binary_output_24_loss: 0.0923 - binary_output_25_loss: 0.1581 - binary_output_26_loss: 0.3215 - binary_output_27_loss: 0.5089 - binary_output_28_loss: 0.3955 - binary_output_29_loss: 0.4265 - binary_output_30_loss: 0.1650 - binary_output_31_loss: 0.4545 - binary_output_32_loss: 0.2180 - binary_output_33_loss: 0.4100 - binary_output_34_loss: 0.6262 - categorical_output_loss: 0.4178 - binary_output_0_binary_accuracy: 0.6962 - binary_output_1_binary_accuracy: 0.9938 - binary_output_2_binary_accuracy: 0.6450 - binary_output_3_binary_accuracy: 0.6513 - binary_output_4_binary_accuracy: 0.8124 - binary_output_5_binary_accuracy: 0.8672 - binary_output_6_binary_accuracy: 0.9404 - binary_output_7_binary_accuracy: 0.9135 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8057 - binary_output_10_binary_accuracy: 0.7492 - binary_output_11_binary_accuracy: 0.8015 - binary_output_12_binary_accuracy: 0.9554 - binary_output_13_binary_accuracy: 0.9081 - binary_output_14_binary_accuracy: 0.9680 - binary_output_15_binary_accuracy: 0.8503 - binary_output_16_binary_accuracy: 0.8083 - binary_output_17_binary_accuracy: 0.5158 - binary_output_18_binary_accuracy: 0.7720 - binary_output_19_binary_accuracy: 0.7985 - binary_output_20_binary_accuracy: 0.8253 - binary_output_21_binary_accuracy: 0.9135 - binary_output_22_binary_accuracy: 0.9892 - binary_output_23_binary_accuracy: 0.9644 - binary_output_24_binary_accuracy: 0.9922 - binary_output_25_binary_accuracy: 0.9522 - binary_output_26_binary_accuracy: 0.8120 - binary_output_27_binary_accuracy: 0.7009 - binary_output_28_binary_accuracy: 0.7770 - binary_output_29_binary_accuracy: 0.7518 - binary_output_30_binary_accuracy: 0.9718 - binary_output_31_binary_accuracy: 0.7211 - binary_output_32_binary_accuracy: 0.9029 - binary_output_33_binary_accuracy: 0.7310 - binary_output_34_binary_accuracy: 0.5912 - categorical_output_sparse_categorical_accuracy: 0.7764\n",
      "Epoch 19/40\n",
      " 1024/22237 [>.............................] - ETA: 5s - loss: 11.7561 - binary_output_0_loss: 0.5371 - binary_output_1_loss: 0.0425 - binary_output_2_loss: 0.5352 - binary_output_3_loss: 0.5258 - binary_output_4_loss: 0.3398 - binary_output_5_loss: 0.3029 - binary_output_6_loss: 0.2500 - binary_output_7_loss: 0.2764 - binary_output_8_loss: 0.0010 - binary_output_9_loss: 0.3613 - binary_output_10_loss: 0.4022 - binary_output_11_loss: 0.3848 - binary_output_12_loss: 0.1439 - binary_output_13_loss: 0.2950 - binary_output_14_loss: 0.1225 - binary_output_15_loss: 0.2973 - binary_output_16_loss: 0.3873 - binary_output_17_loss: 0.6741 - binary_output_18_loss: 0.4321 - binary_output_19_loss: 0.3409 - binary_output_20_loss: 0.3134 - binary_output_21_loss: 0.2480 - binary_output_22_loss: 0.1461 - binary_output_23_loss: 0.1404 - binary_output_24_loss: 0.2118 - binary_output_25_loss: 0.1447 - binary_output_26_loss: 0.3294 - binary_output_27_loss: 0.4796 - binary_output_28_loss: 0.3723 - binary_output_29_loss: 0.4229 - binary_output_30_loss: 0.1345 - binary_output_31_loss: 0.4547 - binary_output_32_loss: 0.2463 - binary_output_33_loss: 0.4134 - binary_output_34_loss: 0.6275 - categorical_output_loss: 0.4189 - binary_output_0_binary_accuracy: 0.7148 - binary_output_1_binary_accuracy: 0.9971 - binary_output_2_binary_accuracy: 0.6904 - binary_output_3_binary_accuracy: 0.6396 - binary_output_4_binary_accuracy: 0.8281 - binary_output_5_binary_accuracy: 0.8828 - binary_output_6_binary_accuracy: 0.9365 - binary_output_7_binary_accuracy: 0.9062 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7988 - binary_output_10_binary_accuracy: 0.7354 - binary_output_11_binary_accuracy: 0.8154 - binary_output_12_binary_accuracy: 0.9551 - binary_output_13_binary_accuracy: 0.8867 - binary_output_14_binary_accuracy: 0.9766 - binary_output_15_binary_accuracy: 0.8525 - binary_output_16_binary_accuracy: 0.8252 - binary_output_17_binary_accuracy: 0.5439 - binary_output_18_binary_accuracy: 0.7969 - binary_output_19_binary_accuracy: 0.8096 - binary_output_20_binary_accuracy: 0.8389 - binary_output_21_binary_accuracy: 0.9111 - binary_output_22_binary_accuracy: 0.9883 - binary_output_23_binary_accuracy: 0.9648 - binary_output_24_binary_accuracy: 0.9912 - binary_output_25_binary_accuracy: 0.9551 - binary_output_26_binary_accuracy: 0.8242 - binary_output_27_binary_accuracy: 0.7520 - binary_output_28_binary_accuracy: 0.8242 - binary_output_29_binary_accuracy: 0.7920 - binary_output_30_binary_accuracy: 0.9746 - binary_output_31_binary_accuracy: 0.7588 - binary_output_32_binary_accuracy: 0.8926 - binary_output_33_binary_accuracy: 0.7520 - binary_output_34_binary_accuracy: 0.6318 - categorical_output_sparse_categorical_accuracy: 0.770522237/22237 [==============================] - 5s 247us/step - loss: 11.4569 - binary_output_0_loss: 0.5014 - binary_output_1_loss: 0.0909 - binary_output_2_loss: 0.5948 - binary_output_3_loss: 0.5062 - binary_output_4_loss: 0.3291 - binary_output_5_loss: 0.2880 - binary_output_6_loss: 0.2445 - binary_output_7_loss: 0.2120 - binary_output_8_loss: 9.5198e-04 - binary_output_9_loss: 0.3433 - binary_output_10_loss: 0.4240 - binary_output_11_loss: 0.3641 - binary_output_12_loss: 0.1353 - binary_output_13_loss: 0.2728 - binary_output_14_loss: 0.1740 - binary_output_15_loss: 0.2965 - binary_output_16_loss: 0.3522 - binary_output_17_loss: 0.6767 - binary_output_18_loss: 0.3756 - binary_output_19_loss: 0.3562 - binary_output_20_loss: 0.3088 - binary_output_21_loss: 0.2282 - binary_output_22_loss: 0.1175 - binary_output_23_loss: 0.1511 - binary_output_24_loss: 0.0914 - binary_output_25_loss: 0.1529 - binary_output_26_loss: 0.3183 - binary_output_27_loss: 0.4952 - binary_output_28_loss: 0.3879 - binary_output_29_loss: 0.4201 - binary_output_30_loss: 0.1615 - binary_output_31_loss: 0.4472 - binary_output_32_loss: 0.2145 - binary_output_33_loss: 0.4072 - binary_output_34_loss: 0.6126 - categorical_output_loss: 0.4087 - binary_output_0_binary_accuracy: 0.6997 - binary_output_1_binary_accuracy: 0.9933 - binary_output_2_binary_accuracy: 0.6621 - binary_output_3_binary_accuracy: 0.6615 - binary_output_4_binary_accuracy: 0.8225 - binary_output_5_binary_accuracy: 0.8671 - binary_output_6_binary_accuracy: 0.9380 - binary_output_7_binary_accuracy: 0.9159 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8037 - binary_output_10_binary_accuracy: 0.7520 - binary_output_11_binary_accuracy: 0.8000 - binary_output_12_binary_accuracy: 0.9577 - binary_output_13_binary_accuracy: 0.9066 - binary_output_14_binary_accuracy: 0.9688 - binary_output_15_binary_accuracy: 0.8520 - binary_output_16_binary_accuracy: 0.8174 - binary_output_17_binary_accuracy: 0.5211 - binary_output_18_binary_accuracy: 0.7838 - binary_output_19_binary_accuracy: 0.8015 - binary_output_20_binary_accuracy: 0.8238 - binary_output_21_binary_accuracy: 0.9101 - binary_output_22_binary_accuracy: 0.9888 - binary_output_23_binary_accuracy: 0.9620 - binary_output_24_binary_accuracy: 0.9926 - binary_output_25_binary_accuracy: 0.9517 - binary_output_26_binary_accuracy: 0.8183 - binary_output_27_binary_accuracy: 0.7123 - binary_output_28_binary_accuracy: 0.7803 - binary_output_29_binary_accuracy: 0.7635 - binary_output_30_binary_accuracy: 0.9697 - binary_output_31_binary_accuracy: 0.7324 - binary_output_32_binary_accuracy: 0.8923 - binary_output_33_binary_accuracy: 0.7337 - binary_output_34_binary_accuracy: 0.6005 - categorical_output_sparse_categorical_accuracy: 0.7809\n",
      "Epoch 20/40\n",
      "22237/22237 [==============================] - 5s 244us/step - loss: 11.2898 - binary_output_0_loss: 0.4976 - binary_output_1_loss: 0.0909 - binary_output_2_loss: 0.5817 - binary_output_3_loss: 0.5030 - binary_output_4_loss: 0.3294 - binary_output_5_loss: 0.2853 - binary_output_6_loss: 0.2379 - binary_output_7_loss: 0.2070 - binary_output_8_loss: 9.0491e-04 - binary_output_9_loss: 0.3387 - binary_output_10_loss: 0.4235 - binary_output_11_loss: 0.3563 - binary_output_12_loss: 0.1351 - binary_output_13_loss: 0.2689 - binary_output_14_loss: 0.1763 - binary_output_15_loss: 0.2908 - binary_output_16_loss: 0.3472 - binary_output_17_loss: 0.6672 - binary_output_18_loss: 0.3634 - binary_output_19_loss: 0.3565 - binary_output_20_loss: 0.3070 - binary_output_21_loss: 0.2194 - binary_output_22_loss: 0.1174 - binary_output_23_loss: 0.1461 - binary_output_24_loss: 0.0853 - binary_output_25_loss: 0.1481 - binary_output_26_loss: 0.3065 - binary_output_27_loss: 0.4829 - binary_output_28_loss: 0.3847 - binary_output_29_loss: 0.4137 - binary_output_30_loss: 0.1497 - binary_output_31_loss: 0.4389 - binary_output_32_loss: 0.2136 - binary_output_33_loss: 0.4021 - binary_output_34_loss: 0.6095 - categorical_output_loss: 0.4063 - binary_output_0_binary_accuracy: 0.7076 - binary_output_1_binary_accuracy: 0.9932 - binary_output_2_binary_accuracy: 0.6780 - binary_output_3_binary_accuracy: 0.6593 - binary_output_4_binary_accuracy: 0.8211 - binary_output_5_binary_accuracy: 0.8711 - binary_output_6_binary_accuracy: 0.9325 - binary_output_7_binary_accuracy: 0.9169 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8035 - binary_output_10_binary_accuracy: 0.7532 - binary_output_11_binary_accuracy: 0.8048 - binary_output_12_binary_accuracy: 0.9551 - binary_output_13_binary_accuracy: 0.9063 - binary_output_14_binary_accuracy: 0.9655 - binary_output_15_binary_accuracy: 0.8489 - binary_output_16_binary_accuracy: 0.8164 - binary_output_17_binary_accuracy: 0.5343 - binary_output_18_binary_accuracy: 0.7844 - binary_output_19_binary_accuracy: 0.8009 - binary_output_20_binary_accuracy: 0.8276 - binary_output_21_binary_accuracy: 0.9066 - binary_output_22_binary_accuracy: 0.9874 - binary_output_23_binary_accuracy: 0.9599 - binary_output_24_binary_accuracy: 0.9915 - binary_output_25_binary_accuracy: 0.9532 - binary_output_26_binary_accuracy: 0.8176 - binary_output_27_binary_accuracy: 0.7209 - binary_output_28_binary_accuracy: 0.7844 - binary_output_29_binary_accuracy: 0.7620 - binary_output_30_binary_accuracy: 0.9678 - binary_output_31_binary_accuracy: 0.7366 - binary_output_32_binary_accuracy: 0.8941 - binary_output_33_binary_accuracy: 0.7367 - binary_output_34_binary_accuracy: 0.6118 - categorical_output_sparse_categorical_accuracy: 0.7833\n",
      "Epoch 21/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  512/22237 [..............................] - ETA: 5s - loss: 11.7798 - binary_output_0_loss: 0.5115 - binary_output_1_loss: 0.0877 - binary_output_2_loss: 0.5310 - binary_output_3_loss: 0.4780 - binary_output_4_loss: 0.3590 - binary_output_5_loss: 0.2386 - binary_output_6_loss: 0.3459 - binary_output_7_loss: 0.2071 - binary_output_8_loss: 9.6715e-04 - binary_output_9_loss: 0.3819 - binary_output_10_loss: 0.4213 - binary_output_11_loss: 0.3537 - binary_output_12_loss: 0.2083 - binary_output_13_loss: 0.2414 - binary_output_14_loss: 0.2120 - binary_output_15_loss: 0.3613 - binary_output_16_loss: 0.3163 - binary_output_17_loss: 0.6524 - binary_output_18_loss: 0.4643 - binary_output_19_loss: 0.3711 - binary_output_20_loss: 0.3131 - binary_output_21_loss: 0.1752 - binary_output_22_loss: 0.0821 - binary_output_23_loss: 0.2867 - binary_output_24_loss: 0.0934 - binary_output_25_loss: 0.2305 - binary_output_26_loss: 0.3133 - binary_output_27_loss: 0.4871 - binary_output_28_loss: 0.4252 - binary_output_29_loss: 0.4263 - binary_output_30_loss: 0.1062 - binary_output_31_loss: 0.3886 - binary_output_32_loss: 0.2866 - binary_output_33_loss: 0.3985 - binary_output_34_loss: 0.5834 - categorical_output_loss: 0.4397 - binary_output_0_binary_accuracy: 0.6914 - binary_output_1_binary_accuracy: 0.9922 - binary_output_2_binary_accuracy: 0.6973 - binary_output_3_binary_accuracy: 0.6348 - binary_output_4_binary_accuracy: 0.7715 - binary_output_5_binary_accuracy: 0.8633 - binary_output_6_binary_accuracy: 0.9199 - binary_output_7_binary_accuracy: 0.9180 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7461 - binary_output_10_binary_accuracy: 0.7227 - binary_output_11_binary_accuracy: 0.7891 - binary_output_12_binary_accuracy: 0.9414 - binary_output_13_binary_accuracy: 0.8652 - binary_output_14_binary_accuracy: 0.9512 - binary_output_15_binary_accuracy: 0.8477 - binary_output_16_binary_accuracy: 0.8184 - binary_output_17_binary_accuracy: 0.5176 - binary_output_18_binary_accuracy: 0.8281 - binary_output_19_binary_accuracy: 0.8145 - binary_output_20_binary_accuracy: 0.8223 - binary_output_21_binary_accuracy: 0.8770 - binary_output_22_binary_accuracy: 0.9883 - binary_output_23_binary_accuracy: 0.9531 - binary_output_24_binary_accuracy: 0.9844 - binary_output_25_binary_accuracy: 0.9512 - binary_output_26_binary_accuracy: 0.8516 - binary_output_27_binary_accuracy: 0.7227 - binary_output_28_binary_accuracy: 0.7969 - binary_output_29_binary_accuracy: 0.7676 - binary_output_30_binary_accuracy: 0.9785 - binary_output_31_binary_accuracy: 0.7344 - binary_output_32_binary_accuracy: 0.8789 - binary_output_33_binary_accuracy: 0.7559 - binary_output_34_binary_accuracy: 0.5898 - categorical_output_sparse_categorical_accuracy: 0.7617\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 1024/22237 [>.............................] - ETA: 5s - loss: 11.6494 - binary_output_0_loss: 0.4991 - binary_output_1_loss: 0.0617 - binary_output_2_loss: 0.5564 - binary_output_3_loss: 0.4976 - binary_output_4_loss: 0.3039 - binary_output_5_loss: 0.2701 - binary_output_6_loss: 0.2957 - binary_output_7_loss: 0.2148 - binary_output_8_loss: 0.0011 - binary_output_9_loss: 0.3810 - binary_output_10_loss: 0.3909 - binary_output_11_loss: 0.3411 - binary_output_12_loss: 0.1684 - binary_output_13_loss: 0.2482 - binary_output_14_loss: 0.1873 - binary_output_15_loss: 0.3193 - binary_output_16_loss: 0.3524 - binary_output_17_loss: 0.6477 - binary_output_18_loss: 0.4051 - binary_output_19_loss: 0.3813 - binary_output_20_loss: 0.3207 - binary_output_21_loss: 0.2658 - binary_output_22_loss: 0.1227 - binary_output_23_loss: 0.1913 - binary_output_24_loss: 0.0771 - binary_output_25_loss: 0.1706 - binary_output_26_loss: 0.3296 - binary_output_27_loss: 0.5103 - binary_output_28_loss: 0.4285 - binary_output_29_loss: 0.4506 - binary_output_30_loss: 0.1684 - binary_output_31_loss: 0.4409 - binary_output_32_loss: 0.2474 - binary_output_33_loss: 0.3970 - binary_output_34_loss: 0.6004 - categorical_output_loss: 0.4050 - binary_output_0_binary_accuracy: 0.6943 - binary_output_1_binary_accuracy: 0.9932 - binary_output_2_binary_accuracy: 0.6982 - binary_output_3_binary_accuracy: 0.6465 - binary_output_4_binary_accuracy: 0.7900 - binary_output_5_binary_accuracy: 0.8525 - binary_output_6_binary_accuracy: 0.9209 - binary_output_7_binary_accuracy: 0.9121 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7686 - binary_output_10_binary_accuracy: 0.7627 - binary_output_11_binary_accuracy: 0.7969 - binary_output_12_binary_accuracy: 0.9404 - binary_output_13_binary_accuracy: 0.8877 - binary_output_14_binary_accuracy: 0.9561 - binary_output_15_binary_accuracy: 0.8359 - binary_output_16_binary_accuracy: 0.8057 - binary_output_17_binary_accuracy: 0.5469 - binary_output_18_binary_accuracy: 0.8105 - binary_output_19_binary_accuracy: 0.7988 - binary_output_20_binary_accuracy: 0.8281 - binary_output_21_binary_accuracy: 0.8691 - binary_output_22_binary_accuracy: 0.9824 - binary_output_23_binary_accuracy: 0.9414 - binary_output_24_binary_accuracy: 0.9873 - binary_output_25_binary_accuracy: 0.9434 - binary_output_26_binary_accuracy: 0.8340 - binary_output_27_binary_accuracy: 0.7139 - binary_output_28_binary_accuracy: 0.7783 - binary_output_29_binary_accuracy: 0.7578 - binary_output_30_binary_accuracy: 0.9668 - binary_output_31_binary_accuracy: 0.7197 - binary_output_32_binary_accuracy: 0.8623 - binary_output_33_binary_accuracy: 0.7363 - binary_output_34_binary_accuracy: 0.6172 - categorical_output_sparse_categorical_accuracy: 0.7705    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22237/22237 [==============================] - 6s 249us/step - loss: 11.1237 - binary_output_0_loss: 0.4853 - binary_output_1_loss: 0.0915 - binary_output_2_loss: 0.5685 - binary_output_3_loss: 0.4913 - binary_output_4_loss: 0.3238 - binary_output_5_loss: 0.2852 - binary_output_6_loss: 0.2361 - binary_output_7_loss: 0.1986 - binary_output_8_loss: 8.0281e-04 - binary_output_9_loss: 0.3291 - binary_output_10_loss: 0.4164 - binary_output_11_loss: 0.3543 - binary_output_12_loss: 0.1339 - binary_output_13_loss: 0.2669 - binary_output_14_loss: 0.1728 - binary_output_15_loss: 0.2863 - binary_output_16_loss: 0.3435 - binary_output_17_loss: 0.6570 - binary_output_18_loss: 0.3579 - binary_output_19_loss: 0.3547 - binary_output_20_loss: 0.3047 - binary_output_21_loss: 0.2263 - binary_output_22_loss: 0.1120 - binary_output_23_loss: 0.1432 - binary_output_24_loss: 0.0891 - binary_output_25_loss: 0.1464 - binary_output_26_loss: 0.3028 - binary_output_27_loss: 0.4672 - binary_output_28_loss: 0.3820 - binary_output_29_loss: 0.3996 - binary_output_30_loss: 0.1531 - binary_output_31_loss: 0.4302 - binary_output_32_loss: 0.2150 - binary_output_33_loss: 0.3963 - binary_output_34_loss: 0.6035 - categorical_output_loss: 0.3956 - binary_output_0_binary_accuracy: 0.7104 - binary_output_1_binary_accuracy: 0.9917 - binary_output_2_binary_accuracy: 0.6839 - binary_output_3_binary_accuracy: 0.6654 - binary_output_4_binary_accuracy: 0.8244 - binary_output_5_binary_accuracy: 0.8663 - binary_output_6_binary_accuracy: 0.9346 - binary_output_7_binary_accuracy: 0.9196 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8068 - binary_output_10_binary_accuracy: 0.7542 - binary_output_11_binary_accuracy: 0.8033 - binary_output_12_binary_accuracy: 0.9567 - binary_output_13_binary_accuracy: 0.9057 - binary_output_14_binary_accuracy: 0.9647 - binary_output_15_binary_accuracy: 0.8467 - binary_output_16_binary_accuracy: 0.8185 - binary_output_17_binary_accuracy: 0.5434 - binary_output_18_binary_accuracy: 0.7909 - binary_output_19_binary_accuracy: 0.8019 - binary_output_20_binary_accuracy: 0.8257 - binary_output_21_binary_accuracy: 0.9074 - binary_output_22_binary_accuracy: 0.9871 - binary_output_23_binary_accuracy: 0.9607 - binary_output_24_binary_accuracy: 0.9909 - binary_output_25_binary_accuracy: 0.9557 - binary_output_26_binary_accuracy: 0.8246 - binary_output_27_binary_accuracy: 0.7331 - binary_output_28_binary_accuracy: 0.7824 - binary_output_29_binary_accuracy: 0.7671 - binary_output_30_binary_accuracy: 0.9692 - binary_output_31_binary_accuracy: 0.7338 - binary_output_32_binary_accuracy: 0.8927 - binary_output_33_binary_accuracy: 0.7359 - binary_output_34_binary_accuracy: 0.6118 - categorical_output_sparse_categorical_accuracy: 0.7858\n",
      "Epoch 22/40\n",
      "22237/22237 [==============================] - 6s 257us/step - loss: 10.9198 - binary_output_0_loss: 0.4886 - binary_output_1_loss: 0.0885 - binary_output_2_loss: 0.5558 - binary_output_3_loss: 0.4878 - binary_output_4_loss: 0.3176 - binary_output_5_loss: 0.2761 - binary_output_6_loss: 0.2316 - binary_output_7_loss: 0.1917 - binary_output_8_loss: 7.4347e-04 - binary_output_9_loss: 0.3265 - binary_output_10_loss: 0.4174 - binary_output_11_loss: 0.3513 - binary_output_12_loss: 0.1307 - binary_output_13_loss: 0.2618 - binary_output_14_loss: 0.1673 - binary_output_15_loss: 0.2864 - binary_output_16_loss: 0.3288 - binary_output_17_loss: 0.6532 - binary_output_18_loss: 0.3443 - binary_output_19_loss: 0.3459 - binary_output_20_loss: 0.2949 - binary_output_21_loss: 0.2207 - binary_output_22_loss: 0.1113 - binary_output_23_loss: 0.1382 - binary_output_24_loss: 0.0874 - binary_output_25_loss: 0.1432 - binary_output_26_loss: 0.2950 - binary_output_27_loss: 0.4597 - binary_output_28_loss: 0.3725 - binary_output_29_loss: 0.4047 - binary_output_30_loss: 0.1493 - binary_output_31_loss: 0.4229 - binary_output_32_loss: 0.2074 - binary_output_33_loss: 0.3924 - binary_output_34_loss: 0.5940 - categorical_output_loss: 0.3900 - binary_output_0_binary_accuracy: 0.7149 - binary_output_1_binary_accuracy: 0.9920 - binary_output_2_binary_accuracy: 0.6889 - binary_output_3_binary_accuracy: 0.6696 - binary_output_4_binary_accuracy: 0.8275 - binary_output_5_binary_accuracy: 0.8672 - binary_output_6_binary_accuracy: 0.9291 - binary_output_7_binary_accuracy: 0.9240 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8132 - binary_output_10_binary_accuracy: 0.7519 - binary_output_11_binary_accuracy: 0.8122 - binary_output_12_binary_accuracy: 0.9596 - binary_output_13_binary_accuracy: 0.9052 - binary_output_14_binary_accuracy: 0.9686 - binary_output_15_binary_accuracy: 0.8503 - binary_output_16_binary_accuracy: 0.8259 - binary_output_17_binary_accuracy: 0.5456 - binary_output_18_binary_accuracy: 0.8013 - binary_output_19_binary_accuracy: 0.8090 - binary_output_20_binary_accuracy: 0.8322 - binary_output_21_binary_accuracy: 0.9061 - binary_output_22_binary_accuracy: 0.9874 - binary_output_23_binary_accuracy: 0.9589 - binary_output_24_binary_accuracy: 0.9914 - binary_output_25_binary_accuracy: 0.9514 - binary_output_26_binary_accuracy: 0.8287 - binary_output_27_binary_accuracy: 0.7370 - binary_output_28_binary_accuracy: 0.7881 - binary_output_29_binary_accuracy: 0.7714 - binary_output_30_binary_accuracy: 0.9667 - binary_output_31_binary_accuracy: 0.7418 - binary_output_32_binary_accuracy: 0.8959 - binary_output_33_binary_accuracy: 0.7412 - binary_output_34_binary_accuracy: 0.6175 - categorical_output_sparse_categorical_accuracy: 0.7864\n",
      "Epoch 23/40\n",
      " 1024/22237 [>.............................] - ETA: 5s - loss: 10.7452 - binary_output_0_loss: 0.4434 - binary_output_1_loss: 0.1111 - binary_output_2_loss: 0.5676 - binary_output_3_loss: 0.4741 - binary_output_4_loss: 0.2560 - binary_output_5_loss: 0.2600 - binary_output_6_loss: 0.3399 - binary_output_7_loss: 0.1998 - binary_output_8_loss: 9.8385e-04 - binary_output_9_loss: 0.3320 - binary_output_10_loss: 0.4156 - binary_output_11_loss: 0.3547 - binary_output_12_loss: 0.1346 - binary_output_13_loss: 0.3138 - binary_output_14_loss: 0.1489 - binary_output_15_loss: 0.2199 - binary_output_16_loss: 0.2836 - binary_output_17_loss: 0.6480 - binary_output_18_loss: 0.3217 - binary_output_19_loss: 0.3118 - binary_output_20_loss: 0.2655 - binary_output_21_loss: 0.1657 - binary_output_22_loss: 0.1503 - binary_output_23_loss: 0.1197 - binary_output_24_loss: 0.0650 - binary_output_25_loss: 0.1758 - binary_output_26_loss: 0.2689 - binary_output_27_loss: 0.4570 - binary_output_28_loss: 0.3727 - binary_output_29_loss: 0.4294 - binary_output_30_loss: 0.1176 - binary_output_31_loss: 0.4113 - binary_output_32_loss: 0.2092 - binary_output_33_loss: 0.3996 - binary_output_34_loss: 0.6066 - categorical_output_loss: 0.3932 - binary_output_0_binary_accuracy: 0.7441 - binary_output_1_binary_accuracy: 0.9932 - binary_output_2_binary_accuracy: 0.7217 - binary_output_3_binary_accuracy: 0.7021 - binary_output_4_binary_accuracy: 0.8271 - binary_output_5_binary_accuracy: 0.8760 - binary_output_6_binary_accuracy: 0.9277 - binary_output_7_binary_accuracy: 0.9209 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8154 - binary_output_10_binary_accuracy: 0.7568 - binary_output_11_binary_accuracy: 0.8057 - binary_output_12_binary_accuracy: 0.9531 - binary_output_13_binary_accuracy: 0.9121 - binary_output_14_binary_accuracy: 0.9688 - binary_output_15_binary_accuracy: 0.8613 - binary_output_16_binary_accuracy: 0.8340 - binary_output_17_binary_accuracy: 0.5693 - binary_output_18_binary_accuracy: 0.8125 - binary_output_19_binary_accuracy: 0.8213 - binary_output_20_binary_accuracy: 0.8340 - binary_output_21_binary_accuracy: 0.9160 - binary_output_22_binary_accuracy: 0.9863 - binary_output_23_binary_accuracy: 0.9658 - binary_output_24_binary_accuracy: 0.9902 - binary_output_25_binary_accuracy: 0.9492 - binary_output_26_binary_accuracy: 0.8232 - binary_output_27_binary_accuracy: 0.7432 - binary_output_28_binary_accuracy: 0.7930 - binary_output_29_binary_accuracy: 0.7617 - binary_output_30_binary_accuracy: 0.9678 - binary_output_31_binary_accuracy: 0.7666 - binary_output_32_binary_accuracy: 0.9131 - binary_output_33_binary_accuracy: 0.7578 - binary_output_34_binary_accuracy: 0.6426 - categorical_output_sparse_categorical_accuracy: 0.783222237/22237 [==============================] - 5s 243us/step - loss: 10.7885 - binary_output_0_loss: 0.4742 - binary_output_1_loss: 0.0878 - binary_output_2_loss: 0.5391 - binary_output_3_loss: 0.4789 - binary_output_4_loss: 0.3149 - binary_output_5_loss: 0.2745 - binary_output_6_loss: 0.2266 - binary_output_7_loss: 0.1882 - binary_output_8_loss: 7.1998e-04 - binary_output_9_loss: 0.3207 - binary_output_10_loss: 0.4084 - binary_output_11_loss: 0.3432 - binary_output_12_loss: 0.1291 - binary_output_13_loss: 0.2515 - binary_output_14_loss: 0.1687 - binary_output_15_loss: 0.2785 - binary_output_16_loss: 0.3317 - binary_output_17_loss: 0.6483 - binary_output_18_loss: 0.3448 - binary_output_19_loss: 0.3423 - binary_output_20_loss: 0.2873 - binary_output_21_loss: 0.2197 - binary_output_22_loss: 0.1092 - binary_output_23_loss: 0.1360 - binary_output_24_loss: 0.0864 - binary_output_25_loss: 0.1420 - binary_output_26_loss: 0.2945 - binary_output_27_loss: 0.4479 - binary_output_28_loss: 0.3677 - binary_output_29_loss: 0.3951 - binary_output_30_loss: 0.1493 - binary_output_31_loss: 0.4158 - binary_output_32_loss: 0.2049 - binary_output_33_loss: 0.3909 - binary_output_34_loss: 0.5917 - categorical_output_loss: 0.3891 - binary_output_0_binary_accuracy: 0.7153 - binary_output_1_binary_accuracy: 0.9917 - binary_output_2_binary_accuracy: 0.7050 - binary_output_3_binary_accuracy: 0.6846 - binary_output_4_binary_accuracy: 0.8288 - binary_output_5_binary_accuracy: 0.8708 - binary_output_6_binary_accuracy: 0.9311 - binary_output_7_binary_accuracy: 0.9235 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8152 - binary_output_10_binary_accuracy: 0.7576 - binary_output_11_binary_accuracy: 0.8104 - binary_output_12_binary_accuracy: 0.9594 - binary_output_13_binary_accuracy: 0.9065 - binary_output_14_binary_accuracy: 0.9597 - binary_output_15_binary_accuracy: 0.8553 - binary_output_16_binary_accuracy: 0.8248 - binary_output_17_binary_accuracy: 0.5542 - binary_output_18_binary_accuracy: 0.8009 - binary_output_19_binary_accuracy: 0.8080 - binary_output_20_binary_accuracy: 0.8371 - binary_output_21_binary_accuracy: 0.9048 - binary_output_22_binary_accuracy: 0.9861 - binary_output_23_binary_accuracy: 0.9587 - binary_output_24_binary_accuracy: 0.9903 - binary_output_25_binary_accuracy: 0.9509 - binary_output_26_binary_accuracy: 0.8278 - binary_output_27_binary_accuracy: 0.7437 - binary_output_28_binary_accuracy: 0.7903 - binary_output_29_binary_accuracy: 0.7672 - binary_output_30_binary_accuracy: 0.9648 - binary_output_31_binary_accuracy: 0.7443 - binary_output_32_binary_accuracy: 0.8970 - binary_output_33_binary_accuracy: 0.7388 - binary_output_34_binary_accuracy: 0.6192 - categorical_output_sparse_categorical_accuracy: 0.7850\n",
      "Epoch 24/40\n",
      "22237/22237 [==============================] - 5s 242us/step - loss: 10.6321 - binary_output_0_loss: 0.4681 - binary_output_1_loss: 0.0863 - binary_output_2_loss: 0.5329 - binary_output_3_loss: 0.4721 - binary_output_4_loss: 0.3079 - binary_output_5_loss: 0.2726 - binary_output_6_loss: 0.2204 - binary_output_7_loss: 0.1856 - binary_output_8_loss: 6.9402e-04 - binary_output_9_loss: 0.3130 - binary_output_10_loss: 0.4090 - binary_output_11_loss: 0.3446 - binary_output_12_loss: 0.1284 - binary_output_13_loss: 0.2492 - binary_output_14_loss: 0.1596 - binary_output_15_loss: 0.2761 - binary_output_16_loss: 0.3258 - binary_output_17_loss: 0.6406 - binary_output_18_loss: 0.3352 - binary_output_19_loss: 0.3350 - binary_output_20_loss: 0.2882 - binary_output_21_loss: 0.2208 - binary_output_22_loss: 0.1083 - binary_output_23_loss: 0.1338 - binary_output_24_loss: 0.0822 - binary_output_25_loss: 0.1381 - binary_output_26_loss: 0.2859 - binary_output_27_loss: 0.4382 - binary_output_28_loss: 0.3618 - binary_output_29_loss: 0.3903 - binary_output_30_loss: 0.1450 - binary_output_31_loss: 0.4109 - binary_output_32_loss: 0.2068 - binary_output_33_loss: 0.3879 - binary_output_34_loss: 0.5876 - categorical_output_loss: 0.3828 - binary_output_0_binary_accuracy: 0.7188 - binary_output_1_binary_accuracy: 0.9916 - binary_output_2_binary_accuracy: 0.7076 - binary_output_3_binary_accuracy: 0.6844 - binary_output_4_binary_accuracy: 0.8328 - binary_output_5_binary_accuracy: 0.8681 - binary_output_6_binary_accuracy: 0.9260 - binary_output_7_binary_accuracy: 0.9272 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8158 - binary_output_10_binary_accuracy: 0.7578 - binary_output_11_binary_accuracy: 0.8104 - binary_output_12_binary_accuracy: 0.9605 - binary_output_13_binary_accuracy: 0.9115 - binary_output_14_binary_accuracy: 0.9603 - binary_output_15_binary_accuracy: 0.8513 - binary_output_16_binary_accuracy: 0.8280 - binary_output_17_binary_accuracy: 0.5569 - binary_output_18_binary_accuracy: 0.8042 - binary_output_19_binary_accuracy: 0.8120 - binary_output_20_binary_accuracy: 0.8358 - binary_output_21_binary_accuracy: 0.9048 - binary_output_22_binary_accuracy: 0.9866 - binary_output_23_binary_accuracy: 0.9617 - binary_output_24_binary_accuracy: 0.9895 - binary_output_25_binary_accuracy: 0.9539 - binary_output_26_binary_accuracy: 0.8312 - binary_output_27_binary_accuracy: 0.7523 - binary_output_28_binary_accuracy: 0.7922 - binary_output_29_binary_accuracy: 0.7763 - binary_output_30_binary_accuracy: 0.9638 - binary_output_31_binary_accuracy: 0.7424 - binary_output_32_binary_accuracy: 0.9009 - binary_output_33_binary_accuracy: 0.7474 - binary_output_34_binary_accuracy: 0.6275 - categorical_output_sparse_categorical_accuracy: 0.7881\n",
      "Epoch 25/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  512/22237 [..............................] - ETA: 5s - loss: 10.4394 - binary_output_0_loss: 0.4624 - binary_output_1_loss: 0.0313 - binary_output_2_loss: 0.5192 - binary_output_3_loss: 0.4533 - binary_output_4_loss: 0.2576 - binary_output_5_loss: 0.3556 - binary_output_6_loss: 0.1967 - binary_output_7_loss: 0.1994 - binary_output_8_loss: 6.7705e-04 - binary_output_9_loss: 0.3044 - binary_output_10_loss: 0.3835 - binary_output_11_loss: 0.3810 - binary_output_12_loss: 0.0836 - binary_output_13_loss: 0.3047 - binary_output_14_loss: 0.1042 - binary_output_15_loss: 0.2303 - binary_output_16_loss: 0.3006 - binary_output_17_loss: 0.7100 - binary_output_18_loss: 0.3745 - binary_output_19_loss: 0.3626 - binary_output_20_loss: 0.3765 - binary_output_21_loss: 0.2368 - binary_output_22_loss: 0.0930 - binary_output_23_loss: 0.1121 - binary_output_24_loss: 0.0886 - binary_output_25_loss: 0.1716 - binary_output_26_loss: 0.3161 - binary_output_27_loss: 0.4189 - binary_output_28_loss: 0.3328 - binary_output_29_loss: 0.3885 - binary_output_30_loss: 0.0801 - binary_output_31_loss: 0.3554 - binary_output_32_loss: 0.1465 - binary_output_33_loss: 0.4112 - binary_output_34_loss: 0.5834 - categorical_output_loss: 0.3124 - binary_output_0_binary_accuracy: 0.7676 - binary_output_1_binary_accuracy: 0.9941 - binary_output_2_binary_accuracy: 0.7695 - binary_output_3_binary_accuracy: 0.6719 - binary_output_4_binary_accuracy: 0.8301 - binary_output_5_binary_accuracy: 0.8926 - binary_output_6_binary_accuracy: 0.9531 - binary_output_7_binary_accuracy: 0.9453 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7852 - binary_output_10_binary_accuracy: 0.7598 - binary_output_11_binary_accuracy: 0.7891 - binary_output_12_binary_accuracy: 0.9648 - binary_output_13_binary_accuracy: 0.8613 - binary_output_14_binary_accuracy: 0.9824 - binary_output_15_binary_accuracy: 0.8828 - binary_output_16_binary_accuracy: 0.8652 - binary_output_17_binary_accuracy: 0.5625 - binary_output_18_binary_accuracy: 0.8164 - binary_output_19_binary_accuracy: 0.8066 - binary_output_20_binary_accuracy: 0.8535 - binary_output_21_binary_accuracy: 0.9023 - binary_output_22_binary_accuracy: 0.9922 - binary_output_23_binary_accuracy: 0.9629 - binary_output_24_binary_accuracy: 0.9922 - binary_output_25_binary_accuracy: 0.9453 - binary_output_26_binary_accuracy: 0.8242 - binary_output_27_binary_accuracy: 0.7148 - binary_output_28_binary_accuracy: 0.7656 - binary_output_29_binary_accuracy: 0.7266 - binary_output_30_binary_accuracy: 0.9688 - binary_output_31_binary_accuracy: 0.7188 - binary_output_32_binary_accuracy: 0.9316 - binary_output_33_binary_accuracy: 0.7168 - binary_output_34_binary_accuracy: 0.6582 - categorical_output_sparse_categorical_accuracy: 0.7773\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 1024/22237 [>.............................] - ETA: 5s - loss: 10.7127 - binary_output_0_loss: 0.5009 - binary_output_1_loss: 0.0291 - binary_output_2_loss: 0.5106 - binary_output_3_loss: 0.4971 - binary_output_4_loss: 0.2813 - binary_output_5_loss: 0.3206 - binary_output_6_loss: 0.1965 - binary_output_7_loss: 0.1844 - binary_output_8_loss: 5.7457e-04 - binary_output_9_loss: 0.2899 - binary_output_10_loss: 0.3703 - binary_output_11_loss: 0.3506 - binary_output_12_loss: 0.1255 - binary_output_13_loss: 0.2924 - binary_output_14_loss: 0.1390 - binary_output_15_loss: 0.2918 - binary_output_16_loss: 0.3500 - binary_output_17_loss: 0.6571 - binary_output_18_loss: 0.3661 - binary_output_19_loss: 0.3599 - binary_output_20_loss: 0.3182 - binary_output_21_loss: 0.2697 - binary_output_22_loss: 0.0870 - binary_output_23_loss: 0.1383 - binary_output_24_loss: 0.0584 - binary_output_25_loss: 0.1579 - binary_output_26_loss: 0.3297 - binary_output_27_loss: 0.4275 - binary_output_28_loss: 0.3428 - binary_output_29_loss: 0.4291 - binary_output_30_loss: 0.1422 - binary_output_31_loss: 0.3863 - binary_output_32_loss: 0.1659 - binary_output_33_loss: 0.3892 - binary_output_34_loss: 0.6101 - categorical_output_loss: 0.3467 - binary_output_0_binary_accuracy: 0.7324 - binary_output_1_binary_accuracy: 0.9961 - binary_output_2_binary_accuracy: 0.7422 - binary_output_3_binary_accuracy: 0.6641 - binary_output_4_binary_accuracy: 0.8369 - binary_output_5_binary_accuracy: 0.8721 - binary_output_6_binary_accuracy: 0.9385 - binary_output_7_binary_accuracy: 0.9336 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8252 - binary_output_10_binary_accuracy: 0.7656 - binary_output_11_binary_accuracy: 0.7988 - binary_output_12_binary_accuracy: 0.9619 - binary_output_13_binary_accuracy: 0.8838 - binary_output_14_binary_accuracy: 0.9658 - binary_output_15_binary_accuracy: 0.8535 - binary_output_16_binary_accuracy: 0.8467 - binary_output_17_binary_accuracy: 0.5420 - binary_output_18_binary_accuracy: 0.8105 - binary_output_19_binary_accuracy: 0.8096 - binary_output_20_binary_accuracy: 0.8506 - binary_output_21_binary_accuracy: 0.9023 - binary_output_22_binary_accuracy: 0.9922 - binary_output_23_binary_accuracy: 0.9619 - binary_output_24_binary_accuracy: 0.9951 - binary_output_25_binary_accuracy: 0.9473 - binary_output_26_binary_accuracy: 0.8281 - binary_output_27_binary_accuracy: 0.7510 - binary_output_28_binary_accuracy: 0.7764 - binary_output_29_binary_accuracy: 0.7529 - binary_output_30_binary_accuracy: 0.9609 - binary_output_31_binary_accuracy: 0.7441 - binary_output_32_binary_accuracy: 0.9150 - binary_output_33_binary_accuracy: 0.7334 - binary_output_34_binary_accuracy: 0.6182 - categorical_output_sparse_categorical_accuracy: 0.7939"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22237/22237 [==============================] - 5s 242us/step - loss: 10.5290 - binary_output_0_loss: 0.4699 - binary_output_1_loss: 0.0890 - binary_output_2_loss: 0.5246 - binary_output_3_loss: 0.4735 - binary_output_4_loss: 0.2996 - binary_output_5_loss: 0.2710 - binary_output_6_loss: 0.2228 - binary_output_7_loss: 0.1770 - binary_output_8_loss: 6.4659e-04 - binary_output_9_loss: 0.3048 - binary_output_10_loss: 0.3965 - binary_output_11_loss: 0.3422 - binary_output_12_loss: 0.1250 - binary_output_13_loss: 0.2489 - binary_output_14_loss: 0.1590 - binary_output_15_loss: 0.2756 - binary_output_16_loss: 0.3276 - binary_output_17_loss: 0.6395 - binary_output_18_loss: 0.3353 - binary_output_19_loss: 0.3265 - binary_output_20_loss: 0.2920 - binary_output_21_loss: 0.2143 - binary_output_22_loss: 0.1066 - binary_output_23_loss: 0.1362 - binary_output_24_loss: 0.0830 - binary_output_25_loss: 0.1430 - binary_output_26_loss: 0.2843 - binary_output_27_loss: 0.4313 - binary_output_28_loss: 0.3535 - binary_output_29_loss: 0.3902 - binary_output_30_loss: 0.1399 - binary_output_31_loss: 0.4080 - binary_output_32_loss: 0.2016 - binary_output_33_loss: 0.3758 - binary_output_34_loss: 0.5811 - categorical_output_loss: 0.3828 - binary_output_0_binary_accuracy: 0.7255 - binary_output_1_binary_accuracy: 0.9917 - binary_output_2_binary_accuracy: 0.7159 - binary_output_3_binary_accuracy: 0.6869 - binary_output_4_binary_accuracy: 0.8395 - binary_output_5_binary_accuracy: 0.8672 - binary_output_6_binary_accuracy: 0.9276 - binary_output_7_binary_accuracy: 0.9281 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8289 - binary_output_10_binary_accuracy: 0.7686 - binary_output_11_binary_accuracy: 0.8087 - binary_output_12_binary_accuracy: 0.9578 - binary_output_13_binary_accuracy: 0.9052 - binary_output_14_binary_accuracy: 0.9623 - binary_output_15_binary_accuracy: 0.8536 - binary_output_16_binary_accuracy: 0.8316 - binary_output_17_binary_accuracy: 0.5566 - binary_output_18_binary_accuracy: 0.8060 - binary_output_19_binary_accuracy: 0.8136 - binary_output_20_binary_accuracy: 0.8315 - binary_output_21_binary_accuracy: 0.9081 - binary_output_22_binary_accuracy: 0.9867 - binary_output_23_binary_accuracy: 0.9571 - binary_output_24_binary_accuracy: 0.9911 - binary_output_25_binary_accuracy: 0.9489 - binary_output_26_binary_accuracy: 0.8344 - binary_output_27_binary_accuracy: 0.7564 - binary_output_28_binary_accuracy: 0.7982 - binary_output_29_binary_accuracy: 0.7742 - binary_output_30_binary_accuracy: 0.9637 - binary_output_31_binary_accuracy: 0.7433 - binary_output_32_binary_accuracy: 0.9000 - binary_output_33_binary_accuracy: 0.7445 - binary_output_34_binary_accuracy: 0.6242 - categorical_output_sparse_categorical_accuracy: 0.7860\n",
      "Epoch 26/40\n",
      "22237/22237 [==============================] - 5s 246us/step - loss: 10.3569 - binary_output_0_loss: 0.4615 - binary_output_1_loss: 0.0883 - binary_output_2_loss: 0.5108 - binary_output_3_loss: 0.4624 - binary_output_4_loss: 0.2990 - binary_output_5_loss: 0.2603 - binary_output_6_loss: 0.2165 - binary_output_7_loss: 0.1721 - binary_output_8_loss: 6.5656e-04 - binary_output_9_loss: 0.3029 - binary_output_10_loss: 0.3972 - binary_output_11_loss: 0.3312 - binary_output_12_loss: 0.1228 - binary_output_13_loss: 0.2478 - binary_output_14_loss: 0.1589 - binary_output_15_loss: 0.2627 - binary_output_16_loss: 0.3195 - binary_output_17_loss: 0.6351 - binary_output_18_loss: 0.3272 - binary_output_19_loss: 0.3247 - binary_output_20_loss: 0.2854 - binary_output_21_loss: 0.2084 - binary_output_22_loss: 0.1022 - binary_output_23_loss: 0.1287 - binary_output_24_loss: 0.0836 - binary_output_25_loss: 0.1347 - binary_output_26_loss: 0.2795 - binary_output_27_loss: 0.4226 - binary_output_28_loss: 0.3539 - binary_output_29_loss: 0.3783 - binary_output_30_loss: 0.1389 - binary_output_31_loss: 0.3928 - binary_output_32_loss: 0.1998 - binary_output_33_loss: 0.3802 - binary_output_34_loss: 0.5816 - categorical_output_loss: 0.3788 - binary_output_0_binary_accuracy: 0.7229 - binary_output_1_binary_accuracy: 0.9905 - binary_output_2_binary_accuracy: 0.7240 - binary_output_3_binary_accuracy: 0.6928 - binary_output_4_binary_accuracy: 0.8390 - binary_output_5_binary_accuracy: 0.8716 - binary_output_6_binary_accuracy: 0.9293 - binary_output_7_binary_accuracy: 0.9280 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8244 - binary_output_10_binary_accuracy: 0.7606 - binary_output_11_binary_accuracy: 0.8194 - binary_output_12_binary_accuracy: 0.9598 - binary_output_13_binary_accuracy: 0.9106 - binary_output_14_binary_accuracy: 0.9576 - binary_output_15_binary_accuracy: 0.8561 - binary_output_16_binary_accuracy: 0.8323 - binary_output_17_binary_accuracy: 0.5656 - binary_output_18_binary_accuracy: 0.8133 - binary_output_19_binary_accuracy: 0.8140 - binary_output_20_binary_accuracy: 0.8375 - binary_output_21_binary_accuracy: 0.9062 - binary_output_22_binary_accuracy: 0.9847 - binary_output_23_binary_accuracy: 0.9589 - binary_output_24_binary_accuracy: 0.9888 - binary_output_25_binary_accuracy: 0.9541 - binary_output_26_binary_accuracy: 0.8353 - binary_output_27_binary_accuracy: 0.7616 - binary_output_28_binary_accuracy: 0.8007 - binary_output_29_binary_accuracy: 0.7782 - binary_output_30_binary_accuracy: 0.9638 - binary_output_31_binary_accuracy: 0.7550 - binary_output_32_binary_accuracy: 0.8974 - binary_output_33_binary_accuracy: 0.7496 - binary_output_34_binary_accuracy: 0.6300 - categorical_output_sparse_categorical_accuracy: 0.7920\n",
      "Epoch 27/40\n",
      " 1024/22237 [>.............................] - ETA: 5s - loss: 9.9040 - binary_output_0_loss: 0.4542 - binary_output_1_loss: 0.1257 - binary_output_2_loss: 0.5314 - binary_output_3_loss: 0.4485 - binary_output_4_loss: 0.2907 - binary_output_5_loss: 0.2477 - binary_output_6_loss: 0.1599 - binary_output_7_loss: 0.1216 - binary_output_8_loss: 4.2453e-04 - binary_output_9_loss: 0.2940 - binary_output_10_loss: 0.3784 - binary_output_11_loss: 0.2687 - binary_output_12_loss: 0.1746 - binary_output_13_loss: 0.2627 - binary_output_14_loss: 0.1283 - binary_output_15_loss: 0.2303 - binary_output_16_loss: 0.3396 - binary_output_17_loss: 0.6385 - binary_output_18_loss: 0.2765 - binary_output_19_loss: 0.3300 - binary_output_20_loss: 0.2692 - binary_output_21_loss: 0.2485 - binary_output_22_loss: 0.0830 - binary_output_23_loss: 0.1126 - binary_output_24_loss: 0.0249 - binary_output_25_loss: 0.0834 - binary_output_26_loss: 0.2428 - binary_output_27_loss: 0.4204 - binary_output_28_loss: 0.3571 - binary_output_29_loss: 0.3858 - binary_output_30_loss: 0.1284 - binary_output_31_loss: 0.3440 - binary_output_32_loss: 0.1568 - binary_output_33_loss: 0.4077 - binary_output_34_loss: 0.5704 - categorical_output_loss: 0.3677 - binary_output_0_binary_accuracy: 0.7412 - binary_output_1_binary_accuracy: 0.9912 - binary_output_2_binary_accuracy: 0.7178 - binary_output_3_binary_accuracy: 0.7100 - binary_output_4_binary_accuracy: 0.8408 - binary_output_5_binary_accuracy: 0.9023 - binary_output_6_binary_accuracy: 0.9482 - binary_output_7_binary_accuracy: 0.9512 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8066 - binary_output_10_binary_accuracy: 0.7734 - binary_output_11_binary_accuracy: 0.8154 - binary_output_12_binary_accuracy: 0.9619 - binary_output_13_binary_accuracy: 0.9219 - binary_output_14_binary_accuracy: 0.9736 - binary_output_15_binary_accuracy: 0.8945 - binary_output_16_binary_accuracy: 0.8525 - binary_output_17_binary_accuracy: 0.5986 - binary_output_18_binary_accuracy: 0.8174 - binary_output_19_binary_accuracy: 0.8359 - binary_output_20_binary_accuracy: 0.8262 - binary_output_21_binary_accuracy: 0.9141 - binary_output_22_binary_accuracy: 0.9902 - binary_output_23_binary_accuracy: 0.9648 - binary_output_24_binary_accuracy: 0.9971 - binary_output_25_binary_accuracy: 0.9629 - binary_output_26_binary_accuracy: 0.8467 - binary_output_27_binary_accuracy: 0.7539 - binary_output_28_binary_accuracy: 0.8096 - binary_output_29_binary_accuracy: 0.7822 - binary_output_30_binary_accuracy: 0.9756 - binary_output_31_binary_accuracy: 0.7539 - binary_output_32_binary_accuracy: 0.9150 - binary_output_33_binary_accuracy: 0.7734 - binary_output_34_binary_accuracy: 0.6338 - categorical_output_sparse_categorical_accuracy: 0.791022237/22237 [==============================] - 6s 271us/step - loss: 10.2157 - binary_output_0_loss: 0.4516 - binary_output_1_loss: 0.0874 - binary_output_2_loss: 0.5040 - binary_output_3_loss: 0.4545 - binary_output_4_loss: 0.2917 - binary_output_5_loss: 0.2612 - binary_output_6_loss: 0.2096 - binary_output_7_loss: 0.1662 - binary_output_8_loss: 6.0173e-04 - binary_output_9_loss: 0.2991 - binary_output_10_loss: 0.3913 - binary_output_11_loss: 0.3296 - binary_output_12_loss: 0.1207 - binary_output_13_loss: 0.2459 - binary_output_14_loss: 0.1586 - binary_output_15_loss: 0.2723 - binary_output_16_loss: 0.3105 - binary_output_17_loss: 0.6311 - binary_output_18_loss: 0.3216 - binary_output_19_loss: 0.3255 - binary_output_20_loss: 0.2746 - binary_output_21_loss: 0.2107 - binary_output_22_loss: 0.1049 - binary_output_23_loss: 0.1250 - binary_output_24_loss: 0.0802 - binary_output_25_loss: 0.1364 - binary_output_26_loss: 0.2777 - binary_output_27_loss: 0.4132 - binary_output_28_loss: 0.3556 - binary_output_29_loss: 0.3785 - binary_output_30_loss: 0.1360 - binary_output_31_loss: 0.3842 - binary_output_32_loss: 0.1962 - binary_output_33_loss: 0.3736 - binary_output_34_loss: 0.5657 - categorical_output_loss: 0.3698 - binary_output_0_binary_accuracy: 0.7354 - binary_output_1_binary_accuracy: 0.9900 - binary_output_2_binary_accuracy: 0.7251 - binary_output_3_binary_accuracy: 0.6992 - binary_output_4_binary_accuracy: 0.8429 - binary_output_5_binary_accuracy: 0.8729 - binary_output_6_binary_accuracy: 0.9238 - binary_output_7_binary_accuracy: 0.9292 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8296 - binary_output_10_binary_accuracy: 0.7680 - binary_output_11_binary_accuracy: 0.8198 - binary_output_12_binary_accuracy: 0.9610 - binary_output_13_binary_accuracy: 0.9066 - binary_output_14_binary_accuracy: 0.9594 - binary_output_15_binary_accuracy: 0.8610 - binary_output_16_binary_accuracy: 0.8335 - binary_output_17_binary_accuracy: 0.5678 - binary_output_18_binary_accuracy: 0.8154 - binary_output_19_binary_accuracy: 0.8172 - binary_output_20_binary_accuracy: 0.8373 - binary_output_21_binary_accuracy: 0.9056 - binary_output_22_binary_accuracy: 0.9832 - binary_output_23_binary_accuracy: 0.9579 - binary_output_24_binary_accuracy: 0.9888 - binary_output_25_binary_accuracy: 0.9514 - binary_output_26_binary_accuracy: 0.8376 - binary_output_27_binary_accuracy: 0.7708 - binary_output_28_binary_accuracy: 0.8006 - binary_output_29_binary_accuracy: 0.7765 - binary_output_30_binary_accuracy: 0.9638 - binary_output_31_binary_accuracy: 0.7629 - binary_output_32_binary_accuracy: 0.8974 - binary_output_33_binary_accuracy: 0.7519 - binary_output_34_binary_accuracy: 0.6392 - categorical_output_sparse_categorical_accuracy: 0.7925\n",
      "Epoch 28/40\n",
      "22237/22237 [==============================] - 6s 251us/step - loss: 10.1328 - binary_output_0_loss: 0.4492 - binary_output_1_loss: 0.0845 - binary_output_2_loss: 0.5072 - binary_output_3_loss: 0.4520 - binary_output_4_loss: 0.2951 - binary_output_5_loss: 0.2647 - binary_output_6_loss: 0.2081 - binary_output_7_loss: 0.1643 - binary_output_8_loss: 5.9877e-04 - binary_output_9_loss: 0.2962 - binary_output_10_loss: 0.3940 - binary_output_11_loss: 0.3364 - binary_output_12_loss: 0.1215 - binary_output_13_loss: 0.2362 - binary_output_14_loss: 0.1565 - binary_output_15_loss: 0.2643 - binary_output_16_loss: 0.3051 - binary_output_17_loss: 0.6280 - binary_output_18_loss: 0.3141 - binary_output_19_loss: 0.3244 - binary_output_20_loss: 0.2819 - binary_output_21_loss: 0.2107 - binary_output_22_loss: 0.1013 - binary_output_23_loss: 0.1242 - binary_output_24_loss: 0.0806 - binary_output_25_loss: 0.1289 - binary_output_26_loss: 0.2727 - binary_output_27_loss: 0.4047 - binary_output_28_loss: 0.3453 - binary_output_29_loss: 0.3726 - binary_output_30_loss: 0.1337 - binary_output_31_loss: 0.3732 - binary_output_32_loss: 0.1931 - binary_output_33_loss: 0.3700 - binary_output_34_loss: 0.5662 - categorical_output_loss: 0.3672 - binary_output_0_binary_accuracy: 0.7358 - binary_output_1_binary_accuracy: 0.9904 - binary_output_2_binary_accuracy: 0.7291 - binary_output_3_binary_accuracy: 0.7015 - binary_output_4_binary_accuracy: 0.8432 - binary_output_5_binary_accuracy: 0.8696 - binary_output_6_binary_accuracy: 0.9252 - binary_output_7_binary_accuracy: 0.9312 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8323 - binary_output_10_binary_accuracy: 0.7652 - binary_output_11_binary_accuracy: 0.8154 - binary_output_12_binary_accuracy: 0.9608 - binary_output_13_binary_accuracy: 0.9210 - binary_output_14_binary_accuracy: 0.9617 - binary_output_15_binary_accuracy: 0.8607 - binary_output_16_binary_accuracy: 0.8404 - binary_output_17_binary_accuracy: 0.5649 - binary_output_18_binary_accuracy: 0.8142 - binary_output_19_binary_accuracy: 0.8198 - binary_output_20_binary_accuracy: 0.8392 - binary_output_21_binary_accuracy: 0.9047 - binary_output_22_binary_accuracy: 0.9826 - binary_output_23_binary_accuracy: 0.9607 - binary_output_24_binary_accuracy: 0.9899 - binary_output_25_binary_accuracy: 0.9526 - binary_output_26_binary_accuracy: 0.8359 - binary_output_27_binary_accuracy: 0.7736 - binary_output_28_binary_accuracy: 0.8034 - binary_output_29_binary_accuracy: 0.7809 - binary_output_30_binary_accuracy: 0.9626 - binary_output_31_binary_accuracy: 0.7629 - binary_output_32_binary_accuracy: 0.9016 - binary_output_33_binary_accuracy: 0.7549 - binary_output_34_binary_accuracy: 0.6392 - categorical_output_sparse_categorical_accuracy: 0.7928\n",
      "Epoch 29/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  512/22237 [..............................] - ETA: 5s - loss: 10.2134 - binary_output_0_loss: 0.3806 - binary_output_1_loss: 0.0246 - binary_output_2_loss: 0.4849 - binary_output_3_loss: 0.4151 - binary_output_4_loss: 0.2817 - binary_output_5_loss: 0.3158 - binary_output_6_loss: 0.2785 - binary_output_7_loss: 0.1319 - binary_output_8_loss: 3.3000e-04 - binary_output_9_loss: 0.2186 - binary_output_10_loss: 0.3494 - binary_output_11_loss: 0.3546 - binary_output_12_loss: 0.1257 - binary_output_13_loss: 0.2214 - binary_output_14_loss: 0.1751 - binary_output_15_loss: 0.3547 - binary_output_16_loss: 0.3208 - binary_output_17_loss: 0.6509 - binary_output_18_loss: 0.4365 - binary_output_19_loss: 0.3051 - binary_output_20_loss: 0.3134 - binary_output_21_loss: 0.2058 - binary_output_22_loss: 0.0953 - binary_output_23_loss: 0.1697 - binary_output_24_loss: 0.1146 - binary_output_25_loss: 0.1133 - binary_output_26_loss: 0.3598 - binary_output_27_loss: 0.3980 - binary_output_28_loss: 0.3694 - binary_output_29_loss: 0.3605 - binary_output_30_loss: 0.1097 - binary_output_31_loss: 0.3323 - binary_output_32_loss: 0.1624 - binary_output_33_loss: 0.3794 - binary_output_34_loss: 0.5612 - categorical_output_loss: 0.3425 - binary_output_0_binary_accuracy: 0.7754 - binary_output_1_binary_accuracy: 0.9922 - binary_output_2_binary_accuracy: 0.7832 - binary_output_3_binary_accuracy: 0.7559 - binary_output_4_binary_accuracy: 0.8770 - binary_output_5_binary_accuracy: 0.9004 - binary_output_6_binary_accuracy: 0.9297 - binary_output_7_binary_accuracy: 0.9512 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8789 - binary_output_10_binary_accuracy: 0.8340 - binary_output_11_binary_accuracy: 0.8555 - binary_output_12_binary_accuracy: 0.9824 - binary_output_13_binary_accuracy: 0.9219 - binary_output_14_binary_accuracy: 0.9609 - binary_output_15_binary_accuracy: 0.8750 - binary_output_16_binary_accuracy: 0.8652 - binary_output_17_binary_accuracy: 0.6270 - binary_output_18_binary_accuracy: 0.8320 - binary_output_19_binary_accuracy: 0.8379 - binary_output_20_binary_accuracy: 0.8613 - binary_output_21_binary_accuracy: 0.9355 - binary_output_22_binary_accuracy: 0.9844 - binary_output_23_binary_accuracy: 0.9707 - binary_output_24_binary_accuracy: 0.9883 - binary_output_25_binary_accuracy: 0.9707 - binary_output_26_binary_accuracy: 0.8477 - binary_output_27_binary_accuracy: 0.8008 - binary_output_28_binary_accuracy: 0.8398 - binary_output_29_binary_accuracy: 0.7773 - binary_output_30_binary_accuracy: 0.9648 - binary_output_31_binary_accuracy: 0.7812 - binary_output_32_binary_accuracy: 0.9316 - binary_output_33_binary_accuracy: 0.8027 - binary_output_34_binary_accuracy: 0.6758 - categorical_output_sparse_categorical_accuracy: 0.7637\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 1024/22237 [>.............................] - ETA: 5s - loss: 9.9963 - binary_output_0_loss: 0.3869 - binary_output_1_loss: 0.0625 - binary_output_2_loss: 0.5021 - binary_output_3_loss: 0.4274 - binary_output_4_loss: 0.2770 - binary_output_5_loss: 0.2668 - binary_output_6_loss: 0.2271 - binary_output_7_loss: 0.1792 - binary_output_8_loss: 4.4031e-04 - binary_output_9_loss: 0.2473 - binary_output_10_loss: 0.3789 - binary_output_11_loss: 0.3226 - binary_output_12_loss: 0.1193 - binary_output_13_loss: 0.2623 - binary_output_14_loss: 0.1534 - binary_output_15_loss: 0.2988 - binary_output_16_loss: 0.2918 - binary_output_17_loss: 0.6264 - binary_output_18_loss: 0.3635 - binary_output_19_loss: 0.3280 - binary_output_20_loss: 0.2756 - binary_output_21_loss: 0.1900 - binary_output_22_loss: 0.0894 - binary_output_23_loss: 0.1239 - binary_output_24_loss: 0.1120 - binary_output_25_loss: 0.1101 - binary_output_26_loss: 0.3218 - binary_output_27_loss: 0.3929 - binary_output_28_loss: 0.3626 - binary_output_29_loss: 0.3663 - binary_output_30_loss: 0.1552 - binary_output_31_loss: 0.3492 - binary_output_32_loss: 0.1659 - binary_output_33_loss: 0.3934 - binary_output_34_loss: 0.5402 - categorical_output_loss: 0.3261 - binary_output_0_binary_accuracy: 0.7510 - binary_output_1_binary_accuracy: 0.9922 - binary_output_2_binary_accuracy: 0.7246 - binary_output_3_binary_accuracy: 0.7041 - binary_output_4_binary_accuracy: 0.8604 - binary_output_5_binary_accuracy: 0.8740 - binary_output_6_binary_accuracy: 0.9287 - binary_output_7_binary_accuracy: 0.9395 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8535 - binary_output_10_binary_accuracy: 0.8037 - binary_output_11_binary_accuracy: 0.8340 - binary_output_12_binary_accuracy: 0.9688 - binary_output_13_binary_accuracy: 0.9082 - binary_output_14_binary_accuracy: 0.9561 - binary_output_15_binary_accuracy: 0.8584 - binary_output_16_binary_accuracy: 0.8545 - binary_output_17_binary_accuracy: 0.5889 - binary_output_18_binary_accuracy: 0.8125 - binary_output_19_binary_accuracy: 0.8047 - binary_output_20_binary_accuracy: 0.8379 - binary_output_21_binary_accuracy: 0.9121 - binary_output_22_binary_accuracy: 0.9824 - binary_output_23_binary_accuracy: 0.9629 - binary_output_24_binary_accuracy: 0.9854 - binary_output_25_binary_accuracy: 0.9531 - binary_output_26_binary_accuracy: 0.8340 - binary_output_27_binary_accuracy: 0.7734 - binary_output_28_binary_accuracy: 0.8027 - binary_output_29_binary_accuracy: 0.7598 - binary_output_30_binary_accuracy: 0.9570 - binary_output_31_binary_accuracy: 0.7480 - binary_output_32_binary_accuracy: 0.9092 - binary_output_33_binary_accuracy: 0.7744 - binary_output_34_binary_accuracy: 0.6650 - categorical_output_sparse_categorical_accuracy: 0.7900 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22237/22237 [==============================] - 5s 242us/step - loss: 9.9713 - binary_output_0_loss: 0.4414 - binary_output_1_loss: 0.0839 - binary_output_2_loss: 0.4904 - binary_output_3_loss: 0.4518 - binary_output_4_loss: 0.2913 - binary_output_5_loss: 0.2547 - binary_output_6_loss: 0.2046 - binary_output_7_loss: 0.1644 - binary_output_8_loss: 5.5614e-04 - binary_output_9_loss: 0.2887 - binary_output_10_loss: 0.3804 - binary_output_11_loss: 0.3299 - binary_output_12_loss: 0.1185 - binary_output_13_loss: 0.2377 - binary_output_14_loss: 0.1463 - binary_output_15_loss: 0.2697 - binary_output_16_loss: 0.3054 - binary_output_17_loss: 0.6179 - binary_output_18_loss: 0.3164 - binary_output_19_loss: 0.3187 - binary_output_20_loss: 0.2730 - binary_output_21_loss: 0.2016 - binary_output_22_loss: 0.1020 - binary_output_23_loss: 0.1218 - binary_output_24_loss: 0.0781 - binary_output_25_loss: 0.1304 - binary_output_26_loss: 0.2750 - binary_output_27_loss: 0.3922 - binary_output_28_loss: 0.3404 - binary_output_29_loss: 0.3716 - binary_output_30_loss: 0.1306 - binary_output_31_loss: 0.3630 - binary_output_32_loss: 0.1925 - binary_output_33_loss: 0.3622 - binary_output_34_loss: 0.5587 - categorical_output_loss: 0.3638 - binary_output_0_binary_accuracy: 0.7417 - binary_output_1_binary_accuracy: 0.9905 - binary_output_2_binary_accuracy: 0.7367 - binary_output_3_binary_accuracy: 0.7060 - binary_output_4_binary_accuracy: 0.8479 - binary_output_5_binary_accuracy: 0.8739 - binary_output_6_binary_accuracy: 0.9246 - binary_output_7_binary_accuracy: 0.9313 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8385 - binary_output_10_binary_accuracy: 0.7736 - binary_output_11_binary_accuracy: 0.8200 - binary_output_12_binary_accuracy: 0.9633 - binary_output_13_binary_accuracy: 0.9119 - binary_output_14_binary_accuracy: 0.9588 - binary_output_15_binary_accuracy: 0.8576 - binary_output_16_binary_accuracy: 0.8364 - binary_output_17_binary_accuracy: 0.5709 - binary_output_18_binary_accuracy: 0.8213 - binary_output_19_binary_accuracy: 0.8175 - binary_output_20_binary_accuracy: 0.8439 - binary_output_21_binary_accuracy: 0.9084 - binary_output_22_binary_accuracy: 0.9816 - binary_output_23_binary_accuracy: 0.9596 - binary_output_24_binary_accuracy: 0.9884 - binary_output_25_binary_accuracy: 0.9519 - binary_output_26_binary_accuracy: 0.8390 - binary_output_27_binary_accuracy: 0.7837 - binary_output_28_binary_accuracy: 0.8039 - binary_output_29_binary_accuracy: 0.7800 - binary_output_30_binary_accuracy: 0.9595 - binary_output_31_binary_accuracy: 0.7764 - binary_output_32_binary_accuracy: 0.9028 - binary_output_33_binary_accuracy: 0.7621 - binary_output_34_binary_accuracy: 0.6462 - categorical_output_sparse_categorical_accuracy: 0.7953\n",
      "Epoch 30/40\n",
      "22237/22237 [==============================] - 6s 248us/step - loss: 9.8868 - binary_output_0_loss: 0.4442 - binary_output_1_loss: 0.0816 - binary_output_2_loss: 0.4857 - binary_output_3_loss: 0.4465 - binary_output_4_loss: 0.2819 - binary_output_5_loss: 0.2563 - binary_output_6_loss: 0.2086 - binary_output_7_loss: 0.1586 - binary_output_8_loss: 5.6760e-04 - binary_output_9_loss: 0.2856 - binary_output_10_loss: 0.3814 - binary_output_11_loss: 0.3235 - binary_output_12_loss: 0.1141 - binary_output_13_loss: 0.2357 - binary_output_14_loss: 0.1492 - binary_output_15_loss: 0.2612 - binary_output_16_loss: 0.3037 - binary_output_17_loss: 0.6196 - binary_output_18_loss: 0.3049 - binary_output_19_loss: 0.3201 - binary_output_20_loss: 0.2790 - binary_output_21_loss: 0.2020 - binary_output_22_loss: 0.0986 - binary_output_23_loss: 0.1172 - binary_output_24_loss: 0.0766 - binary_output_25_loss: 0.1264 - binary_output_26_loss: 0.2683 - binary_output_27_loss: 0.3894 - binary_output_28_loss: 0.3356 - binary_output_29_loss: 0.3637 - binary_output_30_loss: 0.1283 - binary_output_31_loss: 0.3536 - binary_output_32_loss: 0.1913 - binary_output_33_loss: 0.3626 - binary_output_34_loss: 0.5603 - categorical_output_loss: 0.3689 - binary_output_0_binary_accuracy: 0.7396 - binary_output_1_binary_accuracy: 0.9901 - binary_output_2_binary_accuracy: 0.7394 - binary_output_3_binary_accuracy: 0.7078 - binary_output_4_binary_accuracy: 0.8480 - binary_output_5_binary_accuracy: 0.8757 - binary_output_6_binary_accuracy: 0.9240 - binary_output_7_binary_accuracy: 0.9329 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8434 - binary_output_10_binary_accuracy: 0.7743 - binary_output_11_binary_accuracy: 0.8212 - binary_output_12_binary_accuracy: 0.9630 - binary_output_13_binary_accuracy: 0.9131 - binary_output_14_binary_accuracy: 0.9585 - binary_output_15_binary_accuracy: 0.8588 - binary_output_16_binary_accuracy: 0.8415 - binary_output_17_binary_accuracy: 0.5776 - binary_output_18_binary_accuracy: 0.8237 - binary_output_19_binary_accuracy: 0.8204 - binary_output_20_binary_accuracy: 0.8392 - binary_output_21_binary_accuracy: 0.9079 - binary_output_22_binary_accuracy: 0.9812 - binary_output_23_binary_accuracy: 0.9602 - binary_output_24_binary_accuracy: 0.9888 - binary_output_25_binary_accuracy: 0.9487 - binary_output_26_binary_accuracy: 0.8426 - binary_output_27_binary_accuracy: 0.7846 - binary_output_28_binary_accuracy: 0.8112 - binary_output_29_binary_accuracy: 0.7806 - binary_output_30_binary_accuracy: 0.9624 - binary_output_31_binary_accuracy: 0.7796 - binary_output_32_binary_accuracy: 0.8991 - binary_output_33_binary_accuracy: 0.7611 - binary_output_34_binary_accuracy: 0.6476 - categorical_output_sparse_categorical_accuracy: 0.7959\n",
      "Epoch 31/40\n",
      " 1024/22237 [>.............................] - ETA: 5s - loss: 10.0553 - binary_output_0_loss: 0.4153 - binary_output_1_loss: 0.0763 - binary_output_2_loss: 0.4959 - binary_output_3_loss: 0.4306 - binary_output_4_loss: 0.2529 - binary_output_5_loss: 0.3052 - binary_output_6_loss: 0.2432 - binary_output_7_loss: 0.2199 - binary_output_8_loss: 5.8869e-04 - binary_output_9_loss: 0.3192 - binary_output_10_loss: 0.3852 - binary_output_11_loss: 0.2994 - binary_output_12_loss: 0.0811 - binary_output_13_loss: 0.2242 - binary_output_14_loss: 0.1644 - binary_output_15_loss: 0.2708 - binary_output_16_loss: 0.3169 - binary_output_17_loss: 0.5846 - binary_output_18_loss: 0.3447 - binary_output_19_loss: 0.3181 - binary_output_20_loss: 0.3075 - binary_output_21_loss: 0.1800 - binary_output_22_loss: 0.1037 - binary_output_23_loss: 0.1484 - binary_output_24_loss: 0.0394 - binary_output_25_loss: 0.1235 - binary_output_26_loss: 0.3124 - binary_output_27_loss: 0.4155 - binary_output_28_loss: 0.3402 - binary_output_29_loss: 0.3933 - binary_output_30_loss: 0.1048 - binary_output_31_loss: 0.3398 - binary_output_32_loss: 0.2398 - binary_output_33_loss: 0.3486 - binary_output_34_loss: 0.5668 - categorical_output_loss: 0.3430 - binary_output_0_binary_accuracy: 0.7441 - binary_output_1_binary_accuracy: 0.9941 - binary_output_2_binary_accuracy: 0.7207 - binary_output_3_binary_accuracy: 0.7256 - binary_output_4_binary_accuracy: 0.8604 - binary_output_5_binary_accuracy: 0.8682 - binary_output_6_binary_accuracy: 0.8965 - binary_output_7_binary_accuracy: 0.9160 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8613 - binary_output_10_binary_accuracy: 0.7998 - binary_output_11_binary_accuracy: 0.8516 - binary_output_12_binary_accuracy: 0.9590 - binary_output_13_binary_accuracy: 0.9268 - binary_output_14_binary_accuracy: 0.9424 - binary_output_15_binary_accuracy: 0.8379 - binary_output_16_binary_accuracy: 0.8213 - binary_output_17_binary_accuracy: 0.5830 - binary_output_18_binary_accuracy: 0.8057 - binary_output_19_binary_accuracy: 0.8174 - binary_output_20_binary_accuracy: 0.8291 - binary_output_21_binary_accuracy: 0.9072 - binary_output_22_binary_accuracy: 0.9873 - binary_output_23_binary_accuracy: 0.9629 - binary_output_24_binary_accuracy: 0.9893 - binary_output_25_binary_accuracy: 0.9502 - binary_output_26_binary_accuracy: 0.8242 - binary_output_27_binary_accuracy: 0.7900 - binary_output_28_binary_accuracy: 0.8096 - binary_output_29_binary_accuracy: 0.7910 - binary_output_30_binary_accuracy: 0.9580 - binary_output_31_binary_accuracy: 0.7920 - binary_output_32_binary_accuracy: 0.8711 - binary_output_33_binary_accuracy: 0.7676 - binary_output_34_binary_accuracy: 0.6416 - categorical_output_sparse_categorical_accuracy: 0.785222237/22237 [==============================] - 5s 245us/step - loss: 9.7151 - binary_output_0_loss: 0.4271 - binary_output_1_loss: 0.0843 - binary_output_2_loss: 0.4730 - binary_output_3_loss: 0.4414 - binary_output_4_loss: 0.2793 - binary_output_5_loss: 0.2471 - binary_output_6_loss: 0.2021 - binary_output_7_loss: 0.1569 - binary_output_8_loss: 5.7738e-04 - binary_output_9_loss: 0.2725 - binary_output_10_loss: 0.3738 - binary_output_11_loss: 0.3163 - binary_output_12_loss: 0.1127 - binary_output_13_loss: 0.2329 - binary_output_14_loss: 0.1441 - binary_output_15_loss: 0.2568 - binary_output_16_loss: 0.2933 - binary_output_17_loss: 0.6125 - binary_output_18_loss: 0.3047 - binary_output_19_loss: 0.3086 - binary_output_20_loss: 0.2730 - binary_output_21_loss: 0.2013 - binary_output_22_loss: 0.0972 - binary_output_23_loss: 0.1178 - binary_output_24_loss: 0.0763 - binary_output_25_loss: 0.1246 - binary_output_26_loss: 0.2682 - binary_output_27_loss: 0.3901 - binary_output_28_loss: 0.3304 - binary_output_29_loss: 0.3605 - binary_output_30_loss: 0.1278 - binary_output_31_loss: 0.3525 - binary_output_32_loss: 0.1889 - binary_output_33_loss: 0.3621 - binary_output_34_loss: 0.5490 - categorical_output_loss: 0.3546 - binary_output_0_binary_accuracy: 0.7465 - binary_output_1_binary_accuracy: 0.9909 - binary_output_2_binary_accuracy: 0.7496 - binary_output_3_binary_accuracy: 0.7156 - binary_output_4_binary_accuracy: 0.8547 - binary_output_5_binary_accuracy: 0.8739 - binary_output_6_binary_accuracy: 0.9214 - binary_output_7_binary_accuracy: 0.9334 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8459 - binary_output_10_binary_accuracy: 0.7773 - binary_output_11_binary_accuracy: 0.8239 - binary_output_12_binary_accuracy: 0.9618 - binary_output_13_binary_accuracy: 0.9145 - binary_output_14_binary_accuracy: 0.9560 - binary_output_15_binary_accuracy: 0.8603 - binary_output_16_binary_accuracy: 0.8430 - binary_output_17_binary_accuracy: 0.5816 - binary_output_18_binary_accuracy: 0.8245 - binary_output_19_binary_accuracy: 0.8278 - binary_output_20_binary_accuracy: 0.8441 - binary_output_21_binary_accuracy: 0.9133 - binary_output_22_binary_accuracy: 0.9802 - binary_output_23_binary_accuracy: 0.9602 - binary_output_24_binary_accuracy: 0.9887 - binary_output_25_binary_accuracy: 0.9510 - binary_output_26_binary_accuracy: 0.8410 - binary_output_27_binary_accuracy: 0.7876 - binary_output_28_binary_accuracy: 0.8111 - binary_output_29_binary_accuracy: 0.7864 - binary_output_30_binary_accuracy: 0.9616 - binary_output_31_binary_accuracy: 0.7867 - binary_output_32_binary_accuracy: 0.9003 - binary_output_33_binary_accuracy: 0.7622 - binary_output_34_binary_accuracy: 0.6549 - categorical_output_sparse_categorical_accuracy: 0.7953\n",
      "Epoch 32/40\n",
      "22237/22237 [==============================] - 5s 245us/step - loss: 9.6194 - binary_output_0_loss: 0.4259 - binary_output_1_loss: 0.0820 - binary_output_2_loss: 0.4747 - binary_output_3_loss: 0.4390 - binary_output_4_loss: 0.2793 - binary_output_5_loss: 0.2488 - binary_output_6_loss: 0.2008 - binary_output_7_loss: 0.1589 - binary_output_8_loss: 5.2584e-04 - binary_output_9_loss: 0.2730 - binary_output_10_loss: 0.3629 - binary_output_11_loss: 0.3218 - binary_output_12_loss: 0.1143 - binary_output_13_loss: 0.2309 - binary_output_14_loss: 0.1414 - binary_output_15_loss: 0.2530 - binary_output_16_loss: 0.2915 - binary_output_17_loss: 0.6128 - binary_output_18_loss: 0.2990 - binary_output_19_loss: 0.3081 - binary_output_20_loss: 0.2672 - binary_output_21_loss: 0.1996 - binary_output_22_loss: 0.0949 - binary_output_23_loss: 0.1155 - binary_output_24_loss: 0.0752 - binary_output_25_loss: 0.1225 - binary_output_26_loss: 0.2618 - binary_output_27_loss: 0.3831 - binary_output_28_loss: 0.3262 - binary_output_29_loss: 0.3524 - binary_output_30_loss: 0.1262 - binary_output_31_loss: 0.3445 - binary_output_32_loss: 0.1857 - binary_output_33_loss: 0.3536 - binary_output_34_loss: 0.5395 - categorical_output_loss: 0.3511 - binary_output_0_binary_accuracy: 0.7554 - binary_output_1_binary_accuracy: 0.9900 - binary_output_2_binary_accuracy: 0.7497 - binary_output_3_binary_accuracy: 0.7178 - binary_output_4_binary_accuracy: 0.8527 - binary_output_5_binary_accuracy: 0.8740 - binary_output_6_binary_accuracy: 0.9233 - binary_output_7_binary_accuracy: 0.9348 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8497 - binary_output_10_binary_accuracy: 0.7841 - binary_output_11_binary_accuracy: 0.8273 - binary_output_12_binary_accuracy: 0.9624 - binary_output_13_binary_accuracy: 0.9120 - binary_output_14_binary_accuracy: 0.9586 - binary_output_15_binary_accuracy: 0.8623 - binary_output_16_binary_accuracy: 0.8496 - binary_output_17_binary_accuracy: 0.5826 - binary_output_18_binary_accuracy: 0.8292 - binary_output_19_binary_accuracy: 0.8219 - binary_output_20_binary_accuracy: 0.8435 - binary_output_21_binary_accuracy: 0.9075 - binary_output_22_binary_accuracy: 0.9800 - binary_output_23_binary_accuracy: 0.9586 - binary_output_24_binary_accuracy: 0.9884 - binary_output_25_binary_accuracy: 0.9504 - binary_output_26_binary_accuracy: 0.8445 - binary_output_27_binary_accuracy: 0.7896 - binary_output_28_binary_accuracy: 0.8158 - binary_output_29_binary_accuracy: 0.7907 - binary_output_30_binary_accuracy: 0.9615 - binary_output_31_binary_accuracy: 0.7904 - binary_output_32_binary_accuracy: 0.9039 - binary_output_33_binary_accuracy: 0.7658 - binary_output_34_binary_accuracy: 0.6630 - categorical_output_sparse_categorical_accuracy: 0.7986\n",
      "Epoch 33/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  512/22237 [..............................] - ETA: 5s - loss: 10.1304 - binary_output_0_loss: 0.4552 - binary_output_1_loss: 0.0783 - binary_output_2_loss: 0.4951 - binary_output_3_loss: 0.4439 - binary_output_4_loss: 0.3434 - binary_output_5_loss: 0.3045 - binary_output_6_loss: 0.1564 - binary_output_7_loss: 0.2669 - binary_output_8_loss: 3.2989e-04 - binary_output_9_loss: 0.2995 - binary_output_10_loss: 0.3551 - binary_output_11_loss: 0.3408 - binary_output_12_loss: 0.0844 - binary_output_13_loss: 0.2208 - binary_output_14_loss: 0.2515 - binary_output_15_loss: 0.2633 - binary_output_16_loss: 0.3543 - binary_output_17_loss: 0.6404 - binary_output_18_loss: 0.2747 - binary_output_19_loss: 0.3338 - binary_output_20_loss: 0.3302 - binary_output_21_loss: 0.1939 - binary_output_22_loss: 0.1565 - binary_output_23_loss: 0.1237 - binary_output_24_loss: 0.0234 - binary_output_25_loss: 0.1077 - binary_output_26_loss: 0.2575 - binary_output_27_loss: 0.3117 - binary_output_28_loss: 0.3524 - binary_output_29_loss: 0.2950 - binary_output_30_loss: 0.2044 - binary_output_31_loss: 0.3396 - binary_output_32_loss: 0.2222 - binary_output_33_loss: 0.3776 - binary_output_34_loss: 0.5901 - categorical_output_loss: 0.2816 - binary_output_0_binary_accuracy: 0.6934 - binary_output_1_binary_accuracy: 0.9902 - binary_output_2_binary_accuracy: 0.7266 - binary_output_3_binary_accuracy: 0.7090 - binary_output_4_binary_accuracy: 0.8203 - binary_output_5_binary_accuracy: 0.8887 - binary_output_6_binary_accuracy: 0.9297 - binary_output_7_binary_accuracy: 0.9453 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7695 - binary_output_10_binary_accuracy: 0.7402 - binary_output_11_binary_accuracy: 0.8125 - binary_output_12_binary_accuracy: 0.9688 - binary_output_13_binary_accuracy: 0.8906 - binary_output_14_binary_accuracy: 0.9531 - binary_output_15_binary_accuracy: 0.8965 - binary_output_16_binary_accuracy: 0.8672 - binary_output_17_binary_accuracy: 0.5859 - binary_output_18_binary_accuracy: 0.8320 - binary_output_19_binary_accuracy: 0.8496 - binary_output_20_binary_accuracy: 0.8438 - binary_output_21_binary_accuracy: 0.9219 - binary_output_22_binary_accuracy: 0.9766 - binary_output_23_binary_accuracy: 0.9668 - binary_output_24_binary_accuracy: 0.9961 - binary_output_25_binary_accuracy: 0.9648 - binary_output_26_binary_accuracy: 0.8516 - binary_output_27_binary_accuracy: 0.8340 - binary_output_28_binary_accuracy: 0.8477 - binary_output_29_binary_accuracy: 0.8086 - binary_output_30_binary_accuracy: 0.9688 - binary_output_31_binary_accuracy: 0.7578 - binary_output_32_binary_accuracy: 0.9160 - binary_output_33_binary_accuracy: 0.7715 - binary_output_34_binary_accuracy: 0.6641 - categorical_output_sparse_categorical_accuracy: 0.7715\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 1024/22237 [>.............................] - ETA: 5s - loss: 9.7116 - binary_output_0_loss: 0.4317 - binary_output_1_loss: 0.0554 - binary_output_2_loss: 0.4824 - binary_output_3_loss: 0.4468 - binary_output_4_loss: 0.3099 - binary_output_5_loss: 0.2745 - binary_output_6_loss: 0.2026 - binary_output_7_loss: 0.2118 - binary_output_8_loss: 4.4715e-04 - binary_output_9_loss: 0.2684 - binary_output_10_loss: 0.3514 - binary_output_11_loss: 0.3228 - binary_output_12_loss: 0.0989 - binary_output_13_loss: 0.1946 - binary_output_14_loss: 0.2009 - binary_output_15_loss: 0.2513 - binary_output_16_loss: 0.3304 - binary_output_17_loss: 0.6130 - binary_output_18_loss: 0.2820 - binary_output_19_loss: 0.3187 - binary_output_20_loss: 0.2900 - binary_output_21_loss: 0.2237 - binary_output_22_loss: 0.1124 - binary_output_23_loss: 0.0965 - binary_output_24_loss: 0.0349 - binary_output_25_loss: 0.1021 - binary_output_26_loss: 0.2601 - binary_output_27_loss: 0.3423 - binary_output_28_loss: 0.3210 - binary_output_29_loss: 0.3150 - binary_output_30_loss: 0.1553 - binary_output_31_loss: 0.3388 - binary_output_32_loss: 0.2188 - binary_output_33_loss: 0.3553 - binary_output_34_loss: 0.5579 - categorical_output_loss: 0.3395 - binary_output_0_binary_accuracy: 0.7158 - binary_output_1_binary_accuracy: 0.9873 - binary_output_2_binary_accuracy: 0.7041 - binary_output_3_binary_accuracy: 0.7070 - binary_output_4_binary_accuracy: 0.8447 - binary_output_5_binary_accuracy: 0.8760 - binary_output_6_binary_accuracy: 0.9043 - binary_output_7_binary_accuracy: 0.9141 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8291 - binary_output_10_binary_accuracy: 0.7783 - binary_output_11_binary_accuracy: 0.8096 - binary_output_12_binary_accuracy: 0.9688 - binary_output_13_binary_accuracy: 0.9180 - binary_output_14_binary_accuracy: 0.9434 - binary_output_15_binary_accuracy: 0.8682 - binary_output_16_binary_accuracy: 0.8271 - binary_output_17_binary_accuracy: 0.5840 - binary_output_18_binary_accuracy: 0.8066 - binary_output_19_binary_accuracy: 0.8164 - binary_output_20_binary_accuracy: 0.8252 - binary_output_21_binary_accuracy: 0.9111 - binary_output_22_binary_accuracy: 0.9805 - binary_output_23_binary_accuracy: 0.9609 - binary_output_24_binary_accuracy: 0.9941 - binary_output_25_binary_accuracy: 0.9600 - binary_output_26_binary_accuracy: 0.8330 - binary_output_27_binary_accuracy: 0.8018 - binary_output_28_binary_accuracy: 0.8174 - binary_output_29_binary_accuracy: 0.7979 - binary_output_30_binary_accuracy: 0.9521 - binary_output_31_binary_accuracy: 0.7734 - binary_output_32_binary_accuracy: 0.8916 - binary_output_33_binary_accuracy: 0.7646 - binary_output_34_binary_accuracy: 0.6465 - categorical_output_sparse_categorical_accuracy: 0.7861 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22237/22237 [==============================] - 6s 261us/step - loss: 9.5301 - binary_output_0_loss: 0.4313 - binary_output_1_loss: 0.0808 - binary_output_2_loss: 0.4547 - binary_output_3_loss: 0.4307 - binary_output_4_loss: 0.2705 - binary_output_5_loss: 0.2455 - binary_output_6_loss: 0.1952 - binary_output_7_loss: 0.1553 - binary_output_8_loss: 5.4439e-04 - binary_output_9_loss: 0.2732 - binary_output_10_loss: 0.3653 - binary_output_11_loss: 0.3179 - binary_output_12_loss: 0.1125 - binary_output_13_loss: 0.2310 - binary_output_14_loss: 0.1416 - binary_output_15_loss: 0.2482 - binary_output_16_loss: 0.2907 - binary_output_17_loss: 0.6000 - binary_output_18_loss: 0.2949 - binary_output_19_loss: 0.3113 - binary_output_20_loss: 0.2701 - binary_output_21_loss: 0.2012 - binary_output_22_loss: 0.0956 - binary_output_23_loss: 0.1104 - binary_output_24_loss: 0.0740 - binary_output_25_loss: 0.1226 - binary_output_26_loss: 0.2600 - binary_output_27_loss: 0.3713 - binary_output_28_loss: 0.3260 - binary_output_29_loss: 0.3495 - binary_output_30_loss: 0.1277 - binary_output_31_loss: 0.3273 - binary_output_32_loss: 0.1851 - binary_output_33_loss: 0.3557 - binary_output_34_loss: 0.5359 - categorical_output_loss: 0.3554 - binary_output_0_binary_accuracy: 0.7481 - binary_output_1_binary_accuracy: 0.9883 - binary_output_2_binary_accuracy: 0.7564 - binary_output_3_binary_accuracy: 0.7201 - binary_output_4_binary_accuracy: 0.8536 - binary_output_5_binary_accuracy: 0.8770 - binary_output_6_binary_accuracy: 0.9221 - binary_output_7_binary_accuracy: 0.9356 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8476 - binary_output_10_binary_accuracy: 0.7856 - binary_output_11_binary_accuracy: 0.8250 - binary_output_12_binary_accuracy: 0.9627 - binary_output_13_binary_accuracy: 0.9143 - binary_output_14_binary_accuracy: 0.9575 - binary_output_15_binary_accuracy: 0.8656 - binary_output_16_binary_accuracy: 0.8514 - binary_output_17_binary_accuracy: 0.5829 - binary_output_18_binary_accuracy: 0.8296 - binary_output_19_binary_accuracy: 0.8248 - binary_output_20_binary_accuracy: 0.8449 - binary_output_21_binary_accuracy: 0.9124 - binary_output_22_binary_accuracy: 0.9812 - binary_output_23_binary_accuracy: 0.9601 - binary_output_24_binary_accuracy: 0.9874 - binary_output_25_binary_accuracy: 0.9507 - binary_output_26_binary_accuracy: 0.8438 - binary_output_27_binary_accuracy: 0.7943 - binary_output_28_binary_accuracy: 0.8172 - binary_output_29_binary_accuracy: 0.7885 - binary_output_30_binary_accuracy: 0.9615 - binary_output_31_binary_accuracy: 0.8026 - binary_output_32_binary_accuracy: 0.9084 - binary_output_33_binary_accuracy: 0.7679 - binary_output_34_binary_accuracy: 0.6630 - categorical_output_sparse_categorical_accuracy: 0.7969\n",
      "Epoch 34/40\n",
      "22237/22237 [==============================] - 6s 269us/step - loss: 9.3870 - binary_output_0_loss: 0.4232 - binary_output_1_loss: 0.0797 - binary_output_2_loss: 0.4597 - binary_output_3_loss: 0.4266 - binary_output_4_loss: 0.2678 - binary_output_5_loss: 0.2451 - binary_output_6_loss: 0.1951 - binary_output_7_loss: 0.1492 - binary_output_8_loss: 4.8905e-04 - binary_output_9_loss: 0.2587 - binary_output_10_loss: 0.3528 - binary_output_11_loss: 0.3110 - binary_output_12_loss: 0.1088 - binary_output_13_loss: 0.2249 - binary_output_14_loss: 0.1379 - binary_output_15_loss: 0.2595 - binary_output_16_loss: 0.2887 - binary_output_17_loss: 0.6068 - binary_output_18_loss: 0.2899 - binary_output_19_loss: 0.3019 - binary_output_20_loss: 0.2659 - binary_output_21_loss: 0.1955 - binary_output_22_loss: 0.0924 - binary_output_23_loss: 0.1082 - binary_output_24_loss: 0.0730 - binary_output_25_loss: 0.1198 - binary_output_26_loss: 0.2556 - binary_output_27_loss: 0.3694 - binary_output_28_loss: 0.3220 - binary_output_29_loss: 0.3533 - binary_output_30_loss: 0.1205 - binary_output_31_loss: 0.3164 - binary_output_32_loss: 0.1811 - binary_output_33_loss: 0.3539 - binary_output_34_loss: 0.5348 - categorical_output_loss: 0.3449 - binary_output_0_binary_accuracy: 0.7484 - binary_output_1_binary_accuracy: 0.9893 - binary_output_2_binary_accuracy: 0.7550 - binary_output_3_binary_accuracy: 0.7308 - binary_output_4_binary_accuracy: 0.8571 - binary_output_5_binary_accuracy: 0.8767 - binary_output_6_binary_accuracy: 0.9218 - binary_output_7_binary_accuracy: 0.9344 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8535 - binary_output_10_binary_accuracy: 0.7915 - binary_output_11_binary_accuracy: 0.8313 - binary_output_12_binary_accuracy: 0.9634 - binary_output_13_binary_accuracy: 0.9137 - binary_output_14_binary_accuracy: 0.9573 - binary_output_15_binary_accuracy: 0.8589 - binary_output_16_binary_accuracy: 0.8480 - binary_output_17_binary_accuracy: 0.5878 - binary_output_18_binary_accuracy: 0.8340 - binary_output_19_binary_accuracy: 0.8300 - binary_output_20_binary_accuracy: 0.8475 - binary_output_21_binary_accuracy: 0.9109 - binary_output_22_binary_accuracy: 0.9804 - binary_output_23_binary_accuracy: 0.9633 - binary_output_24_binary_accuracy: 0.9866 - binary_output_25_binary_accuracy: 0.9527 - binary_output_26_binary_accuracy: 0.8469 - binary_output_27_binary_accuracy: 0.7962 - binary_output_28_binary_accuracy: 0.8174 - binary_output_29_binary_accuracy: 0.7899 - binary_output_30_binary_accuracy: 0.9627 - binary_output_31_binary_accuracy: 0.8116 - binary_output_32_binary_accuracy: 0.9030 - binary_output_33_binary_accuracy: 0.7658 - binary_output_34_binary_accuracy: 0.6657 - categorical_output_sparse_categorical_accuracy: 0.7985\n",
      "Epoch 35/40\n",
      " 1024/22237 [>.............................] - ETA: 8s - loss: 9.1640 - binary_output_0_loss: 0.4853 - binary_output_1_loss: 0.0437 - binary_output_2_loss: 0.4568 - binary_output_3_loss: 0.4273 - binary_output_4_loss: 0.3084 - binary_output_5_loss: 0.2800 - binary_output_6_loss: 0.1199 - binary_output_7_loss: 0.1151 - binary_output_8_loss: 5.2045e-04 - binary_output_9_loss: 0.2587 - binary_output_10_loss: 0.3292 - binary_output_11_loss: 0.2572 - binary_output_12_loss: 0.1130 - binary_output_13_loss: 0.1722 - binary_output_14_loss: 0.1410 - binary_output_15_loss: 0.2029 - binary_output_16_loss: 0.2977 - binary_output_17_loss: 0.6164 - binary_output_18_loss: 0.2696 - binary_output_19_loss: 0.3042 - binary_output_20_loss: 0.2531 - binary_output_21_loss: 0.2049 - binary_output_22_loss: 0.1095 - binary_output_23_loss: 0.0903 - binary_output_24_loss: 0.0780 - binary_output_25_loss: 0.0956 - binary_output_26_loss: 0.2635 - binary_output_27_loss: 0.3816 - binary_output_28_loss: 0.3388 - binary_output_29_loss: 0.3139 - binary_output_30_loss: 0.0902 - binary_output_31_loss: 0.3688 - binary_output_32_loss: 0.2038 - binary_output_33_loss: 0.3293 - binary_output_34_loss: 0.5018 - categorical_output_loss: 0.3419 - binary_output_0_binary_accuracy: 0.7959 - binary_output_1_binary_accuracy: 0.9941 - binary_output_2_binary_accuracy: 0.7715 - binary_output_3_binary_accuracy: 0.7393 - binary_output_4_binary_accuracy: 0.8633 - binary_output_5_binary_accuracy: 0.8730 - binary_output_6_binary_accuracy: 0.9297 - binary_output_7_binary_accuracy: 0.9473 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8594 - binary_output_10_binary_accuracy: 0.8125 - binary_output_11_binary_accuracy: 0.8477 - binary_output_12_binary_accuracy: 0.9629 - binary_output_13_binary_accuracy: 0.9111 - binary_output_14_binary_accuracy: 0.9453 - binary_output_15_binary_accuracy: 0.8721 - binary_output_16_binary_accuracy: 0.8594 - binary_output_17_binary_accuracy: 0.5986 - binary_output_18_binary_accuracy: 0.8398 - binary_output_19_binary_accuracy: 0.8096 - binary_output_20_binary_accuracy: 0.8545 - binary_output_21_binary_accuracy: 0.8916 - binary_output_22_binary_accuracy: 0.9717 - binary_output_23_binary_accuracy: 0.9561 - binary_output_24_binary_accuracy: 0.9824 - binary_output_25_binary_accuracy: 0.9551 - binary_output_26_binary_accuracy: 0.8408 - binary_output_27_binary_accuracy: 0.7939 - binary_output_28_binary_accuracy: 0.8418 - binary_output_29_binary_accuracy: 0.7959 - binary_output_30_binary_accuracy: 0.9580 - binary_output_31_binary_accuracy: 0.8105 - binary_output_32_binary_accuracy: 0.8926 - binary_output_33_binary_accuracy: 0.7715 - binary_output_34_binary_accuracy: 0.6846 - categorical_output_sparse_categorical_accuracy: 0.7734 22237/22237 [==============================] - 8s 366us/step - loss: 9.3099 - binary_output_0_loss: 0.4153 - binary_output_1_loss: 0.0796 - binary_output_2_loss: 0.4496 - binary_output_3_loss: 0.4237 - binary_output_4_loss: 0.2694 - binary_output_5_loss: 0.2398 - binary_output_6_loss: 0.1941 - binary_output_7_loss: 0.1529 - binary_output_8_loss: 5.2185e-04 - binary_output_9_loss: 0.2536 - binary_output_10_loss: 0.3538 - binary_output_11_loss: 0.3048 - binary_output_12_loss: 0.1080 - binary_output_13_loss: 0.2220 - binary_output_14_loss: 0.1390 - binary_output_15_loss: 0.2504 - binary_output_16_loss: 0.2755 - binary_output_17_loss: 0.6005 - binary_output_18_loss: 0.2896 - binary_output_19_loss: 0.3023 - binary_output_20_loss: 0.2596 - binary_output_21_loss: 0.1968 - binary_output_22_loss: 0.0946 - binary_output_23_loss: 0.1102 - binary_output_24_loss: 0.0728 - binary_output_25_loss: 0.1140 - binary_output_26_loss: 0.2563 - binary_output_27_loss: 0.3703 - binary_output_28_loss: 0.3252 - binary_output_29_loss: 0.3403 - binary_output_30_loss: 0.1250 - binary_output_31_loss: 0.3159 - binary_output_32_loss: 0.1830 - binary_output_33_loss: 0.3487 - binary_output_34_loss: 0.5310 - categorical_output_loss: 0.3458 - binary_output_0_binary_accuracy: 0.7576 - binary_output_1_binary_accuracy: 0.9902 - binary_output_2_binary_accuracy: 0.7604 - binary_output_3_binary_accuracy: 0.7282 - binary_output_4_binary_accuracy: 0.8538 - binary_output_5_binary_accuracy: 0.8747 - binary_output_6_binary_accuracy: 0.9208 - binary_output_7_binary_accuracy: 0.9365 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8585 - binary_output_10_binary_accuracy: 0.7906 - binary_output_11_binary_accuracy: 0.8360 - binary_output_12_binary_accuracy: 0.9631 - binary_output_13_binary_accuracy: 0.9124 - binary_output_14_binary_accuracy: 0.9549 - binary_output_15_binary_accuracy: 0.8628 - binary_output_16_binary_accuracy: 0.8550 - binary_output_17_binary_accuracy: 0.5915 - binary_output_18_binary_accuracy: 0.8364 - binary_output_19_binary_accuracy: 0.8271 - binary_output_20_binary_accuracy: 0.8507 - binary_output_21_binary_accuracy: 0.9084 - binary_output_22_binary_accuracy: 0.9781 - binary_output_23_binary_accuracy: 0.9608 - binary_output_24_binary_accuracy: 0.9858 - binary_output_25_binary_accuracy: 0.9508 - binary_output_26_binary_accuracy: 0.8485 - binary_output_27_binary_accuracy: 0.8011 - binary_output_28_binary_accuracy: 0.8194 - binary_output_29_binary_accuracy: 0.7958 - binary_output_30_binary_accuracy: 0.9612 - binary_output_31_binary_accuracy: 0.8151 - binary_output_32_binary_accuracy: 0.9024 - binary_output_33_binary_accuracy: 0.7738 - binary_output_34_binary_accuracy: 0.6732 - categorical_output_sparse_categorical_accuracy: 0.7993\n",
      "Epoch 36/40\n",
      "22237/22237 [==============================] - 9s 386us/step - loss: 9.1680 - binary_output_0_loss: 0.4155 - binary_output_1_loss: 0.0785 - binary_output_2_loss: 0.4438 - binary_output_3_loss: 0.4158 - binary_output_4_loss: 0.2629 - binary_output_5_loss: 0.2367 - binary_output_6_loss: 0.1897 - binary_output_7_loss: 0.1429 - binary_output_8_loss: 5.0135e-04 - binary_output_9_loss: 0.2553 - binary_output_10_loss: 0.3480 - binary_output_11_loss: 0.3158 - binary_output_12_loss: 0.1055 - binary_output_13_loss: 0.2178 - binary_output_14_loss: 0.1345 - binary_output_15_loss: 0.2480 - binary_output_16_loss: 0.2729 - binary_output_17_loss: 0.5974 - binary_output_18_loss: 0.2855 - binary_output_19_loss: 0.3031 - binary_output_20_loss: 0.2627 - binary_output_21_loss: 0.1913 - binary_output_22_loss: 0.0961 - binary_output_23_loss: 0.1105 - binary_output_24_loss: 0.0686 - binary_output_25_loss: 0.1212 - binary_output_26_loss: 0.2504 - binary_output_27_loss: 0.3540 - binary_output_28_loss: 0.3113 - binary_output_29_loss: 0.3383 - binary_output_30_loss: 0.1151 - binary_output_31_loss: 0.3052 - binary_output_32_loss: 0.1784 - binary_output_33_loss: 0.3398 - binary_output_34_loss: 0.5203 - categorical_output_loss: 0.3363 - binary_output_0_binary_accuracy: 0.7574 - binary_output_1_binary_accuracy: 0.9897 - binary_output_2_binary_accuracy: 0.7675 - binary_output_3_binary_accuracy: 0.7367 - binary_output_4_binary_accuracy: 0.8620 - binary_output_5_binary_accuracy: 0.8781 - binary_output_6_binary_accuracy: 0.9245 - binary_output_7_binary_accuracy: 0.9381 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8589 - binary_output_10_binary_accuracy: 0.7980 - binary_output_11_binary_accuracy: 0.8286 - binary_output_12_binary_accuracy: 0.9637 - binary_output_13_binary_accuracy: 0.9174 - binary_output_14_binary_accuracy: 0.9564 - binary_output_15_binary_accuracy: 0.8629 - binary_output_16_binary_accuracy: 0.8567 - binary_output_17_binary_accuracy: 0.5925 - binary_output_18_binary_accuracy: 0.8383 - binary_output_19_binary_accuracy: 0.8294 - binary_output_20_binary_accuracy: 0.8495 - binary_output_21_binary_accuracy: 0.9109 - binary_output_22_binary_accuracy: 0.9778 - binary_output_23_binary_accuracy: 0.9606 - binary_output_24_binary_accuracy: 0.9865 - binary_output_25_binary_accuracy: 0.9487 - binary_output_26_binary_accuracy: 0.8516 - binary_output_27_binary_accuracy: 0.8038 - binary_output_28_binary_accuracy: 0.8207 - binary_output_29_binary_accuracy: 0.8041 - binary_output_30_binary_accuracy: 0.9629 - binary_output_31_binary_accuracy: 0.8163 - binary_output_32_binary_accuracy: 0.9070 - binary_output_33_binary_accuracy: 0.7719 - binary_output_34_binary_accuracy: 0.6742 - categorical_output_sparse_categorical_accuracy: 0.8015\n",
      "Epoch 37/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  512/22237 [..............................] - ETA: 5s - loss: 9.3852 - binary_output_0_loss: 0.3786 - binary_output_1_loss: 0.1088 - binary_output_2_loss: 0.4334 - binary_output_3_loss: 0.4805 - binary_output_4_loss: 0.2165 - binary_output_5_loss: 0.2379 - binary_output_6_loss: 0.2664 - binary_output_7_loss: 0.2154 - binary_output_8_loss: 5.5271e-04 - binary_output_9_loss: 0.2094 - binary_output_10_loss: 0.3313 - binary_output_11_loss: 0.2690 - binary_output_12_loss: 0.1394 - binary_output_13_loss: 0.2056 - binary_output_14_loss: 0.1797 - binary_output_15_loss: 0.2182 - binary_output_16_loss: 0.3691 - binary_output_17_loss: 0.5943 - binary_output_18_loss: 0.3043 - binary_output_19_loss: 0.2835 - binary_output_20_loss: 0.2752 - binary_output_21_loss: 0.1784 - binary_output_22_loss: 0.0990 - binary_output_23_loss: 0.0740 - binary_output_24_loss: 0.0955 - binary_output_25_loss: 0.1422 - binary_output_26_loss: 0.2626 - binary_output_27_loss: 0.3150 - binary_output_28_loss: 0.3541 - binary_output_29_loss: 0.3352 - binary_output_30_loss: 0.1333 - binary_output_31_loss: 0.2494 - binary_output_32_loss: 0.2997 - binary_output_33_loss: 0.3424 - binary_output_34_loss: 0.4984 - categorical_output_loss: 0.2892 - binary_output_0_binary_accuracy: 0.7695 - binary_output_1_binary_accuracy: 0.9883 - binary_output_2_binary_accuracy: 0.7383 - binary_output_3_binary_accuracy: 0.6660 - binary_output_4_binary_accuracy: 0.8516 - binary_output_5_binary_accuracy: 0.8535 - binary_output_6_binary_accuracy: 0.9023 - binary_output_7_binary_accuracy: 0.9277 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8535 - binary_output_10_binary_accuracy: 0.7812 - binary_output_11_binary_accuracy: 0.7852 - binary_output_12_binary_accuracy: 0.9668 - binary_output_13_binary_accuracy: 0.8906 - binary_output_14_binary_accuracy: 0.9492 - binary_output_15_binary_accuracy: 0.8203 - binary_output_16_binary_accuracy: 0.8398 - binary_output_17_binary_accuracy: 0.5664 - binary_output_18_binary_accuracy: 0.7949 - binary_output_19_binary_accuracy: 0.7773 - binary_output_20_binary_accuracy: 0.8008 - binary_output_21_binary_accuracy: 0.8809 - binary_output_22_binary_accuracy: 0.9766 - binary_output_23_binary_accuracy: 0.9629 - binary_output_24_binary_accuracy: 0.9824 - binary_output_25_binary_accuracy: 0.9531 - binary_output_26_binary_accuracy: 0.8164 - binary_output_27_binary_accuracy: 0.8223 - binary_output_28_binary_accuracy: 0.7832 - binary_output_29_binary_accuracy: 0.7949 - binary_output_30_binary_accuracy: 0.9492 - binary_output_31_binary_accuracy: 0.8340 - binary_output_32_binary_accuracy: 0.8672 - binary_output_33_binary_accuracy: 0.7266 - binary_output_34_binary_accuracy: 0.6660 - categorical_output_sparse_categorical_accuracy: 0.8145\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 1024/22237 [>.............................] - ETA: 5s - loss: 9.1601 - binary_output_0_loss: 0.3864 - binary_output_1_loss: 0.0881 - binary_output_2_loss: 0.4119 - binary_output_3_loss: 0.4248 - binary_output_4_loss: 0.2798 - binary_output_5_loss: 0.2542 - binary_output_6_loss: 0.2230 - binary_output_7_loss: 0.1619 - binary_output_8_loss: 4.8011e-04 - binary_output_9_loss: 0.2235 - binary_output_10_loss: 0.3583 - binary_output_11_loss: 0.3132 - binary_output_12_loss: 0.1362 - binary_output_13_loss: 0.1979 - binary_output_14_loss: 0.1446 - binary_output_15_loss: 0.2651 - binary_output_16_loss: 0.2806 - binary_output_17_loss: 0.5582 - binary_output_18_loss: 0.3078 - binary_output_19_loss: 0.2573 - binary_output_20_loss: 0.2624 - binary_output_21_loss: 0.1368 - binary_output_22_loss: 0.0888 - binary_output_23_loss: 0.0726 - binary_output_24_loss: 0.1079 - binary_output_25_loss: 0.1658 - binary_output_26_loss: 0.2724 - binary_output_27_loss: 0.3324 - binary_output_28_loss: 0.2907 - binary_output_29_loss: 0.3403 - binary_output_30_loss: 0.1071 - binary_output_31_loss: 0.2985 - binary_output_32_loss: 0.2373 - binary_output_33_loss: 0.3498 - binary_output_34_loss: 0.5371 - categorical_output_loss: 0.2870 - binary_output_0_binary_accuracy: 0.7656 - binary_output_1_binary_accuracy: 0.9893 - binary_output_2_binary_accuracy: 0.7549 - binary_output_3_binary_accuracy: 0.7158 - binary_output_4_binary_accuracy: 0.8633 - binary_output_5_binary_accuracy: 0.8789 - binary_output_6_binary_accuracy: 0.9121 - binary_output_7_binary_accuracy: 0.9307 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8818 - binary_output_10_binary_accuracy: 0.8008 - binary_output_11_binary_accuracy: 0.8281 - binary_output_12_binary_accuracy: 0.9697 - binary_output_13_binary_accuracy: 0.9121 - binary_output_14_binary_accuracy: 0.9541 - binary_output_15_binary_accuracy: 0.8506 - binary_output_16_binary_accuracy: 0.8564 - binary_output_17_binary_accuracy: 0.5957 - binary_output_18_binary_accuracy: 0.8271 - binary_output_19_binary_accuracy: 0.8193 - binary_output_20_binary_accuracy: 0.8359 - binary_output_21_binary_accuracy: 0.9111 - binary_output_22_binary_accuracy: 0.9785 - binary_output_23_binary_accuracy: 0.9668 - binary_output_24_binary_accuracy: 0.9814 - binary_output_25_binary_accuracy: 0.9561 - binary_output_26_binary_accuracy: 0.8418 - binary_output_27_binary_accuracy: 0.8291 - binary_output_28_binary_accuracy: 0.8174 - binary_output_29_binary_accuracy: 0.8154 - binary_output_30_binary_accuracy: 0.9551 - binary_output_31_binary_accuracy: 0.8467 - binary_output_32_binary_accuracy: 0.8945 - binary_output_33_binary_accuracy: 0.7578 - binary_output_34_binary_accuracy: 0.6738 - categorical_output_sparse_categorical_accuracy: 0.8125"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22237/22237 [==============================] - 6s 287us/step - loss: 9.1530 - binary_output_0_loss: 0.4123 - binary_output_1_loss: 0.0794 - binary_output_2_loss: 0.4518 - binary_output_3_loss: 0.4212 - binary_output_4_loss: 0.2647 - binary_output_5_loss: 0.2402 - binary_output_6_loss: 0.1913 - binary_output_7_loss: 0.1409 - binary_output_8_loss: 4.8926e-04 - binary_output_9_loss: 0.2445 - binary_output_10_loss: 0.3459 - binary_output_11_loss: 0.3015 - binary_output_12_loss: 0.1083 - binary_output_13_loss: 0.2234 - binary_output_14_loss: 0.1317 - binary_output_15_loss: 0.2503 - binary_output_16_loss: 0.2763 - binary_output_17_loss: 0.5934 - binary_output_18_loss: 0.2834 - binary_output_19_loss: 0.3042 - binary_output_20_loss: 0.2614 - binary_output_21_loss: 0.1873 - binary_output_22_loss: 0.0893 - binary_output_23_loss: 0.1050 - binary_output_24_loss: 0.0747 - binary_output_25_loss: 0.1172 - binary_output_26_loss: 0.2487 - binary_output_27_loss: 0.3579 - binary_output_28_loss: 0.3150 - binary_output_29_loss: 0.3297 - binary_output_30_loss: 0.1237 - binary_output_31_loss: 0.3000 - binary_output_32_loss: 0.1808 - binary_output_33_loss: 0.3452 - binary_output_34_loss: 0.5215 - categorical_output_loss: 0.3403 - binary_output_0_binary_accuracy: 0.7597 - binary_output_1_binary_accuracy: 0.9899 - binary_output_2_binary_accuracy: 0.7628 - binary_output_3_binary_accuracy: 0.7317 - binary_output_4_binary_accuracy: 0.8583 - binary_output_5_binary_accuracy: 0.8788 - binary_output_6_binary_accuracy: 0.9236 - binary_output_7_binary_accuracy: 0.9386 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8669 - binary_output_10_binary_accuracy: 0.7989 - binary_output_11_binary_accuracy: 0.8354 - binary_output_12_binary_accuracy: 0.9646 - binary_output_13_binary_accuracy: 0.9174 - binary_output_14_binary_accuracy: 0.9557 - binary_output_15_binary_accuracy: 0.8637 - binary_output_16_binary_accuracy: 0.8574 - binary_output_17_binary_accuracy: 0.5955 - binary_output_18_binary_accuracy: 0.8386 - binary_output_19_binary_accuracy: 0.8239 - binary_output_20_binary_accuracy: 0.8502 - binary_output_21_binary_accuracy: 0.9126 - binary_output_22_binary_accuracy: 0.9752 - binary_output_23_binary_accuracy: 0.9597 - binary_output_24_binary_accuracy: 0.9852 - binary_output_25_binary_accuracy: 0.9497 - binary_output_26_binary_accuracy: 0.8535 - binary_output_27_binary_accuracy: 0.8069 - binary_output_28_binary_accuracy: 0.8243 - binary_output_29_binary_accuracy: 0.8113 - binary_output_30_binary_accuracy: 0.9639 - binary_output_31_binary_accuracy: 0.8283 - binary_output_32_binary_accuracy: 0.9034 - binary_output_33_binary_accuracy: 0.7736 - binary_output_34_binary_accuracy: 0.6814 - categorical_output_sparse_categorical_accuracy: 0.7995\n",
      "Epoch 38/40\n",
      "22237/22237 [==============================] - 6s 283us/step - loss: 9.0023 - binary_output_0_loss: 0.4060 - binary_output_1_loss: 0.0796 - binary_output_2_loss: 0.4331 - binary_output_3_loss: 0.4148 - binary_output_4_loss: 0.2654 - binary_output_5_loss: 0.2364 - binary_output_6_loss: 0.1819 - binary_output_7_loss: 0.1416 - binary_output_8_loss: 4.9356e-04 - binary_output_9_loss: 0.2481 - binary_output_10_loss: 0.3307 - binary_output_11_loss: 0.3023 - binary_output_12_loss: 0.1023 - binary_output_13_loss: 0.2166 - binary_output_14_loss: 0.1272 - binary_output_15_loss: 0.2533 - binary_output_16_loss: 0.2660 - binary_output_17_loss: 0.5883 - binary_output_18_loss: 0.2811 - binary_output_19_loss: 0.2921 - binary_output_20_loss: 0.2607 - binary_output_21_loss: 0.1842 - binary_output_22_loss: 0.0884 - binary_output_23_loss: 0.1035 - binary_output_24_loss: 0.0738 - binary_output_25_loss: 0.1165 - binary_output_26_loss: 0.2507 - binary_output_27_loss: 0.3479 - binary_output_28_loss: 0.3136 - binary_output_29_loss: 0.3233 - binary_output_30_loss: 0.1212 - binary_output_31_loss: 0.2941 - binary_output_32_loss: 0.1792 - binary_output_33_loss: 0.3408 - binary_output_34_loss: 0.5117 - categorical_output_loss: 0.3363 - binary_output_0_binary_accuracy: 0.7656 - binary_output_1_binary_accuracy: 0.9876 - binary_output_2_binary_accuracy: 0.7706 - binary_output_3_binary_accuracy: 0.7413 - binary_output_4_binary_accuracy: 0.8613 - binary_output_5_binary_accuracy: 0.8787 - binary_output_6_binary_accuracy: 0.9241 - binary_output_7_binary_accuracy: 0.9373 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8669 - binary_output_10_binary_accuracy: 0.8076 - binary_output_11_binary_accuracy: 0.8357 - binary_output_12_binary_accuracy: 0.9645 - binary_output_13_binary_accuracy: 0.9178 - binary_output_14_binary_accuracy: 0.9557 - binary_output_15_binary_accuracy: 0.8639 - binary_output_16_binary_accuracy: 0.8612 - binary_output_17_binary_accuracy: 0.5960 - binary_output_18_binary_accuracy: 0.8412 - binary_output_19_binary_accuracy: 0.8342 - binary_output_20_binary_accuracy: 0.8529 - binary_output_21_binary_accuracy: 0.9134 - binary_output_22_binary_accuracy: 0.9762 - binary_output_23_binary_accuracy: 0.9609 - binary_output_24_binary_accuracy: 0.9856 - binary_output_25_binary_accuracy: 0.9513 - binary_output_26_binary_accuracy: 0.8529 - binary_output_27_binary_accuracy: 0.8095 - binary_output_28_binary_accuracy: 0.8260 - binary_output_29_binary_accuracy: 0.8154 - binary_output_30_binary_accuracy: 0.9598 - binary_output_31_binary_accuracy: 0.8261 - binary_output_32_binary_accuracy: 0.9088 - binary_output_33_binary_accuracy: 0.7756 - binary_output_34_binary_accuracy: 0.6847 - categorical_output_sparse_categorical_accuracy: 0.8000\n",
      "Epoch 39/40\n",
      " 1024/22237 [>.............................] - ETA: 5s - loss: 8.6518 - binary_output_0_loss: 0.3725 - binary_output_1_loss: 0.0275 - binary_output_2_loss: 0.4146 - binary_output_3_loss: 0.4268 - binary_output_4_loss: 0.2697 - binary_output_5_loss: 0.2654 - binary_output_6_loss: 0.2092 - binary_output_7_loss: 0.1425 - binary_output_8_loss: 5.3857e-04 - binary_output_9_loss: 0.2456 - binary_output_10_loss: 0.3471 - binary_output_11_loss: 0.2667 - binary_output_12_loss: 0.0815 - binary_output_13_loss: 0.1734 - binary_output_14_loss: 0.1194 - binary_output_15_loss: 0.2752 - binary_output_16_loss: 0.2628 - binary_output_17_loss: 0.5641 - binary_output_18_loss: 0.2557 - binary_output_19_loss: 0.2876 - binary_output_20_loss: 0.2650 - binary_output_21_loss: 0.1973 - binary_output_22_loss: 0.0530 - binary_output_23_loss: 0.1054 - binary_output_24_loss: 0.0432 - binary_output_25_loss: 0.0957 - binary_output_26_loss: 0.2417 - binary_output_27_loss: 0.3114 - binary_output_28_loss: 0.2914 - binary_output_29_loss: 0.3407 - binary_output_30_loss: 0.0850 - binary_output_31_loss: 0.3006 - binary_output_32_loss: 0.1537 - binary_output_33_loss: 0.3188 - binary_output_34_loss: 0.5096 - categorical_output_loss: 0.3313 - binary_output_0_binary_accuracy: 0.7559 - binary_output_1_binary_accuracy: 0.9902 - binary_output_2_binary_accuracy: 0.8008 - binary_output_3_binary_accuracy: 0.7539 - binary_output_4_binary_accuracy: 0.8760 - binary_output_5_binary_accuracy: 0.8828 - binary_output_6_binary_accuracy: 0.9189 - binary_output_7_binary_accuracy: 0.9385 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8760 - binary_output_10_binary_accuracy: 0.8008 - binary_output_11_binary_accuracy: 0.8584 - binary_output_12_binary_accuracy: 0.9736 - binary_output_13_binary_accuracy: 0.8955 - binary_output_14_binary_accuracy: 0.9561 - binary_output_15_binary_accuracy: 0.8662 - binary_output_16_binary_accuracy: 0.8623 - binary_output_17_binary_accuracy: 0.6035 - binary_output_18_binary_accuracy: 0.8428 - binary_output_19_binary_accuracy: 0.8262 - binary_output_20_binary_accuracy: 0.8379 - binary_output_21_binary_accuracy: 0.9102 - binary_output_22_binary_accuracy: 0.9863 - binary_output_23_binary_accuracy: 0.9727 - binary_output_24_binary_accuracy: 0.9863 - binary_output_25_binary_accuracy: 0.9629 - binary_output_26_binary_accuracy: 0.8418 - binary_output_27_binary_accuracy: 0.7969 - binary_output_28_binary_accuracy: 0.8164 - binary_output_29_binary_accuracy: 0.7803 - binary_output_30_binary_accuracy: 0.9600 - binary_output_31_binary_accuracy: 0.8281 - binary_output_32_binary_accuracy: 0.9043 - binary_output_33_binary_accuracy: 0.7598 - binary_output_34_binary_accuracy: 0.6719 - categorical_output_sparse_categorical_accuracy: 0.802722237/22237 [==============================] - 6s 258us/step - loss: 8.9565 - binary_output_0_loss: 0.4088 - binary_output_1_loss: 0.0775 - binary_output_2_loss: 0.4406 - binary_output_3_loss: 0.4120 - binary_output_4_loss: 0.2582 - binary_output_5_loss: 0.2400 - binary_output_6_loss: 0.1872 - binary_output_7_loss: 0.1414 - binary_output_8_loss: 4.5595e-04 - binary_output_9_loss: 0.2382 - binary_output_10_loss: 0.3403 - binary_output_11_loss: 0.2977 - binary_output_12_loss: 0.1064 - binary_output_13_loss: 0.2148 - binary_output_14_loss: 0.1309 - binary_output_15_loss: 0.2453 - binary_output_16_loss: 0.2691 - binary_output_17_loss: 0.5860 - binary_output_18_loss: 0.2778 - binary_output_19_loss: 0.2987 - binary_output_20_loss: 0.2594 - binary_output_21_loss: 0.1822 - binary_output_22_loss: 0.0910 - binary_output_23_loss: 0.1013 - binary_output_24_loss: 0.0688 - binary_output_25_loss: 0.1120 - binary_output_26_loss: 0.2464 - binary_output_27_loss: 0.3416 - binary_output_28_loss: 0.3104 - binary_output_29_loss: 0.3198 - binary_output_30_loss: 0.1161 - binary_output_31_loss: 0.2874 - binary_output_32_loss: 0.1723 - binary_output_33_loss: 0.3386 - binary_output_34_loss: 0.5044 - categorical_output_loss: 0.3315 - binary_output_0_binary_accuracy: 0.7613 - binary_output_1_binary_accuracy: 0.9879 - binary_output_2_binary_accuracy: 0.7676 - binary_output_3_binary_accuracy: 0.7397 - binary_output_4_binary_accuracy: 0.8632 - binary_output_5_binary_accuracy: 0.8846 - binary_output_6_binary_accuracy: 0.9236 - binary_output_7_binary_accuracy: 0.9379 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8732 - binary_output_10_binary_accuracy: 0.8067 - binary_output_11_binary_accuracy: 0.8414 - binary_output_12_binary_accuracy: 0.9660 - binary_output_13_binary_accuracy: 0.9178 - binary_output_14_binary_accuracy: 0.9591 - binary_output_15_binary_accuracy: 0.8645 - binary_output_16_binary_accuracy: 0.8617 - binary_output_17_binary_accuracy: 0.5980 - binary_output_18_binary_accuracy: 0.8419 - binary_output_19_binary_accuracy: 0.8337 - binary_output_20_binary_accuracy: 0.8523 - binary_output_21_binary_accuracy: 0.9179 - binary_output_22_binary_accuracy: 0.9783 - binary_output_23_binary_accuracy: 0.9599 - binary_output_24_binary_accuracy: 0.9854 - binary_output_25_binary_accuracy: 0.9544 - binary_output_26_binary_accuracy: 0.8545 - binary_output_27_binary_accuracy: 0.8133 - binary_output_28_binary_accuracy: 0.8271 - binary_output_29_binary_accuracy: 0.8169 - binary_output_30_binary_accuracy: 0.9616 - binary_output_31_binary_accuracy: 0.8312 - binary_output_32_binary_accuracy: 0.9050 - binary_output_33_binary_accuracy: 0.7778 - binary_output_34_binary_accuracy: 0.6884 - categorical_output_sparse_categorical_accuracy: 0.8014\n",
      "Epoch 40/40\n",
      "22237/22237 [==============================] - 6s 255us/step - loss: 8.8787 - binary_output_0_loss: 0.3996 - binary_output_1_loss: 0.0753 - binary_output_2_loss: 0.4417 - binary_output_3_loss: 0.4061 - binary_output_4_loss: 0.2596 - binary_output_5_loss: 0.2335 - binary_output_6_loss: 0.1829 - binary_output_7_loss: 0.1398 - binary_output_8_loss: 4.6103e-04 - binary_output_9_loss: 0.2337 - binary_output_10_loss: 0.3323 - binary_output_11_loss: 0.2930 - binary_output_12_loss: 0.1016 - binary_output_13_loss: 0.2091 - binary_output_14_loss: 0.1267 - binary_output_15_loss: 0.2450 - binary_output_16_loss: 0.2623 - binary_output_17_loss: 0.5893 - binary_output_18_loss: 0.2776 - binary_output_19_loss: 0.2959 - binary_output_20_loss: 0.2535 - binary_output_21_loss: 0.1789 - binary_output_22_loss: 0.0907 - binary_output_23_loss: 0.1004 - binary_output_24_loss: 0.0672 - binary_output_25_loss: 0.1142 - binary_output_26_loss: 0.2475 - binary_output_27_loss: 0.3421 - binary_output_28_loss: 0.3097 - binary_output_29_loss: 0.3218 - binary_output_30_loss: 0.1174 - binary_output_31_loss: 0.2829 - binary_output_32_loss: 0.1773 - binary_output_33_loss: 0.3354 - binary_output_34_loss: 0.5144 - categorical_output_loss: 0.3282 - binary_output_0_binary_accuracy: 0.7694 - binary_output_1_binary_accuracy: 0.9884 - binary_output_2_binary_accuracy: 0.7678 - binary_output_3_binary_accuracy: 0.7480 - binary_output_4_binary_accuracy: 0.8620 - binary_output_5_binary_accuracy: 0.8780 - binary_output_6_binary_accuracy: 0.9207 - binary_output_7_binary_accuracy: 0.9394 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8768 - binary_output_10_binary_accuracy: 0.8087 - binary_output_11_binary_accuracy: 0.8396 - binary_output_12_binary_accuracy: 0.9666 - binary_output_13_binary_accuracy: 0.9222 - binary_output_14_binary_accuracy: 0.9572 - binary_output_15_binary_accuracy: 0.8661 - binary_output_16_binary_accuracy: 0.8623 - binary_output_17_binary_accuracy: 0.5950 - binary_output_18_binary_accuracy: 0.8411 - binary_output_19_binary_accuracy: 0.8311 - binary_output_20_binary_accuracy: 0.8532 - binary_output_21_binary_accuracy: 0.9180 - binary_output_22_binary_accuracy: 0.9785 - binary_output_23_binary_accuracy: 0.9624 - binary_output_24_binary_accuracy: 0.9848 - binary_output_25_binary_accuracy: 0.9543 - binary_output_26_binary_accuracy: 0.8558 - binary_output_27_binary_accuracy: 0.8157 - binary_output_28_binary_accuracy: 0.8283 - binary_output_29_binary_accuracy: 0.8198 - binary_output_30_binary_accuracy: 0.9596 - binary_output_31_binary_accuracy: 0.8387 - binary_output_32_binary_accuracy: 0.9124 - binary_output_33_binary_accuracy: 0.7796 - binary_output_34_binary_accuracy: 0.6871 - categorical_output_sparse_categorical_accuracy: 0.8049\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x16d93ffd0>"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train_output,\n",
    "          epochs=40, batch_size=512,\n",
    "         class_weight=classes_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, 50, 50)       1000000     main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 50, 50)       0           embedding_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 46, 64)       16064       dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling1D) (None, 11, 64)       0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_12 (LSTM)                  (None, 100)          66000       max_pooling1d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 100)          0           lstm_12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "binary_output_0 (Dense)         (None, 1)            101         dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "binary_output_1 (Dense)         (None, 1)            101         dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "binary_output_2 (Dense)         (None, 1)            101         dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "binary_output_3 (Dense)         (None, 1)            101         dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "binary_output_4 (Dense)         (None, 1)            101         dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "binary_output_5 (Dense)         (None, 1)            101         dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "binary_output_6 (Dense)         (None, 1)            101         dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "binary_output_7 (Dense)         (None, 1)            101         dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "binary_output_8 (Dense)         (None, 1)            101         dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "binary_output_9 (Dense)         (None, 1)            101         dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "binary_output_10 (Dense)        (None, 1)            101         dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "binary_output_11 (Dense)        (None, 1)            101         dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "binary_output_12 (Dense)        (None, 1)            101         dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "binary_output_13 (Dense)        (None, 1)            101         dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "binary_output_14 (Dense)        (None, 1)            101         dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "binary_output_15 (Dense)        (None, 1)            101         dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "binary_output_16 (Dense)        (None, 1)            101         dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "binary_output_17 (Dense)        (None, 1)            101         dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "binary_output_18 (Dense)        (None, 1)            101         dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "binary_output_19 (Dense)        (None, 1)            101         dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "binary_output_20 (Dense)        (None, 1)            101         dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "binary_output_21 (Dense)        (None, 1)            101         dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "binary_output_22 (Dense)        (None, 1)            101         dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "binary_output_23 (Dense)        (None, 1)            101         dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "binary_output_24 (Dense)        (None, 1)            101         dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "binary_output_25 (Dense)        (None, 1)            101         dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "binary_output_26 (Dense)        (None, 1)            101         dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "binary_output_27 (Dense)        (None, 1)            101         dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "binary_output_28 (Dense)        (None, 1)            101         dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "binary_output_29 (Dense)        (None, 1)            101         dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "binary_output_30 (Dense)        (None, 1)            101         dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "binary_output_31 (Dense)        (None, 1)            101         dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "binary_output_32 (Dense)        (None, 1)            101         dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "binary_output_33 (Dense)        (None, 1)            101         dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "binary_output_34 (Dense)        (None, 1)            101         dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "categorical_output (Dense)      (None, 3)            303         dropout_22[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,085,902\n",
      "Trainable params: 1,085,902\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the dataset is quite imbalanced, we'll use the F1 score to evaluate the model performance, since this metric takes into account both precision and recall.\n",
    "\n",
    "The precision explains how accurate our model is: for those predicted positive, how many of them are actual positive. The recall calculates how many of the actual positives our model capture through labeling it as positive, an important metric for an imbalanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the huge amount of outputs, comparing different results can be quite a challenge, you'd be dealing \n",
    "with a total of 36 metrics to compare between different models. Therefore, in order to better evaluate the model result, a metric combining all the 36 outputs was created:\n",
    "    - Model Metric: sum of all the F1-score of each output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.5 # threshold between classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.76      0.84      3237\n",
      "           1       0.40      0.75      0.52       688\n",
      "\n",
      "    accuracy                           0.76      3925\n",
      "   macro avg       0.67      0.76      0.68      3925\n",
      "weighted avg       0.84      0.76      0.78      3925\n",
      "\n",
      "offer accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3903\n",
      "           1       0.04      0.09      0.06        22\n",
      "\n",
      "    accuracy                           0.98      3925\n",
      "   macro avg       0.52      0.54      0.52      3925\n",
      "weighted avg       0.99      0.98      0.99      3925\n",
      "\n",
      "aid_related accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.47      0.60      2310\n",
      "           1       0.53      0.86      0.66      1615\n",
      "\n",
      "    accuracy                           0.63      3925\n",
      "   macro avg       0.68      0.66      0.63      3925\n",
      "weighted avg       0.70      0.63      0.62      3925\n",
      "\n",
      "medical_help accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.74      0.84      3635\n",
      "           1       0.17      0.63      0.26       290\n",
      "\n",
      "    accuracy                           0.74      3925\n",
      "   macro avg       0.56      0.69      0.55      3925\n",
      "weighted avg       0.90      0.74      0.80      3925\n",
      "\n",
      "medical_products accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.86      0.92      3739\n",
      "           1       0.18      0.60      0.27       186\n",
      "\n",
      "    accuracy                           0.85      3925\n",
      "   macro avg       0.58      0.73      0.60      3925\n",
      "weighted avg       0.94      0.85      0.89      3925\n",
      "\n",
      "search_and_rescue accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.87      0.92      3824\n",
      "           1       0.07      0.39      0.12       101\n",
      "\n",
      "    accuracy                           0.86      3925\n",
      "   macro avg       0.53      0.63      0.52      3925\n",
      "weighted avg       0.96      0.86      0.90      3925\n",
      "\n",
      "security accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95      3869\n",
      "           1       0.03      0.18      0.05        56\n",
      "\n",
      "    accuracy                           0.90      3925\n",
      "   macro avg       0.51      0.54      0.50      3925\n",
      "weighted avg       0.97      0.90      0.93      3925\n",
      "\n",
      "military accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95      3795\n",
      "           1       0.20      0.65      0.30       130\n",
      "\n",
      "    accuracy                           0.90      3925\n",
      "   macro avg       0.59      0.78      0.63      3925\n",
      "weighted avg       0.96      0.90      0.93      3925\n",
      "\n",
      "child_alone accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3925\n",
      "\n",
      "    accuracy                           1.00      3925\n",
      "   macro avg       1.00      1.00      1.00      3925\n",
      "weighted avg       1.00      1.00      1.00      3925\n",
      "\n",
      "water accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95      3677\n",
      "           1       0.36      0.70      0.48       248\n",
      "\n",
      "    accuracy                           0.90      3925\n",
      "   macro avg       0.67      0.81      0.71      3925\n",
      "weighted avg       0.94      0.90      0.92      3925\n",
      "\n",
      "food accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.80      0.88      3505\n",
      "           1       0.33      0.83      0.47       420\n",
      "\n",
      "    accuracy                           0.80      3925\n",
      "   macro avg       0.65      0.81      0.67      3925\n",
      "weighted avg       0.91      0.80      0.83      3925\n",
      "\n",
      "shelter accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.92      3569\n",
      "           1       0.37      0.70      0.49       356\n",
      "\n",
      "    accuracy                           0.87      3925\n",
      "   macro avg       0.67      0.79      0.70      3925\n",
      "weighted avg       0.91      0.87      0.88      3925\n",
      "\n",
      "clothing accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98      3863\n",
      "           1       0.20      0.60      0.30        62\n",
      "\n",
      "    accuracy                           0.96      3925\n",
      "   macro avg       0.60      0.78      0.64      3925\n",
      "weighted avg       0.98      0.96      0.97      3925\n",
      "\n",
      "money accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96      3833\n",
      "           1       0.16      0.49      0.24        92\n",
      "\n",
      "    accuracy                           0.93      3925\n",
      "   macro avg       0.57      0.71      0.60      3925\n",
      "weighted avg       0.97      0.93      0.94      3925\n",
      "\n",
      "missing_people accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97      3892\n",
      "           1       0.05      0.30      0.09        33\n",
      "\n",
      "    accuracy                           0.95      3925\n",
      "   macro avg       0.52      0.63      0.53      3925\n",
      "weighted avg       0.99      0.95      0.97      3925\n",
      "\n",
      "refugees accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94      3797\n",
      "           1       0.14      0.49      0.22       128\n",
      "\n",
      "    accuracy                           0.89      3925\n",
      "   macro avg       0.56      0.70      0.58      3925\n",
      "weighted avg       0.95      0.89      0.92      3925\n",
      "\n",
      "death accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.86      0.92      3752\n",
      "           1       0.19      0.68      0.29       173\n",
      "\n",
      "    accuracy                           0.85      3925\n",
      "   macro avg       0.58      0.77      0.60      3925\n",
      "weighted avg       0.95      0.85      0.89      3925\n",
      "\n",
      "other_aid accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.54      0.68      3390\n",
      "           1       0.19      0.69      0.30       535\n",
      "\n",
      "    accuracy                           0.56      3925\n",
      "   macro avg       0.55      0.61      0.49      3925\n",
      "weighted avg       0.82      0.56      0.63      3925\n",
      "\n",
      "infrastructure_related accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.82      0.88      3692\n",
      "           1       0.14      0.47      0.21       233\n",
      "\n",
      "    accuracy                           0.79      3925\n",
      "   macro avg       0.55      0.64      0.55      3925\n",
      "weighted avg       0.91      0.79      0.84      3925\n",
      "\n",
      "transport accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.80      0.88      3751\n",
      "           1       0.10      0.49      0.17       174\n",
      "\n",
      "    accuracy                           0.79      3925\n",
      "   macro avg       0.54      0.65      0.52      3925\n",
      "weighted avg       0.93      0.79      0.85      3925\n",
      "\n",
      "buildings accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94      3735\n",
      "           1       0.24      0.60      0.35       190\n",
      "\n",
      "    accuracy                           0.89      3925\n",
      "   macro avg       0.61      0.75      0.64      3925\n",
      "weighted avg       0.94      0.89      0.91      3925\n",
      "\n",
      "electricity accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96      3838\n",
      "           1       0.13      0.37      0.19        87\n",
      "\n",
      "    accuracy                           0.93      3925\n",
      "   macro avg       0.56      0.66      0.58      3925\n",
      "weighted avg       0.97      0.93      0.95      3925\n",
      "\n",
      "tools accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      3906\n",
      "           1       0.01      0.05      0.02        19\n",
      "\n",
      "    accuracy                           0.97      3925\n",
      "   macro avg       0.50      0.52      0.50      3925\n",
      "weighted avg       0.99      0.97      0.98      3925\n",
      "\n",
      "hospitals accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98      3890\n",
      "           1       0.05      0.20      0.07        35\n",
      "\n",
      "    accuracy                           0.96      3925\n",
      "   macro avg       0.52      0.58      0.53      3925\n",
      "weighted avg       0.98      0.96      0.97      3925\n",
      "\n",
      "shops accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      3908\n",
      "           1       0.04      0.12      0.06        17\n",
      "\n",
      "    accuracy                           0.98      3925\n",
      "   macro avg       0.52      0.55      0.52      3925\n",
      "weighted avg       0.99      0.98      0.99      3925\n",
      "\n",
      "aid_centers accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97      3885\n",
      "           1       0.02      0.07      0.03        40\n",
      "\n",
      "    accuracy                           0.95      3925\n",
      "   macro avg       0.50      0.52      0.50      3925\n",
      "weighted avg       0.98      0.95      0.96      3925\n",
      "\n",
      "other_infrastructure accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.86      0.91      3766\n",
      "           1       0.11      0.43      0.18       159\n",
      "\n",
      "    accuracy                           0.84      3925\n",
      "   macro avg       0.54      0.64      0.54      3925\n",
      "weighted avg       0.94      0.84      0.88      3925\n",
      "\n",
      "weather_related accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.70      0.79      2858\n",
      "           1       0.50      0.82      0.62      1067\n",
      "\n",
      "    accuracy                           0.73      3925\n",
      "   macro avg       0.71      0.76      0.71      3925\n",
      "weighted avg       0.80      0.73      0.75      3925\n",
      "\n",
      "floods accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.84      0.90      3604\n",
      "           1       0.29      0.72      0.41       321\n",
      "\n",
      "    accuracy                           0.83      3925\n",
      "   macro avg       0.63      0.78      0.66      3925\n",
      "weighted avg       0.92      0.83      0.86      3925\n",
      "\n",
      "storm accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90      3572\n",
      "           1       0.33      0.75      0.46       353\n",
      "\n",
      "    accuracy                           0.84      3925\n",
      "   macro avg       0.65      0.80      0.68      3925\n",
      "weighted avg       0.91      0.84      0.86      3925\n",
      "\n",
      "fire accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97      3881\n",
      "           1       0.09      0.36      0.14        44\n",
      "\n",
      "    accuracy                           0.95      3925\n",
      "   macro avg       0.54      0.66      0.56      3925\n",
      "weighted avg       0.98      0.95      0.96      3925\n",
      "\n",
      "earthquake accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.88      0.92      3572\n",
      "           1       0.39      0.78      0.52       353\n",
      "\n",
      "    accuracy                           0.87      3925\n",
      "   macro avg       0.68      0.83      0.72      3925\n",
      "weighted avg       0.92      0.87      0.89      3925\n",
      "\n",
      "cold accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96      3844\n",
      "           1       0.12      0.42      0.18        81\n",
      "\n",
      "    accuracy                           0.92      3925\n",
      "   macro avg       0.55      0.68      0.57      3925\n",
      "weighted avg       0.97      0.92      0.94      3925\n",
      "\n",
      "other_weather accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.76      0.86      3730\n",
      "           1       0.11      0.58      0.19       195\n",
      "\n",
      "    accuracy                           0.76      3925\n",
      "   macro avg       0.54      0.67      0.52      3925\n",
      "weighted avg       0.93      0.76      0.82      3925\n",
      "\n",
      "direct_report accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.67      0.77      3134\n",
      "           1       0.36      0.73      0.48       791\n",
      "\n",
      "    accuracy                           0.68      3925\n",
      "   macro avg       0.63      0.70      0.62      3925\n",
      "weighted avg       0.80      0.68      0.71      3925\n",
      "\n",
      "related accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.69      0.58       947\n",
      "           1       0.88      0.77      0.82      2949\n",
      "           2       0.13      0.07      0.09        29\n",
      "\n",
      "    accuracy                           0.75      3925\n",
      "   macro avg       0.50      0.51      0.50      3925\n",
      "weighted avg       0.78      0.75      0.76      3925\n",
      "\n",
      "Total : 21.5917304305898\n"
     ]
    }
   ],
   "source": [
    "f1_score_results = []\n",
    "# Binary Outputs\n",
    "for col_idx, col in enumerate(output_columns_binary):\n",
    "    print(f'{col} accuracy \\n')\n",
    "    \n",
    "    # Transform array of probabilities to class: 0 or 1\n",
    "    y_pred[col_idx][y_pred[col_idx]>=THRESHOLD] = 1\n",
    "    y_pred[col_idx][y_pred[col_idx]<THRESHOLD] = 0\n",
    "    f1_score_results.append(f1_score(y_test[col], y_pred[col_idx], average='macro'))\n",
    "    print(classification_report(y_test[col], y_pred[col_idx]))\n",
    "\n",
    "# Multi Class Output\n",
    "for col_idx, col in enumerate(output_columns_categorical):\n",
    "    print(f'{col} accuracy \\n')\n",
    "    \n",
    "    # Select class with higher probability from the softmax output: 0, 1 or 2\n",
    "    y_pred_2 = np.argmax(y_pred[-1], axis=-1)\n",
    "    f1_score_results.append(f1_score(y_test[col], y_pred_2, average='macro'))\n",
    "    print(classification_report(y_test[col], y_pred_2))\n",
    "print('Total :',np.sum(f1_score_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to check for overfitting, the model was also evaluated in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.84      0.91     18458\n",
      "           1       0.56      0.97      0.71      3779\n",
      "\n",
      "    accuracy                           0.87     22237\n",
      "   macro avg       0.78      0.91      0.81     22237\n",
      "weighted avg       0.92      0.87      0.88     22237\n",
      "\n",
      "offer accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     22142\n",
      "           1       0.20      0.71      0.31        95\n",
      "\n",
      "    accuracy                           0.99     22237\n",
      "   macro avg       0.60      0.85      0.65     22237\n",
      "weighted avg       1.00      0.99      0.99     22237\n",
      "\n",
      "aid_related accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.77      0.87     13010\n",
      "           1       0.75      1.00      0.86      9227\n",
      "\n",
      "    accuracy                           0.86     22237\n",
      "   macro avg       0.88      0.88      0.86     22237\n",
      "weighted avg       0.90      0.86      0.86     22237\n",
      "\n",
      "medical_help accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.84      0.91     20445\n",
      "           1       0.34      0.96      0.50      1792\n",
      "\n",
      "    accuracy                           0.85     22237\n",
      "   macro avg       0.67      0.90      0.70     22237\n",
      "weighted avg       0.94      0.85      0.88     22237\n",
      "\n",
      "medical_products accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95     21112\n",
      "           1       0.34      0.97      0.50      1125\n",
      "\n",
      "    accuracy                           0.90     22237\n",
      "   macro avg       0.67      0.93      0.72     22237\n",
      "weighted avg       0.96      0.90      0.92     22237\n",
      "\n",
      "search_and_rescue accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95     21614\n",
      "           1       0.22      0.88      0.35       623\n",
      "\n",
      "    accuracy                           0.91     22237\n",
      "   macro avg       0.61      0.89      0.65     22237\n",
      "weighted avg       0.97      0.91      0.93     22237\n",
      "\n",
      "security accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96     21822\n",
      "           1       0.19      0.87      0.32       415\n",
      "\n",
      "    accuracy                           0.93     22237\n",
      "   macro avg       0.59      0.90      0.64     22237\n",
      "weighted avg       0.98      0.93      0.95     22237\n",
      "\n",
      "military accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97     21507\n",
      "           1       0.35      0.98      0.51       730\n",
      "\n",
      "    accuracy                           0.94     22237\n",
      "   macro avg       0.67      0.96      0.74     22237\n",
      "weighted avg       0.98      0.94      0.95     22237\n",
      "\n",
      "child_alone accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     22237\n",
      "\n",
      "    accuracy                           1.00     22237\n",
      "   macro avg       1.00      1.00      1.00     22237\n",
      "weighted avg       1.00      1.00      1.00     22237\n",
      "\n",
      "water accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97     20816\n",
      "           1       0.54      0.97      0.70      1421\n",
      "\n",
      "    accuracy                           0.95     22237\n",
      "   macro avg       0.77      0.96      0.83     22237\n",
      "weighted avg       0.97      0.95      0.95     22237\n",
      "\n",
      "food accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.84      0.91     19740\n",
      "           1       0.43      0.99      0.60      2497\n",
      "\n",
      "    accuracy                           0.85     22237\n",
      "   macro avg       0.72      0.91      0.76     22237\n",
      "weighted avg       0.93      0.85      0.88     22237\n",
      "\n",
      "shelter accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.96     20284\n",
      "           1       0.54      0.95      0.69      1953\n",
      "\n",
      "    accuracy                           0.92     22237\n",
      "   macro avg       0.77      0.94      0.82     22237\n",
      "weighted avg       0.95      0.92      0.93     22237\n",
      "\n",
      "clothing accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     21895\n",
      "           1       0.31      0.92      0.46       342\n",
      "\n",
      "    accuracy                           0.97     22237\n",
      "   macro avg       0.65      0.94      0.72     22237\n",
      "weighted avg       0.99      0.97      0.98     22237\n",
      "\n",
      "money accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97     21726\n",
      "           1       0.30      0.84      0.44       511\n",
      "\n",
      "    accuracy                           0.95     22237\n",
      "   macro avg       0.65      0.90      0.71     22237\n",
      "weighted avg       0.98      0.95      0.96     22237\n",
      "\n",
      "missing_people accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     21972\n",
      "           1       0.22      0.85      0.34       265\n",
      "\n",
      "    accuracy                           0.96     22237\n",
      "   macro avg       0.61      0.90      0.66     22237\n",
      "weighted avg       0.99      0.96      0.97     22237\n",
      "\n",
      "refugees accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96     21490\n",
      "           1       0.30      0.88      0.45       747\n",
      "\n",
      "    accuracy                           0.93     22237\n",
      "   macro avg       0.65      0.91      0.71     22237\n",
      "weighted avg       0.97      0.93      0.94     22237\n",
      "\n",
      "death accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.94     21218\n",
      "           1       0.31      0.95      0.46      1019\n",
      "\n",
      "    accuracy                           0.90     22237\n",
      "   macro avg       0.65      0.92      0.70     22237\n",
      "weighted avg       0.97      0.90      0.92     22237\n",
      "\n",
      "other_aid accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.67      0.80     19330\n",
      "           1       0.31      0.96      0.47      2907\n",
      "\n",
      "    accuracy                           0.71     22237\n",
      "   macro avg       0.65      0.82      0.63     22237\n",
      "weighted avg       0.90      0.71      0.76     22237\n",
      "\n",
      "infrastructure_related accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95     20765\n",
      "           1       0.41      0.98      0.58      1472\n",
      "\n",
      "    accuracy                           0.90     22237\n",
      "   macro avg       0.70      0.94      0.76     22237\n",
      "weighted avg       0.96      0.90      0.92     22237\n",
      "\n",
      "transport accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93     21212\n",
      "           1       0.26      0.94      0.40      1025\n",
      "\n",
      "    accuracy                           0.87     22237\n",
      "   macro avg       0.63      0.91      0.67     22237\n",
      "weighted avg       0.96      0.87      0.90     22237\n",
      "\n",
      "buildings accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.96     21096\n",
      "           1       0.44      0.91      0.59      1141\n",
      "\n",
      "    accuracy                           0.93     22237\n",
      "   macro avg       0.72      0.92      0.78     22237\n",
      "weighted avg       0.97      0.93      0.95     22237\n",
      "\n",
      "electricity accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98     21792\n",
      "           1       0.29      0.91      0.44       445\n",
      "\n",
      "    accuracy                           0.95     22237\n",
      "   macro avg       0.64      0.93      0.71     22237\n",
      "weighted avg       0.98      0.95      0.96     22237\n",
      "\n",
      "tools accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     22097\n",
      "           1       0.18      0.82      0.29       140\n",
      "\n",
      "    accuracy                           0.98     22237\n",
      "   macro avg       0.59      0.90      0.64     22237\n",
      "weighted avg       0.99      0.98      0.98     22237\n",
      "\n",
      "hospitals accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     21989\n",
      "           1       0.26      0.94      0.40       248\n",
      "\n",
      "    accuracy                           0.97     22237\n",
      "   macro avg       0.63      0.95      0.69     22237\n",
      "weighted avg       0.99      0.97      0.98     22237\n",
      "\n",
      "shops accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     22134\n",
      "           1       0.21      0.80      0.33       103\n",
      "\n",
      "    accuracy                           0.98     22237\n",
      "   macro avg       0.60      0.89      0.66     22237\n",
      "weighted avg       1.00      0.98      0.99     22237\n",
      "\n",
      "aid_centers accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     21968\n",
      "           1       0.26      0.89      0.41       269\n",
      "\n",
      "    accuracy                           0.97     22237\n",
      "   macro avg       0.63      0.93      0.70     22237\n",
      "weighted avg       0.99      0.97      0.98     22237\n",
      "\n",
      "other_infrastructure accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95     21245\n",
      "           1       0.32      0.96      0.48       992\n",
      "\n",
      "    accuracy                           0.91     22237\n",
      "   macro avg       0.66      0.93      0.71     22237\n",
      "weighted avg       0.97      0.91      0.93     22237\n",
      "\n",
      "weather_related accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92     16018\n",
      "           1       0.73      1.00      0.84      6219\n",
      "\n",
      "    accuracy                           0.90     22237\n",
      "   macro avg       0.87      0.93      0.88     22237\n",
      "weighted avg       0.92      0.90      0.90     22237\n",
      "\n",
      "floods accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94     20409\n",
      "           1       0.44      0.98      0.61      1828\n",
      "\n",
      "    accuracy                           0.90     22237\n",
      "   macro avg       0.72      0.93      0.77     22237\n",
      "weighted avg       0.95      0.90      0.91     22237\n",
      "\n",
      "storm accuracy \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.94     20149\n",
      "           1       0.47      0.98      0.63      2088\n",
      "\n",
      "    accuracy                           0.89     22237\n",
      "   macro avg       0.73      0.93      0.78     22237\n",
      "weighted avg       0.95      0.89      0.91     22237\n",
      "\n",
      "fire accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     21999\n",
      "           1       0.20      0.89      0.33       238\n",
      "\n",
      "    accuracy                           0.96     22237\n",
      "   macro avg       0.60      0.92      0.65     22237\n",
      "weighted avg       0.99      0.96      0.97     22237\n",
      "\n",
      "earthquake accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95     20138\n",
      "           1       0.52      0.98      0.68      2099\n",
      "\n",
      "    accuracy                           0.91     22237\n",
      "   macro avg       0.76      0.94      0.81     22237\n",
      "weighted avg       0.95      0.91      0.92     22237\n",
      "\n",
      "cold accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97     21789\n",
      "           1       0.28      0.95      0.43       448\n",
      "\n",
      "    accuracy                           0.95     22237\n",
      "   macro avg       0.64      0.95      0.70     22237\n",
      "weighted avg       0.98      0.95      0.96     22237\n",
      "\n",
      "other_weather accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.81      0.90     21056\n",
      "           1       0.22      0.96      0.36      1181\n",
      "\n",
      "    accuracy                           0.82     22237\n",
      "   macro avg       0.61      0.89      0.63     22237\n",
      "weighted avg       0.96      0.82      0.87     22237\n",
      "\n",
      "direct_report accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.78      0.87     17961\n",
      "           1       0.51      0.97      0.67      4276\n",
      "\n",
      "    accuracy                           0.82     22237\n",
      "   macro avg       0.75      0.87      0.77     22237\n",
      "weighted avg       0.90      0.82      0.83     22237\n",
      "\n",
      "related accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.96      0.68      5164\n",
      "           1       0.99      0.74      0.84     16924\n",
      "           2       0.72      0.83      0.77       149\n",
      "\n",
      "    accuracy                           0.79     22237\n",
      "   macro avg       0.74      0.84      0.76     22237\n",
      "weighted avg       0.88      0.79      0.80     22237\n",
      "\n",
      "Total : 26.417517685099916\n"
     ]
    }
   ],
   "source": [
    "f1_score_results = []\n",
    "# Binary Outputs\n",
    "for col_idx, col in enumerate(output_columns_binary):\n",
    "    print(f'{col} accuracy \\n')\n",
    "    \n",
    "    # Transform array of probabilities to class: 0 or 1\n",
    "    y_pred_train[col_idx][y_pred_train[col_idx]>=THRESHOLD] = 1\n",
    "    y_pred_train[col_idx][y_pred_train[col_idx]<THRESHOLD] = 0\n",
    "    f1_score_results.append(f1_score(y_train[col], y_pred_train[col_idx], average='macro'))\n",
    "    print(classification_report(y_train[col], y_pred_train[col_idx]))\n",
    "\n",
    "# Multi Class Output\n",
    "for col_idx, col in enumerate(output_columns_categorical):\n",
    "    print(f'{col} accuracy \\n')\n",
    "    \n",
    "    # Select class with higher probability from the softmax output: 0, 1 or 2\n",
    "    y_pred_2 = np.argmax(y_pred_train[-1], axis=-1)\n",
    "    f1_score_results.append(f1_score(y_train[col], y_pred_2, average='macro'))\n",
    "    print(classification_report(y_train[col], y_pred_2))\n",
    "print('Total :',np.sum(f1_score_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings from the Glove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of training the word embedding from scratch, the same model used before will be retrained using the Word Embedding from [Glove](https://nlp.stanford.edu/projects/glove/), an unsupervised learning algorithm for obtaining vector representations for words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedding size will be the same as before: MAXLEN=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-28-7061d36a7f67>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-28-7061d36a7f67>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    To download the model Glove go to: https://nlp.stanford.edu/projects/glove/\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "To download the model Glove go to: https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = dict()\n",
    "f = open('glove/glove.6B.50d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocabulary_size, MAXLEN))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    if index > vocabulary_size - 1:\n",
    "        break\n",
    "    else:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_input = Input(shape=(MAXLEN,), dtype='int32', name='main_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Embedding(vocabulary_size, 50, input_length=MAXLEN)(main_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dropout(0.3)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Conv1D(64, 5, activation='relu')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = MaxPooling1D(pool_size=4)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = LSTM(100)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dropout(0.3)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_array = []\n",
    "metrics_array = {}\n",
    "loss_array = {}\n",
    "for i, dense_layer in enumerate(output_columns_binary):\n",
    "    name = f'binary_output_{i}'\n",
    "    binary_output = Dense(1, activation='sigmoid', name=name)(x)\n",
    "    output_array.append(binary_output)\n",
    "    metrics_array[name] = 'binary_accuracy'\n",
    "    loss_array[name] = 'binary_crossentropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_output = Dense(3, activation='softmax', name='categorical_output')(x)\n",
    "output_array.append(categorical_output)\n",
    "metrics_array['categorical_output'] = 'sparse_categorical_accuracy'\n",
    "loss_array['categorical_output'] = 'sparse_categorical_crossentropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Model(main_input, outputs=[binary_output, categorical_ouput])\n",
    "model = Model(inputs=main_input, outputs=output_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adadelta',\n",
    "              loss=loss_array,\n",
    "              metrics = metrics_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_output = []\n",
    "for col in output_columns_binary:\n",
    "    y_train_output.append(y_train[col])\n",
    "\n",
    "for col in output_columns_categorical:\n",
    "    y_train_output.append(y_train[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_binary = {0: 0.5, 1: 7}\n",
    "weight_categorical = {0: 1.4, 1: 0.43, 2: 7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_weights = {}\n",
    "for i, dense_layer in enumerate(output_columns_binary):\n",
    "    name = f'binary_output_{i}'\n",
    "    classes_weights[name] = weight_binary\n",
    "for i, dense_layer in enumerate(output_columns_categorical):\n",
    "    name = 'categorical_output'\n",
    "    classes_weights[name] = weight_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danieldacosta/.virtualenvs/cor/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "22237/22237 [==============================] - 10s 470us/step - loss: 19.5621 - binary_output_0_loss: 0.9433 - binary_output_1_loss: 0.1700 - binary_output_2_loss: 1.1642 - binary_output_3_loss: 0.7119 - binary_output_4_loss: 0.5672 - binary_output_5_loss: 0.4261 - binary_output_6_loss: 0.3352 - binary_output_7_loss: 0.4542 - binary_output_8_loss: 0.0982 - binary_output_9_loss: 0.6375 - binary_output_10_loss: 0.8228 - binary_output_11_loss: 0.7384 - binary_output_12_loss: 0.3024 - binary_output_13_loss: 0.3705 - binary_output_14_loss: 0.2694 - binary_output_15_loss: 0.4541 - binary_output_16_loss: 0.5381 - binary_output_17_loss: 0.8744 - binary_output_18_loss: 0.6472 - binary_output_19_loss: 0.5426 - binary_output_20_loss: 0.5725 - binary_output_21_loss: 0.3458 - binary_output_22_loss: 0.1803 - binary_output_23_loss: 0.2505 - binary_output_24_loss: 0.1682 - binary_output_25_loss: 0.2656 - binary_output_26_loss: 0.5312 - binary_output_27_loss: 1.0851 - binary_output_28_loss: 0.7111 - binary_output_29_loss: 0.7668 - binary_output_30_loss: 0.2506 - binary_output_31_loss: 0.7626 - binary_output_32_loss: 0.3557 - binary_output_33_loss: 0.5824 - binary_output_34_loss: 0.9862 - categorical_output_loss: 0.6549 - binary_output_0_binary_accuracy: 0.1788 - binary_output_1_binary_accuracy: 0.9662 - binary_output_2_binary_accuracy: 0.4194 - binary_output_3_binary_accuracy: 0.4199 - binary_output_4_binary_accuracy: 0.7327 - binary_output_5_binary_accuracy: 0.8609 - binary_output_6_binary_accuracy: 0.9616 - binary_output_7_binary_accuracy: 0.9309 - binary_output_8_binary_accuracy: 0.9164 - binary_output_9_binary_accuracy: 0.5544 - binary_output_10_binary_accuracy: 0.1454 - binary_output_11_binary_accuracy: 0.2237 - binary_output_12_binary_accuracy: 0.9538 - binary_output_13_binary_accuracy: 0.9540 - binary_output_14_binary_accuracy: 0.9758 - binary_output_15_binary_accuracy: 0.9476 - binary_output_16_binary_accuracy: 0.8934 - binary_output_17_binary_accuracy: 0.1686 - binary_output_18_binary_accuracy: 0.5370 - binary_output_19_binary_accuracy: 0.8661 - binary_output_20_binary_accuracy: 0.7988 - binary_output_21_binary_accuracy: 0.9633 - binary_output_22_binary_accuracy: 0.9872 - binary_output_23_binary_accuracy: 0.9731 - binary_output_24_binary_accuracy: 0.9792 - binary_output_25_binary_accuracy: 0.9616 - binary_output_26_binary_accuracy: 0.7658 - binary_output_27_binary_accuracy: 0.2879 - binary_output_28_binary_accuracy: 0.3569 - binary_output_29_binary_accuracy: 0.3169 - binary_output_30_binary_accuracy: 0.9839 - binary_output_31_binary_accuracy: 0.1958 - binary_output_32_binary_accuracy: 0.8408 - binary_output_33_binary_accuracy: 0.7479 - binary_output_34_binary_accuracy: 0.2100 - categorical_output_sparse_categorical_accuracy: 0.4559\n",
      "Epoch 2/40\n",
      "22237/22237 [==============================] - 7s 297us/step - loss: 18.1670 - binary_output_0_loss: 0.9091 - binary_output_1_loss: 0.1217 - binary_output_2_loss: 0.9734 - binary_output_3_loss: 0.6829 - binary_output_4_loss: 0.5421 - binary_output_5_loss: 0.4015 - binary_output_6_loss: 0.3165 - binary_output_7_loss: 0.4136 - binary_output_8_loss: 0.0240 - binary_output_9_loss: 0.6162 - binary_output_10_loss: 0.8074 - binary_output_11_loss: 0.7182 - binary_output_12_loss: 0.2825 - binary_output_13_loss: 0.3508 - binary_output_14_loss: 0.2388 - binary_output_15_loss: 0.4217 - binary_output_16_loss: 0.5035 - binary_output_17_loss: 0.8529 - binary_output_18_loss: 0.6055 - binary_output_19_loss: 0.5157 - binary_output_20_loss: 0.5454 - binary_output_21_loss: 0.3253 - binary_output_22_loss: 0.1505 - binary_output_23_loss: 0.2231 - binary_output_24_loss: 0.1238 - binary_output_25_loss: 0.2346 - binary_output_26_loss: 0.4973 - binary_output_27_loss: 0.9835 - binary_output_28_loss: 0.6431 - binary_output_29_loss: 0.7290 - binary_output_30_loss: 0.2169 - binary_output_31_loss: 0.7593 - binary_output_32_loss: 0.3184 - binary_output_33_loss: 0.5539 - binary_output_34_loss: 0.9435 - categorical_output_loss: 0.6120 - binary_output_0_binary_accuracy: 0.1734 - binary_output_1_binary_accuracy: 0.9957 - binary_output_2_binary_accuracy: 0.4149 - binary_output_3_binary_accuracy: 0.4548 - binary_output_4_binary_accuracy: 0.7914 - binary_output_5_binary_accuracy: 0.9657 - binary_output_6_binary_accuracy: 0.9785 - binary_output_7_binary_accuracy: 0.9041 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.6245 - binary_output_10_binary_accuracy: 0.1322 - binary_output_11_binary_accuracy: 0.3337 - binary_output_12_binary_accuracy: 0.9846 - binary_output_13_binary_accuracy: 0.9624 - binary_output_14_binary_accuracy: 0.9881 - binary_output_15_binary_accuracy: 0.8806 - binary_output_16_binary_accuracy: 0.8235 - binary_output_17_binary_accuracy: 0.1488 - binary_output_18_binary_accuracy: 0.6160 - binary_output_19_binary_accuracy: 0.7941 - binary_output_20_binary_accuracy: 0.7412 - binary_output_21_binary_accuracy: 0.9785 - binary_output_22_binary_accuracy: 0.9937 - binary_output_23_binary_accuracy: 0.9888 - binary_output_24_binary_accuracy: 0.9954 - binary_output_25_binary_accuracy: 0.9877 - binary_output_26_binary_accuracy: 0.8006 - binary_output_27_binary_accuracy: 0.2798 - binary_output_28_binary_accuracy: 0.5543 - binary_output_29_binary_accuracy: 0.3613 - binary_output_30_binary_accuracy: 0.9893 - binary_output_31_binary_accuracy: 0.1957 - binary_output_32_binary_accuracy: 0.9745 - binary_output_33_binary_accuracy: 0.7117 - binary_output_34_binary_accuracy: 0.1939 - categorical_output_sparse_categorical_accuracy: 0.5967\n",
      "Epoch 3/40\n",
      " 1024/22237 [>.............................] - ETA: 5s - loss: 17.3346 - binary_output_0_loss: 0.9017 - binary_output_1_loss: 0.0586 - binary_output_2_loss: 0.9613 - binary_output_3_loss: 0.6483 - binary_output_4_loss: 0.4710 - binary_output_5_loss: 0.4412 - binary_output_6_loss: 0.3498 - binary_output_7_loss: 0.3603 - binary_output_8_loss: 0.0210 - binary_output_9_loss: 0.5938 - binary_output_10_loss: 0.7309 - binary_output_11_loss: 0.6007 - binary_output_12_loss: 0.2654 - binary_output_13_loss: 0.3648 - binary_output_14_loss: 0.2415 - binary_output_15_loss: 0.3387 - binary_output_16_loss: 0.5150 - binary_output_17_loss: 0.8537 - binary_output_18_loss: 0.5882 - binary_output_19_loss: 0.4477 - binary_output_20_loss: 0.4674 - binary_output_21_loss: 0.3355 - binary_output_22_loss: 0.1054 - binary_output_23_loss: 0.2786 - binary_output_24_loss: 0.1347 - binary_output_25_loss: 0.2238 - binary_output_26_loss: 0.5012 - binary_output_27_loss: 0.9463 - binary_output_28_loss: 0.5473 - binary_output_29_loss: 0.6861 - binary_output_30_loss: 0.2547 - binary_output_31_loss: 0.7939 - binary_output_32_loss: 0.2515 - binary_output_33_loss: 0.5330 - binary_output_34_loss: 0.9417 - categorical_output_loss: 0.5803 - binary_output_0_binary_accuracy: 0.1758 - binary_output_1_binary_accuracy: 0.9990 - binary_output_2_binary_accuracy: 0.3916 - binary_output_3_binary_accuracy: 0.5479 - binary_output_4_binary_accuracy: 0.7979 - binary_output_5_binary_accuracy: 0.9561 - binary_output_6_binary_accuracy: 0.9795 - binary_output_7_binary_accuracy: 0.8828 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7217 - binary_output_10_binary_accuracy: 0.3398 - binary_output_11_binary_accuracy: 0.5381 - binary_output_12_binary_accuracy: 0.9854 - binary_output_13_binary_accuracy: 0.9609 - binary_output_14_binary_accuracy: 0.9883 - binary_output_15_binary_accuracy: 0.8799 - binary_output_16_binary_accuracy: 0.7842 - binary_output_17_binary_accuracy: 0.1621 - binary_output_18_binary_accuracy: 0.6406 - binary_output_19_binary_accuracy: 0.8555 - binary_output_20_binary_accuracy: 0.8057 - binary_output_21_binary_accuracy: 0.9775 - binary_output_22_binary_accuracy: 0.9971 - binary_output_23_binary_accuracy: 0.9844 - binary_output_24_binary_accuracy: 0.9941 - binary_output_25_binary_accuracy: 0.9873 - binary_output_26_binary_accuracy: 0.8008 - binary_output_27_binary_accuracy: 0.2676 - binary_output_28_binary_accuracy: 0.5928 - binary_output_29_binary_accuracy: 0.3896 - binary_output_30_binary_accuracy: 0.9863 - binary_output_31_binary_accuracy: 0.2275 - binary_output_32_binary_accuracy: 0.9824 - binary_output_33_binary_accuracy: 0.7402 - binary_output_34_binary_accuracy: 0.1904 - categorical_output_sparse_categorical_accuracy: 0.614322237/22237 [==============================] - 6s 282us/step - loss: 17.1506 - binary_output_0_loss: 0.8823 - binary_output_1_loss: 0.1171 - binary_output_2_loss: 0.9144 - binary_output_3_loss: 0.6723 - binary_output_4_loss: 0.5239 - binary_output_5_loss: 0.3921 - binary_output_6_loss: 0.3174 - binary_output_7_loss: 0.4242 - binary_output_8_loss: 0.0173 - binary_output_9_loss: 0.5315 - binary_output_10_loss: 0.7447 - binary_output_11_loss: 0.6243 - binary_output_12_loss: 0.2774 - binary_output_13_loss: 0.3451 - binary_output_14_loss: 0.2343 - binary_output_15_loss: 0.4018 - binary_output_16_loss: 0.4714 - binary_output_17_loss: 0.8331 - binary_output_18_loss: 0.5687 - binary_output_19_loss: 0.4932 - binary_output_20_loss: 0.4724 - binary_output_21_loss: 0.3085 - binary_output_22_loss: 0.1510 - binary_output_23_loss: 0.2166 - binary_output_24_loss: 0.1172 - binary_output_25_loss: 0.2251 - binary_output_26_loss: 0.4644 - binary_output_27_loss: 0.9081 - binary_output_28_loss: 0.5668 - binary_output_29_loss: 0.6817 - binary_output_30_loss: 0.2129 - binary_output_31_loss: 0.7355 - binary_output_32_loss: 0.3010 - binary_output_33_loss: 0.5367 - binary_output_34_loss: 0.9153 - categorical_output_loss: 0.5582 - binary_output_0_binary_accuracy: 0.1717 - binary_output_1_binary_accuracy: 0.9957 - binary_output_2_binary_accuracy: 0.4149 - binary_output_3_binary_accuracy: 0.5125 - binary_output_4_binary_accuracy: 0.7517 - binary_output_5_binary_accuracy: 0.9315 - binary_output_6_binary_accuracy: 0.9802 - binary_output_7_binary_accuracy: 0.8914 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7007 - binary_output_10_binary_accuracy: 0.3177 - binary_output_11_binary_accuracy: 0.5901 - binary_output_12_binary_accuracy: 0.9821 - binary_output_13_binary_accuracy: 0.9558 - binary_output_14_binary_accuracy: 0.9879 - binary_output_15_binary_accuracy: 0.8591 - binary_output_16_binary_accuracy: 0.7756 - binary_output_17_binary_accuracy: 0.1674 - binary_output_18_binary_accuracy: 0.6592 - binary_output_19_binary_accuracy: 0.7809 - binary_output_20_binary_accuracy: 0.7625 - binary_output_21_binary_accuracy: 0.9587 - binary_output_22_binary_accuracy: 0.9937 - binary_output_23_binary_accuracy: 0.9884 - binary_output_24_binary_accuracy: 0.9954 - binary_output_25_binary_accuracy: 0.9847 - binary_output_26_binary_accuracy: 0.7836 - binary_output_27_binary_accuracy: 0.2866 - binary_output_28_binary_accuracy: 0.6607 - binary_output_29_binary_accuracy: 0.5174 - binary_output_30_binary_accuracy: 0.9889 - binary_output_31_binary_accuracy: 0.2897 - binary_output_32_binary_accuracy: 0.9489 - binary_output_33_binary_accuracy: 0.7176 - binary_output_34_binary_accuracy: 0.1929 - categorical_output_sparse_categorical_accuracy: 0.6624\n",
      "Epoch 4/40\n",
      "22237/22237 [==============================] - 6s 285us/step - loss: 16.1209 - binary_output_0_loss: 0.7580 - binary_output_1_loss: 0.1202 - binary_output_2_loss: 0.8682 - binary_output_3_loss: 0.6651 - binary_output_4_loss: 0.5005 - binary_output_5_loss: 0.3781 - binary_output_6_loss: 0.3151 - binary_output_7_loss: 0.3982 - binary_output_8_loss: 0.0118 - binary_output_9_loss: 0.4592 - binary_output_10_loss: 0.6162 - binary_output_11_loss: 0.5481 - binary_output_12_loss: 0.2630 - binary_output_13_loss: 0.3397 - binary_output_14_loss: 0.2290 - binary_output_15_loss: 0.3906 - binary_output_16_loss: 0.4458 - binary_output_17_loss: 0.8178 - binary_output_18_loss: 0.5452 - binary_output_19_loss: 0.4688 - binary_output_20_loss: 0.4298 - binary_output_21_loss: 0.3023 - binary_output_22_loss: 0.1481 - binary_output_23_loss: 0.2114 - binary_output_24_loss: 0.1146 - binary_output_25_loss: 0.2136 - binary_output_26_loss: 0.4447 - binary_output_27_loss: 0.8694 - binary_output_28_loss: 0.5344 - binary_output_29_loss: 0.6346 - binary_output_30_loss: 0.2127 - binary_output_31_loss: 0.7048 - binary_output_32_loss: 0.2821 - binary_output_33_loss: 0.5257 - binary_output_34_loss: 0.8324 - categorical_output_loss: 0.5207 - binary_output_0_binary_accuracy: 0.3347 - binary_output_1_binary_accuracy: 0.9957 - binary_output_2_binary_accuracy: 0.4155 - binary_output_3_binary_accuracy: 0.5306 - binary_output_4_binary_accuracy: 0.7357 - binary_output_5_binary_accuracy: 0.9054 - binary_output_6_binary_accuracy: 0.9726 - binary_output_7_binary_accuracy: 0.9121 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7489 - binary_output_10_binary_accuracy: 0.5931 - binary_output_11_binary_accuracy: 0.6743 - binary_output_12_binary_accuracy: 0.9718 - binary_output_13_binary_accuracy: 0.9366 - binary_output_14_binary_accuracy: 0.9867 - binary_output_15_binary_accuracy: 0.8407 - binary_output_16_binary_accuracy: 0.7842 - binary_output_17_binary_accuracy: 0.2362 - binary_output_18_binary_accuracy: 0.6747 - binary_output_19_binary_accuracy: 0.7742 - binary_output_20_binary_accuracy: 0.7721 - binary_output_21_binary_accuracy: 0.9447 - binary_output_22_binary_accuracy: 0.9931 - binary_output_23_binary_accuracy: 0.9856 - binary_output_24_binary_accuracy: 0.9951 - binary_output_25_binary_accuracy: 0.9783 - binary_output_26_binary_accuracy: 0.7939 - binary_output_27_binary_accuracy: 0.3116 - binary_output_28_binary_accuracy: 0.6993 - binary_output_29_binary_accuracy: 0.5935 - binary_output_30_binary_accuracy: 0.9884 - binary_output_31_binary_accuracy: 0.4255 - binary_output_32_binary_accuracy: 0.9331 - binary_output_33_binary_accuracy: 0.7246 - binary_output_34_binary_accuracy: 0.2463 - categorical_output_sparse_categorical_accuracy: 0.7059\n",
      "Epoch 5/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  512/22237 [..............................] - ETA: 5s - loss: 14.9030 - binary_output_0_loss: 0.7333 - binary_output_1_loss: 0.0837 - binary_output_2_loss: 0.8298 - binary_output_3_loss: 0.5766 - binary_output_4_loss: 0.4302 - binary_output_5_loss: 0.2880 - binary_output_6_loss: 0.3140 - binary_output_7_loss: 0.3031 - binary_output_8_loss: 0.0128 - binary_output_9_loss: 0.4150 - binary_output_10_loss: 0.5452 - binary_output_11_loss: 0.5079 - binary_output_12_loss: 0.1649 - binary_output_13_loss: 0.3873 - binary_output_14_loss: 0.1830 - binary_output_15_loss: 0.3632 - binary_output_16_loss: 0.3869 - binary_output_17_loss: 0.7710 - binary_output_18_loss: 0.4915 - binary_output_19_loss: 0.3773 - binary_output_20_loss: 0.4709 - binary_output_21_loss: 0.2800 - binary_output_22_loss: 0.1257 - binary_output_23_loss: 0.1753 - binary_output_24_loss: 0.1270 - binary_output_25_loss: 0.1646 - binary_output_26_loss: 0.4282 - binary_output_27_loss: 0.8038 - binary_output_28_loss: 0.4413 - binary_output_29_loss: 0.5951 - binary_output_30_loss: 0.2445 - binary_output_31_loss: 0.6986 - binary_output_32_loss: 0.2515 - binary_output_33_loss: 0.5743 - binary_output_34_loss: 0.8280 - categorical_output_loss: 0.5297 - binary_output_0_binary_accuracy: 0.5742 - binary_output_1_binary_accuracy: 0.9980 - binary_output_2_binary_accuracy: 0.3828 - binary_output_3_binary_accuracy: 0.5430 - binary_output_4_binary_accuracy: 0.7500 - binary_output_5_binary_accuracy: 0.9023 - binary_output_6_binary_accuracy: 0.9785 - binary_output_7_binary_accuracy: 0.8457 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8027 - binary_output_10_binary_accuracy: 0.7363 - binary_output_11_binary_accuracy: 0.6348 - binary_output_12_binary_accuracy: 0.9727 - binary_output_13_binary_accuracy: 0.9395 - binary_output_14_binary_accuracy: 0.9922 - binary_output_15_binary_accuracy: 0.7969 - binary_output_16_binary_accuracy: 0.7246 - binary_output_17_binary_accuracy: 0.2461 - binary_output_18_binary_accuracy: 0.6074 - binary_output_19_binary_accuracy: 0.7656 - binary_output_20_binary_accuracy: 0.7676 - binary_output_21_binary_accuracy: 0.9102 - binary_output_22_binary_accuracy: 0.9961 - binary_output_23_binary_accuracy: 0.9824 - binary_output_24_binary_accuracy: 0.9941 - binary_output_25_binary_accuracy: 0.9688 - binary_output_26_binary_accuracy: 0.7168 - binary_output_27_binary_accuracy: 0.3027 - binary_output_28_binary_accuracy: 0.6523 - binary_output_29_binary_accuracy: 0.5059 - binary_output_30_binary_accuracy: 0.9844 - binary_output_31_binary_accuracy: 0.4316 - binary_output_32_binary_accuracy: 0.8887 - binary_output_33_binary_accuracy: 0.6328 - binary_output_34_binary_accuracy: 0.4863 - categorical_output_sparse_categorical_accuracy: 0.7402\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 1024/22237 [>.............................] - ETA: 5s - loss: 15.1336 - binary_output_0_loss: 0.7439 - binary_output_1_loss: 0.1267 - binary_output_2_loss: 0.8378 - binary_output_3_loss: 0.5975 - binary_output_4_loss: 0.4150 - binary_output_5_loss: 0.3742 - binary_output_6_loss: 0.3225 - binary_output_7_loss: 0.3302 - binary_output_8_loss: 0.0100 - binary_output_9_loss: 0.4052 - binary_output_10_loss: 0.5499 - binary_output_11_loss: 0.5438 - binary_output_12_loss: 0.2660 - binary_output_13_loss: 0.4376 - binary_output_14_loss: 0.2554 - binary_output_15_loss: 0.3499 - binary_output_16_loss: 0.3242 - binary_output_17_loss: 0.7853 - binary_output_18_loss: 0.4997 - binary_output_19_loss: 0.4357 - binary_output_20_loss: 0.4311 - binary_output_21_loss: 0.2692 - binary_output_22_loss: 0.0792 - binary_output_23_loss: 0.1897 - binary_output_24_loss: 0.1138 - binary_output_25_loss: 0.2047 - binary_output_26_loss: 0.4023 - binary_output_27_loss: 0.7908 - binary_output_28_loss: 0.4932 - binary_output_29_loss: 0.5679 - binary_output_30_loss: 0.2255 - binary_output_31_loss: 0.6884 - binary_output_32_loss: 0.2506 - binary_output_33_loss: 0.5043 - binary_output_34_loss: 0.8189 - categorical_output_loss: 0.4936 - binary_output_0_binary_accuracy: 0.4688 - binary_output_1_binary_accuracy: 0.9951 - binary_output_2_binary_accuracy: 0.3994 - binary_output_3_binary_accuracy: 0.6240 - binary_output_4_binary_accuracy: 0.8047 - binary_output_5_binary_accuracy: 0.9209 - binary_output_6_binary_accuracy: 0.9785 - binary_output_7_binary_accuracy: 0.8984 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8184 - binary_output_10_binary_accuracy: 0.7393 - binary_output_11_binary_accuracy: 0.6963 - binary_output_12_binary_accuracy: 0.9668 - binary_output_13_binary_accuracy: 0.9443 - binary_output_14_binary_accuracy: 0.9863 - binary_output_15_binary_accuracy: 0.8477 - binary_output_16_binary_accuracy: 0.8008 - binary_output_17_binary_accuracy: 0.3047 - binary_output_18_binary_accuracy: 0.6973 - binary_output_19_binary_accuracy: 0.8115 - binary_output_20_binary_accuracy: 0.8115 - binary_output_21_binary_accuracy: 0.9404 - binary_output_22_binary_accuracy: 0.9980 - binary_output_23_binary_accuracy: 0.9863 - binary_output_24_binary_accuracy: 0.9951 - binary_output_25_binary_accuracy: 0.9736 - binary_output_26_binary_accuracy: 0.7881 - binary_output_27_binary_accuracy: 0.3193 - binary_output_28_binary_accuracy: 0.7246 - binary_output_29_binary_accuracy: 0.6123 - binary_output_30_binary_accuracy: 0.9854 - binary_output_31_binary_accuracy: 0.5059 - binary_output_32_binary_accuracy: 0.9248 - binary_output_33_binary_accuracy: 0.7100 - binary_output_34_binary_accuracy: 0.4043 - categorical_output_sparse_categorical_accuracy: 0.6963"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22237/22237 [==============================] - 7s 293us/step - loss: 15.3000 - binary_output_0_loss: 0.7018 - binary_output_1_loss: 0.1140 - binary_output_2_loss: 0.8373 - binary_output_3_loss: 0.6501 - binary_output_4_loss: 0.4582 - binary_output_5_loss: 0.3724 - binary_output_6_loss: 0.3115 - binary_output_7_loss: 0.3782 - binary_output_8_loss: 0.0084 - binary_output_9_loss: 0.4056 - binary_output_10_loss: 0.5349 - binary_output_11_loss: 0.5023 - binary_output_12_loss: 0.2293 - binary_output_13_loss: 0.3409 - binary_output_14_loss: 0.2293 - binary_output_15_loss: 0.3743 - binary_output_16_loss: 0.4293 - binary_output_17_loss: 0.8044 - binary_output_18_loss: 0.5279 - binary_output_19_loss: 0.4586 - binary_output_20_loss: 0.4048 - binary_output_21_loss: 0.2927 - binary_output_22_loss: 0.1438 - binary_output_23_loss: 0.2069 - binary_output_24_loss: 0.1124 - binary_output_25_loss: 0.2088 - binary_output_26_loss: 0.4262 - binary_output_27_loss: 0.7942 - binary_output_28_loss: 0.5136 - binary_output_29_loss: 0.5857 - binary_output_30_loss: 0.2042 - binary_output_31_loss: 0.6459 - binary_output_32_loss: 0.2706 - binary_output_33_loss: 0.5065 - binary_output_34_loss: 0.7988 - categorical_output_loss: 0.5039 - binary_output_0_binary_accuracy: 0.5144 - binary_output_1_binary_accuracy: 0.9957 - binary_output_2_binary_accuracy: 0.4215 - binary_output_3_binary_accuracy: 0.5399 - binary_output_4_binary_accuracy: 0.7819 - binary_output_5_binary_accuracy: 0.8882 - binary_output_6_binary_accuracy: 0.9788 - binary_output_7_binary_accuracy: 0.8846 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8008 - binary_output_10_binary_accuracy: 0.7360 - binary_output_11_binary_accuracy: 0.7114 - binary_output_12_binary_accuracy: 0.9531 - binary_output_13_binary_accuracy: 0.9398 - binary_output_14_binary_accuracy: 0.9862 - binary_output_15_binary_accuracy: 0.8346 - binary_output_16_binary_accuracy: 0.7767 - binary_output_17_binary_accuracy: 0.3023 - binary_output_18_binary_accuracy: 0.6824 - binary_output_19_binary_accuracy: 0.7781 - binary_output_20_binary_accuracy: 0.7823 - binary_output_21_binary_accuracy: 0.9376 - binary_output_22_binary_accuracy: 0.9932 - binary_output_23_binary_accuracy: 0.9854 - binary_output_24_binary_accuracy: 0.9952 - binary_output_25_binary_accuracy: 0.9757 - binary_output_26_binary_accuracy: 0.7865 - binary_output_27_binary_accuracy: 0.3628 - binary_output_28_binary_accuracy: 0.7189 - binary_output_29_binary_accuracy: 0.6574 - binary_output_30_binary_accuracy: 0.9885 - binary_output_31_binary_accuracy: 0.5619 - binary_output_32_binary_accuracy: 0.9213 - binary_output_33_binary_accuracy: 0.7173 - binary_output_34_binary_accuracy: 0.3387 - categorical_output_sparse_categorical_accuracy: 0.7252\n",
      "Epoch 6/40\n",
      "22237/22237 [==============================] - 6s 252us/step - loss: 14.8047 - binary_output_0_loss: 0.6788 - binary_output_1_loss: 0.1105 - binary_output_2_loss: 0.8074 - binary_output_3_loss: 0.6339 - binary_output_4_loss: 0.4386 - binary_output_5_loss: 0.3647 - binary_output_6_loss: 0.3118 - binary_output_7_loss: 0.3650 - binary_output_8_loss: 0.0065 - binary_output_9_loss: 0.3993 - binary_output_10_loss: 0.5132 - binary_output_11_loss: 0.4676 - binary_output_12_loss: 0.2101 - binary_output_13_loss: 0.3308 - binary_output_14_loss: 0.2239 - binary_output_15_loss: 0.3695 - binary_output_16_loss: 0.4262 - binary_output_17_loss: 0.7981 - binary_output_18_loss: 0.5135 - binary_output_19_loss: 0.4492 - binary_output_20_loss: 0.3950 - binary_output_21_loss: 0.2903 - binary_output_22_loss: 0.1452 - binary_output_23_loss: 0.2015 - binary_output_24_loss: 0.1145 - binary_output_25_loss: 0.2061 - binary_output_26_loss: 0.4144 - binary_output_27_loss: 0.7387 - binary_output_28_loss: 0.4992 - binary_output_29_loss: 0.5519 - binary_output_30_loss: 0.2103 - binary_output_31_loss: 0.6052 - binary_output_32_loss: 0.2627 - binary_output_33_loss: 0.4941 - binary_output_34_loss: 0.7780 - categorical_output_loss: 0.4947 - binary_output_0_binary_accuracy: 0.5676 - binary_output_1_binary_accuracy: 0.9957 - binary_output_2_binary_accuracy: 0.4404 - binary_output_3_binary_accuracy: 0.5584 - binary_output_4_binary_accuracy: 0.7998 - binary_output_5_binary_accuracy: 0.8933 - binary_output_6_binary_accuracy: 0.9772 - binary_output_7_binary_accuracy: 0.8712 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8041 - binary_output_10_binary_accuracy: 0.7417 - binary_output_11_binary_accuracy: 0.7355 - binary_output_12_binary_accuracy: 0.9391 - binary_output_13_binary_accuracy: 0.9425 - binary_output_14_binary_accuracy: 0.9855 - binary_output_15_binary_accuracy: 0.8415 - binary_output_16_binary_accuracy: 0.7787 - binary_output_17_binary_accuracy: 0.3481 - binary_output_18_binary_accuracy: 0.6844 - binary_output_19_binary_accuracy: 0.7680 - binary_output_20_binary_accuracy: 0.7765 - binary_output_21_binary_accuracy: 0.9334 - binary_output_22_binary_accuracy: 0.9930 - binary_output_23_binary_accuracy: 0.9840 - binary_output_24_binary_accuracy: 0.9947 - binary_output_25_binary_accuracy: 0.9729 - binary_output_26_binary_accuracy: 0.7810 - binary_output_27_binary_accuracy: 0.4505 - binary_output_28_binary_accuracy: 0.7344 - binary_output_29_binary_accuracy: 0.6906 - binary_output_30_binary_accuracy: 0.9876 - binary_output_31_binary_accuracy: 0.6486 - binary_output_32_binary_accuracy: 0.9211 - binary_output_33_binary_accuracy: 0.7218 - binary_output_34_binary_accuracy: 0.3876 - categorical_output_sparse_categorical_accuracy: 0.7389\n",
      "Epoch 7/40\n",
      " 1024/22237 [>.............................] - ETA: 6s - loss: 14.6184 - binary_output_0_loss: 0.6873 - binary_output_1_loss: 0.0660 - binary_output_2_loss: 0.7591 - binary_output_3_loss: 0.6118 - binary_output_4_loss: 0.4407 - binary_output_5_loss: 0.3456 - binary_output_6_loss: 0.3313 - binary_output_7_loss: 0.3777 - binary_output_8_loss: 0.0069 - binary_output_9_loss: 0.4700 - binary_output_10_loss: 0.5329 - binary_output_11_loss: 0.4715 - binary_output_12_loss: 0.2383 - binary_output_13_loss: 0.3229 - binary_output_14_loss: 0.2158 - binary_output_15_loss: 0.3609 - binary_output_16_loss: 0.4519 - binary_output_17_loss: 0.7942 - binary_output_18_loss: 0.4694 - binary_output_19_loss: 0.4733 - binary_output_20_loss: 0.3362 - binary_output_21_loss: 0.2711 - binary_output_22_loss: 0.1407 - binary_output_23_loss: 0.2553 - binary_output_24_loss: 0.0802 - binary_output_25_loss: 0.1685 - binary_output_26_loss: 0.3933 - binary_output_27_loss: 0.7022 - binary_output_28_loss: 0.4880 - binary_output_29_loss: 0.5447 - binary_output_30_loss: 0.1439 - binary_output_31_loss: 0.6309 - binary_output_32_loss: 0.3012 - binary_output_33_loss: 0.4624 - binary_output_34_loss: 0.7986 - categorical_output_loss: 0.4736 - binary_output_0_binary_accuracy: 0.5508 - binary_output_1_binary_accuracy: 0.9980 - binary_output_2_binary_accuracy: 0.4434 - binary_output_3_binary_accuracy: 0.5166 - binary_output_4_binary_accuracy: 0.7725 - binary_output_5_binary_accuracy: 0.8809 - binary_output_6_binary_accuracy: 0.9697 - binary_output_7_binary_accuracy: 0.8379 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7744 - binary_output_10_binary_accuracy: 0.7285 - binary_output_11_binary_accuracy: 0.7363 - binary_output_12_binary_accuracy: 0.9395 - binary_output_13_binary_accuracy: 0.9150 - binary_output_14_binary_accuracy: 0.9854 - binary_output_15_binary_accuracy: 0.8486 - binary_output_16_binary_accuracy: 0.7432 - binary_output_17_binary_accuracy: 0.3779 - binary_output_18_binary_accuracy: 0.7012 - binary_output_19_binary_accuracy: 0.7637 - binary_output_20_binary_accuracy: 0.7939 - binary_output_21_binary_accuracy: 0.8916 - binary_output_22_binary_accuracy: 0.9932 - binary_output_23_binary_accuracy: 0.9775 - binary_output_24_binary_accuracy: 0.9941 - binary_output_25_binary_accuracy: 0.9756 - binary_output_26_binary_accuracy: 0.7900 - binary_output_27_binary_accuracy: 0.4961 - binary_output_28_binary_accuracy: 0.7422 - binary_output_29_binary_accuracy: 0.7393 - binary_output_30_binary_accuracy: 0.9854 - binary_output_31_binary_accuracy: 0.6611 - binary_output_32_binary_accuracy: 0.8428 - binary_output_33_binary_accuracy: 0.7021 - binary_output_34_binary_accuracy: 0.4189 - categorical_output_sparse_categorical_accuracy: 0.773422237/22237 [==============================] - 6s 275us/step - loss: 14.3770 - binary_output_0_loss: 0.6609 - binary_output_1_loss: 0.1078 - binary_output_2_loss: 0.7888 - binary_output_3_loss: 0.6139 - binary_output_4_loss: 0.4205 - binary_output_5_loss: 0.3588 - binary_output_6_loss: 0.3030 - binary_output_7_loss: 0.3468 - binary_output_8_loss: 0.0052 - binary_output_9_loss: 0.3932 - binary_output_10_loss: 0.5006 - binary_output_11_loss: 0.4572 - binary_output_12_loss: 0.1996 - binary_output_13_loss: 0.3245 - binary_output_14_loss: 0.2158 - binary_output_15_loss: 0.3546 - binary_output_16_loss: 0.4200 - binary_output_17_loss: 0.7819 - binary_output_18_loss: 0.4929 - binary_output_19_loss: 0.4423 - binary_output_20_loss: 0.3759 - binary_output_21_loss: 0.2779 - binary_output_22_loss: 0.1396 - binary_output_23_loss: 0.1956 - binary_output_24_loss: 0.1081 - binary_output_25_loss: 0.1941 - binary_output_26_loss: 0.4014 - binary_output_27_loss: 0.7120 - binary_output_28_loss: 0.4859 - binary_output_29_loss: 0.5307 - binary_output_30_loss: 0.1991 - binary_output_31_loss: 0.5747 - binary_output_32_loss: 0.2632 - binary_output_33_loss: 0.4819 - binary_output_34_loss: 0.7680 - categorical_output_loss: 0.4880 - binary_output_0_binary_accuracy: 0.5810 - binary_output_1_binary_accuracy: 0.9957 - binary_output_2_binary_accuracy: 0.4566 - binary_output_3_binary_accuracy: 0.5873 - binary_output_4_binary_accuracy: 0.7968 - binary_output_5_binary_accuracy: 0.8859 - binary_output_6_binary_accuracy: 0.9758 - binary_output_7_binary_accuracy: 0.8765 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7932 - binary_output_10_binary_accuracy: 0.7424 - binary_output_11_binary_accuracy: 0.7573 - binary_output_12_binary_accuracy: 0.9397 - binary_output_13_binary_accuracy: 0.9342 - binary_output_14_binary_accuracy: 0.9845 - binary_output_15_binary_accuracy: 0.8435 - binary_output_16_binary_accuracy: 0.7759 - binary_output_17_binary_accuracy: 0.3842 - binary_output_18_binary_accuracy: 0.6969 - binary_output_19_binary_accuracy: 0.7727 - binary_output_20_binary_accuracy: 0.7947 - binary_output_21_binary_accuracy: 0.9325 - binary_output_22_binary_accuracy: 0.9929 - binary_output_23_binary_accuracy: 0.9806 - binary_output_24_binary_accuracy: 0.9942 - binary_output_25_binary_accuracy: 0.9689 - binary_output_26_binary_accuracy: 0.7844 - binary_output_27_binary_accuracy: 0.4988 - binary_output_28_binary_accuracy: 0.7449 - binary_output_29_binary_accuracy: 0.7104 - binary_output_30_binary_accuracy: 0.9865 - binary_output_31_binary_accuracy: 0.6742 - binary_output_32_binary_accuracy: 0.9053 - binary_output_33_binary_accuracy: 0.7152 - binary_output_34_binary_accuracy: 0.4229 - categorical_output_sparse_categorical_accuracy: 0.7440\n",
      "Epoch 8/40\n",
      "22237/22237 [==============================] - 6s 276us/step - loss: 13.9652 - binary_output_0_loss: 0.6373 - binary_output_1_loss: 0.1053 - binary_output_2_loss: 0.7653 - binary_output_3_loss: 0.5994 - binary_output_4_loss: 0.4010 - binary_output_5_loss: 0.3513 - binary_output_6_loss: 0.2950 - binary_output_7_loss: 0.3289 - binary_output_8_loss: 0.0040 - binary_output_9_loss: 0.3878 - binary_output_10_loss: 0.4867 - binary_output_11_loss: 0.4398 - binary_output_12_loss: 0.1911 - binary_output_13_loss: 0.3216 - binary_output_14_loss: 0.2121 - binary_output_15_loss: 0.3422 - binary_output_16_loss: 0.4051 - binary_output_17_loss: 0.7719 - binary_output_18_loss: 0.4809 - binary_output_19_loss: 0.4235 - binary_output_20_loss: 0.3699 - binary_output_21_loss: 0.2720 - binary_output_22_loss: 0.1357 - binary_output_23_loss: 0.1935 - binary_output_24_loss: 0.1067 - binary_output_25_loss: 0.1904 - binary_output_26_loss: 0.3904 - binary_output_27_loss: 0.6752 - binary_output_28_loss: 0.4706 - binary_output_29_loss: 0.5036 - binary_output_30_loss: 0.1956 - binary_output_31_loss: 0.5550 - binary_output_32_loss: 0.2501 - binary_output_33_loss: 0.4731 - binary_output_34_loss: 0.7391 - categorical_output_loss: 0.4825 - binary_output_0_binary_accuracy: 0.6094 - binary_output_1_binary_accuracy: 0.9956 - binary_output_2_binary_accuracy: 0.4894 - binary_output_3_binary_accuracy: 0.6073 - binary_output_4_binary_accuracy: 0.7971 - binary_output_5_binary_accuracy: 0.8858 - binary_output_6_binary_accuracy: 0.9709 - binary_output_7_binary_accuracy: 0.8769 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7898 - binary_output_10_binary_accuracy: 0.7408 - binary_output_11_binary_accuracy: 0.7613 - binary_output_12_binary_accuracy: 0.9370 - binary_output_13_binary_accuracy: 0.9283 - binary_output_14_binary_accuracy: 0.9833 - binary_output_15_binary_accuracy: 0.8504 - binary_output_16_binary_accuracy: 0.7848 - binary_output_17_binary_accuracy: 0.4085 - binary_output_18_binary_accuracy: 0.7103 - binary_output_19_binary_accuracy: 0.7718 - binary_output_20_binary_accuracy: 0.7947 - binary_output_21_binary_accuracy: 0.9317 - binary_output_22_binary_accuracy: 0.9920 - binary_output_23_binary_accuracy: 0.9779 - binary_output_24_binary_accuracy: 0.9933 - binary_output_25_binary_accuracy: 0.9710 - binary_output_26_binary_accuracy: 0.7942 - binary_output_27_binary_accuracy: 0.5454 - binary_output_28_binary_accuracy: 0.7482 - binary_output_29_binary_accuracy: 0.7211 - binary_output_30_binary_accuracy: 0.9853 - binary_output_31_binary_accuracy: 0.6996 - binary_output_32_binary_accuracy: 0.9025 - binary_output_33_binary_accuracy: 0.7208 - binary_output_34_binary_accuracy: 0.4629 - categorical_output_sparse_categorical_accuracy: 0.7506\n",
      "Epoch 9/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  512/22237 [..............................] - ETA: 6s - loss: 14.1422 - binary_output_0_loss: 0.6695 - binary_output_1_loss: 0.0413 - binary_output_2_loss: 0.7977 - binary_output_3_loss: 0.6412 - binary_output_4_loss: 0.2882 - binary_output_5_loss: 0.3926 - binary_output_6_loss: 0.4060 - binary_output_7_loss: 0.4470 - binary_output_8_loss: 0.0026 - binary_output_9_loss: 0.4962 - binary_output_10_loss: 0.5078 - binary_output_11_loss: 0.4021 - binary_output_12_loss: 0.1323 - binary_output_13_loss: 0.2595 - binary_output_14_loss: 0.1583 - binary_output_15_loss: 0.3197 - binary_output_16_loss: 0.3904 - binary_output_17_loss: 0.8192 - binary_output_18_loss: 0.4390 - binary_output_19_loss: 0.3791 - binary_output_20_loss: 0.3414 - binary_output_21_loss: 0.3098 - binary_output_22_loss: 0.2575 - binary_output_23_loss: 0.1949 - binary_output_24_loss: 0.0626 - binary_output_25_loss: 0.2342 - binary_output_26_loss: 0.2968 - binary_output_27_loss: 0.6783 - binary_output_28_loss: 0.4838 - binary_output_29_loss: 0.5576 - binary_output_30_loss: 0.2608 - binary_output_31_loss: 0.5000 - binary_output_32_loss: 0.3159 - binary_output_33_loss: 0.4608 - binary_output_34_loss: 0.7686 - categorical_output_loss: 0.4298 - binary_output_0_binary_accuracy: 0.5605 - binary_output_1_binary_accuracy: 0.9980 - binary_output_2_binary_accuracy: 0.5488 - binary_output_3_binary_accuracy: 0.6797 - binary_output_4_binary_accuracy: 0.8770 - binary_output_5_binary_accuracy: 0.9062 - binary_output_6_binary_accuracy: 0.9688 - binary_output_7_binary_accuracy: 0.9102 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8516 - binary_output_10_binary_accuracy: 0.7734 - binary_output_11_binary_accuracy: 0.7988 - binary_output_12_binary_accuracy: 0.9707 - binary_output_13_binary_accuracy: 0.9609 - binary_output_14_binary_accuracy: 0.9922 - binary_output_15_binary_accuracy: 0.9082 - binary_output_16_binary_accuracy: 0.8398 - binary_output_17_binary_accuracy: 0.4199 - binary_output_18_binary_accuracy: 0.7793 - binary_output_19_binary_accuracy: 0.8242 - binary_output_20_binary_accuracy: 0.8398 - binary_output_21_binary_accuracy: 0.9414 - binary_output_22_binary_accuracy: 0.9883 - binary_output_23_binary_accuracy: 0.9844 - binary_output_24_binary_accuracy: 0.9980 - binary_output_25_binary_accuracy: 0.9785 - binary_output_26_binary_accuracy: 0.8262 - binary_output_27_binary_accuracy: 0.4512 - binary_output_28_binary_accuracy: 0.7598 - binary_output_29_binary_accuracy: 0.7090 - binary_output_30_binary_accuracy: 0.9824 - binary_output_31_binary_accuracy: 0.5508 - binary_output_32_binary_accuracy: 0.9238 - binary_output_33_binary_accuracy: 0.7676 - binary_output_34_binary_accuracy: 0.4316 - categorical_output_sparse_categorical_accuracy: 0.7285\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 1024/22237 [>.............................] - ETA: 7s - loss: 14.4280 - binary_output_0_loss: 0.6420 - binary_output_1_loss: 0.0718 - binary_output_2_loss: 0.8012 - binary_output_3_loss: 0.6529 - binary_output_4_loss: 0.3915 - binary_output_5_loss: 0.3958 - binary_output_6_loss: 0.2874 - binary_output_7_loss: 0.3835 - binary_output_8_loss: 0.0034 - binary_output_9_loss: 0.4221 - binary_output_10_loss: 0.4951 - binary_output_11_loss: 0.4574 - binary_output_12_loss: 0.1946 - binary_output_13_loss: 0.3098 - binary_output_14_loss: 0.2175 - binary_output_15_loss: 0.3630 - binary_output_16_loss: 0.4064 - binary_output_17_loss: 0.7849 - binary_output_18_loss: 0.5031 - binary_output_19_loss: 0.4249 - binary_output_20_loss: 0.3430 - binary_output_21_loss: 0.3054 - binary_output_22_loss: 0.1842 - binary_output_23_loss: 0.1770 - binary_output_24_loss: 0.1135 - binary_output_25_loss: 0.1974 - binary_output_26_loss: 0.4021 - binary_output_27_loss: 0.6612 - binary_output_28_loss: 0.5161 - binary_output_29_loss: 0.5636 - binary_output_30_loss: 0.2389 - binary_output_31_loss: 0.5233 - binary_output_32_loss: 0.3255 - binary_output_33_loss: 0.4836 - binary_output_34_loss: 0.7513 - categorical_output_loss: 0.4332 - binary_output_0_binary_accuracy: 0.5869 - binary_output_1_binary_accuracy: 0.9971 - binary_output_2_binary_accuracy: 0.4863 - binary_output_3_binary_accuracy: 0.5742 - binary_output_4_binary_accuracy: 0.8135 - binary_output_5_binary_accuracy: 0.8574 - binary_output_6_binary_accuracy: 0.9678 - binary_output_7_binary_accuracy: 0.8438 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7949 - binary_output_10_binary_accuracy: 0.7275 - binary_output_11_binary_accuracy: 0.7637 - binary_output_12_binary_accuracy: 0.9404 - binary_output_13_binary_accuracy: 0.9170 - binary_output_14_binary_accuracy: 0.9824 - binary_output_15_binary_accuracy: 0.8330 - binary_output_16_binary_accuracy: 0.7949 - binary_output_17_binary_accuracy: 0.3623 - binary_output_18_binary_accuracy: 0.7236 - binary_output_19_binary_accuracy: 0.7881 - binary_output_20_binary_accuracy: 0.8105 - binary_output_21_binary_accuracy: 0.9258 - binary_output_22_binary_accuracy: 0.9902 - binary_output_23_binary_accuracy: 0.9736 - binary_output_24_binary_accuracy: 0.9941 - binary_output_25_binary_accuracy: 0.9688 - binary_output_26_binary_accuracy: 0.7930 - binary_output_27_binary_accuracy: 0.5176 - binary_output_28_binary_accuracy: 0.7246 - binary_output_29_binary_accuracy: 0.7158 - binary_output_30_binary_accuracy: 0.9766 - binary_output_31_binary_accuracy: 0.6475 - binary_output_32_binary_accuracy: 0.8994 - binary_output_33_binary_accuracy: 0.7178 - binary_output_34_binary_accuracy: 0.4727 - categorical_output_sparse_categorical_accuracy: 0.7666"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22237/22237 [==============================] - 7s 315us/step - loss: 13.6484 - binary_output_0_loss: 0.6276 - binary_output_1_loss: 0.1032 - binary_output_2_loss: 0.7553 - binary_output_3_loss: 0.5854 - binary_output_4_loss: 0.3921 - binary_output_5_loss: 0.3380 - binary_output_6_loss: 0.2913 - binary_output_7_loss: 0.3108 - binary_output_8_loss: 0.0031 - binary_output_9_loss: 0.3839 - binary_output_10_loss: 0.4777 - binary_output_11_loss: 0.4318 - binary_output_12_loss: 0.1817 - binary_output_13_loss: 0.3155 - binary_output_14_loss: 0.2050 - binary_output_15_loss: 0.3387 - binary_output_16_loss: 0.4052 - binary_output_17_loss: 0.7658 - binary_output_18_loss: 0.4689 - binary_output_19_loss: 0.4188 - binary_output_20_loss: 0.3565 - binary_output_21_loss: 0.2684 - binary_output_22_loss: 0.1335 - binary_output_23_loss: 0.1843 - binary_output_24_loss: 0.1075 - binary_output_25_loss: 0.1885 - binary_output_26_loss: 0.3821 - binary_output_27_loss: 0.6474 - binary_output_28_loss: 0.4565 - binary_output_29_loss: 0.4937 - binary_output_30_loss: 0.1905 - binary_output_31_loss: 0.5263 - binary_output_32_loss: 0.2458 - binary_output_33_loss: 0.4593 - binary_output_34_loss: 0.7246 - categorical_output_loss: 0.4768 - binary_output_0_binary_accuracy: 0.6156 - binary_output_1_binary_accuracy: 0.9955 - binary_output_2_binary_accuracy: 0.5101 - binary_output_3_binary_accuracy: 0.6158 - binary_output_4_binary_accuracy: 0.8015 - binary_output_5_binary_accuracy: 0.8778 - binary_output_6_binary_accuracy: 0.9696 - binary_output_7_binary_accuracy: 0.8762 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7910 - binary_output_10_binary_accuracy: 0.7412 - binary_output_11_binary_accuracy: 0.7675 - binary_output_12_binary_accuracy: 0.9372 - binary_output_13_binary_accuracy: 0.9252 - binary_output_14_binary_accuracy: 0.9830 - binary_output_15_binary_accuracy: 0.8403 - binary_output_16_binary_accuracy: 0.7890 - binary_output_17_binary_accuracy: 0.4161 - binary_output_18_binary_accuracy: 0.7207 - binary_output_19_binary_accuracy: 0.7837 - binary_output_20_binary_accuracy: 0.8065 - binary_output_21_binary_accuracy: 0.9228 - binary_output_22_binary_accuracy: 0.9915 - binary_output_23_binary_accuracy: 0.9754 - binary_output_24_binary_accuracy: 0.9929 - binary_output_25_binary_accuracy: 0.9669 - binary_output_26_binary_accuracy: 0.7965 - binary_output_27_binary_accuracy: 0.5830 - binary_output_28_binary_accuracy: 0.7483 - binary_output_29_binary_accuracy: 0.7209 - binary_output_30_binary_accuracy: 0.9840 - binary_output_31_binary_accuracy: 0.7121 - binary_output_32_binary_accuracy: 0.9102 - binary_output_33_binary_accuracy: 0.7230 - binary_output_34_binary_accuracy: 0.4909 - categorical_output_sparse_categorical_accuracy: 0.7582\n",
      "Epoch 10/40\n",
      "22237/22237 [==============================] - 7s 317us/step - loss: 13.3410 - binary_output_0_loss: 0.6113 - binary_output_1_loss: 0.1025 - binary_output_2_loss: 0.7352 - binary_output_3_loss: 0.5745 - binary_output_4_loss: 0.3869 - binary_output_5_loss: 0.3354 - binary_output_6_loss: 0.2824 - binary_output_7_loss: 0.2957 - binary_output_8_loss: 0.0026 - binary_output_9_loss: 0.3828 - binary_output_10_loss: 0.4655 - binary_output_11_loss: 0.4163 - binary_output_12_loss: 0.1775 - binary_output_13_loss: 0.3093 - binary_output_14_loss: 0.2057 - binary_output_15_loss: 0.3313 - binary_output_16_loss: 0.3971 - binary_output_17_loss: 0.7546 - binary_output_18_loss: 0.4565 - binary_output_19_loss: 0.4072 - binary_output_20_loss: 0.3515 - binary_output_21_loss: 0.2612 - binary_output_22_loss: 0.1276 - binary_output_23_loss: 0.1783 - binary_output_24_loss: 0.1044 - binary_output_25_loss: 0.1847 - binary_output_26_loss: 0.3778 - binary_output_27_loss: 0.6206 - binary_output_28_loss: 0.4392 - binary_output_29_loss: 0.4765 - binary_output_30_loss: 0.1880 - binary_output_31_loss: 0.5142 - binary_output_32_loss: 0.2426 - binary_output_33_loss: 0.4562 - binary_output_34_loss: 0.7110 - categorical_output_loss: 0.4752 - binary_output_0_binary_accuracy: 0.6330 - binary_output_1_binary_accuracy: 0.9953 - binary_output_2_binary_accuracy: 0.5268 - binary_output_3_binary_accuracy: 0.6226 - binary_output_4_binary_accuracy: 0.8140 - binary_output_5_binary_accuracy: 0.8688 - binary_output_6_binary_accuracy: 0.9588 - binary_output_7_binary_accuracy: 0.8835 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7896 - binary_output_10_binary_accuracy: 0.7483 - binary_output_11_binary_accuracy: 0.7693 - binary_output_12_binary_accuracy: 0.9381 - binary_output_13_binary_accuracy: 0.9220 - binary_output_14_binary_accuracy: 0.9782 - binary_output_15_binary_accuracy: 0.8437 - binary_output_16_binary_accuracy: 0.7916 - binary_output_17_binary_accuracy: 0.4235 - binary_output_18_binary_accuracy: 0.7269 - binary_output_19_binary_accuracy: 0.7822 - binary_output_20_binary_accuracy: 0.7992 - binary_output_21_binary_accuracy: 0.9264 - binary_output_22_binary_accuracy: 0.9912 - binary_output_23_binary_accuracy: 0.9746 - binary_output_24_binary_accuracy: 0.9940 - binary_output_25_binary_accuracy: 0.9663 - binary_output_26_binary_accuracy: 0.7962 - binary_output_27_binary_accuracy: 0.6103 - binary_output_28_binary_accuracy: 0.7597 - binary_output_29_binary_accuracy: 0.7322 - binary_output_30_binary_accuracy: 0.9821 - binary_output_31_binary_accuracy: 0.7206 - binary_output_32_binary_accuracy: 0.9060 - binary_output_33_binary_accuracy: 0.7342 - binary_output_34_binary_accuracy: 0.5025 - categorical_output_sparse_categorical_accuracy: 0.7591\n",
      "Epoch 11/40\n",
      " 1024/22237 [>.............................] - ETA: 6s - loss: 12.7275 - binary_output_0_loss: 0.5600 - binary_output_1_loss: 0.1446 - binary_output_2_loss: 0.7386 - binary_output_3_loss: 0.5538 - binary_output_4_loss: 0.3363 - binary_output_5_loss: 0.3104 - binary_output_6_loss: 0.2777 - binary_output_7_loss: 0.2326 - binary_output_8_loss: 0.0026 - binary_output_9_loss: 0.3418 - binary_output_10_loss: 0.4514 - binary_output_11_loss: 0.3473 - binary_output_12_loss: 0.1634 - binary_output_13_loss: 0.2694 - binary_output_14_loss: 0.2069 - binary_output_15_loss: 0.2831 - binary_output_16_loss: 0.3928 - binary_output_17_loss: 0.7591 - binary_output_18_loss: 0.4115 - binary_output_19_loss: 0.4279 - binary_output_20_loss: 0.3411 - binary_output_21_loss: 0.2972 - binary_output_22_loss: 0.0800 - binary_output_23_loss: 0.1586 - binary_output_24_loss: 0.0941 - binary_output_25_loss: 0.1643 - binary_output_26_loss: 0.3701 - binary_output_27_loss: 0.5974 - binary_output_28_loss: 0.4674 - binary_output_29_loss: 0.4256 - binary_output_30_loss: 0.2046 - binary_output_31_loss: 0.5392 - binary_output_32_loss: 0.1979 - binary_output_33_loss: 0.4273 - binary_output_34_loss: 0.7406 - categorical_output_loss: 0.4111 - binary_output_0_binary_accuracy: 0.6006 - binary_output_1_binary_accuracy: 0.9932 - binary_output_2_binary_accuracy: 0.4941 - binary_output_3_binary_accuracy: 0.6289 - binary_output_4_binary_accuracy: 0.8125 - binary_output_5_binary_accuracy: 0.8770 - binary_output_6_binary_accuracy: 0.9482 - binary_output_7_binary_accuracy: 0.8936 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7891 - binary_output_10_binary_accuracy: 0.7393 - binary_output_11_binary_accuracy: 0.7666 - binary_output_12_binary_accuracy: 0.9473 - binary_output_13_binary_accuracy: 0.9209 - binary_output_14_binary_accuracy: 0.9736 - binary_output_15_binary_accuracy: 0.8457 - binary_output_16_binary_accuracy: 0.7969 - binary_output_17_binary_accuracy: 0.4248 - binary_output_18_binary_accuracy: 0.7383 - binary_output_19_binary_accuracy: 0.7539 - binary_output_20_binary_accuracy: 0.8115 - binary_output_21_binary_accuracy: 0.9092 - binary_output_22_binary_accuracy: 0.9922 - binary_output_23_binary_accuracy: 0.9727 - binary_output_24_binary_accuracy: 0.9912 - binary_output_25_binary_accuracy: 0.9658 - binary_output_26_binary_accuracy: 0.7930 - binary_output_27_binary_accuracy: 0.6582 - binary_output_28_binary_accuracy: 0.7422 - binary_output_29_binary_accuracy: 0.7500 - binary_output_30_binary_accuracy: 0.9844 - binary_output_31_binary_accuracy: 0.7549 - binary_output_32_binary_accuracy: 0.8994 - binary_output_33_binary_accuracy: 0.7266 - binary_output_34_binary_accuracy: 0.4609 - categorical_output_sparse_categorical_accuracy: 0.753922237/22237 [==============================] - 8s 370us/step - loss: 13.0242 - binary_output_0_loss: 0.5984 - binary_output_1_loss: 0.0999 - binary_output_2_loss: 0.7132 - binary_output_3_loss: 0.5617 - binary_output_4_loss: 0.3733 - binary_output_5_loss: 0.3276 - binary_output_6_loss: 0.2797 - binary_output_7_loss: 0.2860 - binary_output_8_loss: 0.0021 - binary_output_9_loss: 0.3763 - binary_output_10_loss: 0.4511 - binary_output_11_loss: 0.4181 - binary_output_12_loss: 0.1687 - binary_output_13_loss: 0.3037 - binary_output_14_loss: 0.2004 - binary_output_15_loss: 0.3265 - binary_output_16_loss: 0.3868 - binary_output_17_loss: 0.7436 - binary_output_18_loss: 0.4417 - binary_output_19_loss: 0.4059 - binary_output_20_loss: 0.3473 - binary_output_21_loss: 0.2605 - binary_output_22_loss: 0.1286 - binary_output_23_loss: 0.1731 - binary_output_24_loss: 0.1036 - binary_output_25_loss: 0.1809 - binary_output_26_loss: 0.3648 - binary_output_27_loss: 0.6016 - binary_output_28_loss: 0.4339 - binary_output_29_loss: 0.4684 - binary_output_30_loss: 0.1831 - binary_output_31_loss: 0.4979 - binary_output_32_loss: 0.2366 - binary_output_33_loss: 0.4445 - binary_output_34_loss: 0.6925 - categorical_output_loss: 0.4629 - binary_output_0_binary_accuracy: 0.6460 - binary_output_1_binary_accuracy: 0.9948 - binary_output_2_binary_accuracy: 0.5496 - binary_output_3_binary_accuracy: 0.6310 - binary_output_4_binary_accuracy: 0.8110 - binary_output_5_binary_accuracy: 0.8754 - binary_output_6_binary_accuracy: 0.9527 - binary_output_7_binary_accuracy: 0.8859 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7889 - binary_output_10_binary_accuracy: 0.7525 - binary_output_11_binary_accuracy: 0.7749 - binary_output_12_binary_accuracy: 0.9431 - binary_output_13_binary_accuracy: 0.9211 - binary_output_14_binary_accuracy: 0.9765 - binary_output_15_binary_accuracy: 0.8497 - binary_output_16_binary_accuracy: 0.7975 - binary_output_17_binary_accuracy: 0.4406 - binary_output_18_binary_accuracy: 0.7364 - binary_output_19_binary_accuracy: 0.7803 - binary_output_20_binary_accuracy: 0.8059 - binary_output_21_binary_accuracy: 0.9211 - binary_output_22_binary_accuracy: 0.9913 - binary_output_23_binary_accuracy: 0.9703 - binary_output_24_binary_accuracy: 0.9929 - binary_output_25_binary_accuracy: 0.9681 - binary_output_26_binary_accuracy: 0.8002 - binary_output_27_binary_accuracy: 0.6308 - binary_output_28_binary_accuracy: 0.7608 - binary_output_29_binary_accuracy: 0.7366 - binary_output_30_binary_accuracy: 0.9829 - binary_output_31_binary_accuracy: 0.7296 - binary_output_32_binary_accuracy: 0.8997 - binary_output_33_binary_accuracy: 0.7329 - binary_output_34_binary_accuracy: 0.5318 - categorical_output_sparse_categorical_accuracy: 0.7618\n",
      "Epoch 12/40\n",
      "22237/22237 [==============================] - 6s 283us/step - loss: 12.7540 - binary_output_0_loss: 0.5814 - binary_output_1_loss: 0.0983 - binary_output_2_loss: 0.7021 - binary_output_3_loss: 0.5557 - binary_output_4_loss: 0.3711 - binary_output_5_loss: 0.3223 - binary_output_6_loss: 0.2717 - binary_output_7_loss: 0.2747 - binary_output_8_loss: 0.0019 - binary_output_9_loss: 0.3683 - binary_output_10_loss: 0.4351 - binary_output_11_loss: 0.4133 - binary_output_12_loss: 0.1649 - binary_output_13_loss: 0.2931 - binary_output_14_loss: 0.1963 - binary_output_15_loss: 0.3166 - binary_output_16_loss: 0.3819 - binary_output_17_loss: 0.7355 - binary_output_18_loss: 0.4336 - binary_output_19_loss: 0.3906 - binary_output_20_loss: 0.3411 - binary_output_21_loss: 0.2508 - binary_output_22_loss: 0.1312 - binary_output_23_loss: 0.1687 - binary_output_24_loss: 0.1028 - binary_output_25_loss: 0.1755 - binary_output_26_loss: 0.3580 - binary_output_27_loss: 0.5796 - binary_output_28_loss: 0.4165 - binary_output_29_loss: 0.4557 - binary_output_30_loss: 0.1792 - binary_output_31_loss: 0.4825 - binary_output_32_loss: 0.2353 - binary_output_33_loss: 0.4403 - binary_output_34_loss: 0.6792 - categorical_output_loss: 0.4602 - binary_output_0_binary_accuracy: 0.6547 - binary_output_1_binary_accuracy: 0.9949 - binary_output_2_binary_accuracy: 0.5709 - binary_output_3_binary_accuracy: 0.6394 - binary_output_4_binary_accuracy: 0.8108 - binary_output_5_binary_accuracy: 0.8660 - binary_output_6_binary_accuracy: 0.9497 - binary_output_7_binary_accuracy: 0.8915 - binary_output_8_binary_accuracy: 0.9999 - binary_output_9_binary_accuracy: 0.7965 - binary_output_10_binary_accuracy: 0.7566 - binary_output_11_binary_accuracy: 0.7725 - binary_output_12_binary_accuracy: 0.9477 - binary_output_13_binary_accuracy: 0.9193 - binary_output_14_binary_accuracy: 0.9757 - binary_output_15_binary_accuracy: 0.8444 - binary_output_16_binary_accuracy: 0.7993 - binary_output_17_binary_accuracy: 0.4560 - binary_output_18_binary_accuracy: 0.7407 - binary_output_19_binary_accuracy: 0.7874 - binary_output_20_binary_accuracy: 0.8091 - binary_output_21_binary_accuracy: 0.9180 - binary_output_22_binary_accuracy: 0.9897 - binary_output_23_binary_accuracy: 0.9703 - binary_output_24_binary_accuracy: 0.9927 - binary_output_25_binary_accuracy: 0.9611 - binary_output_26_binary_accuracy: 0.7967 - binary_output_27_binary_accuracy: 0.6598 - binary_output_28_binary_accuracy: 0.7716 - binary_output_29_binary_accuracy: 0.7431 - binary_output_30_binary_accuracy: 0.9796 - binary_output_31_binary_accuracy: 0.7355 - binary_output_32_binary_accuracy: 0.9025 - binary_output_33_binary_accuracy: 0.7356 - binary_output_34_binary_accuracy: 0.5429 - categorical_output_sparse_categorical_accuracy: 0.7666\n",
      "Epoch 13/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  512/22237 [..............................] - ETA: 5s - loss: 12.2644 - binary_output_0_loss: 0.5859 - binary_output_1_loss: 0.1091 - binary_output_2_loss: 0.7124 - binary_output_3_loss: 0.5323 - binary_output_4_loss: 0.3306 - binary_output_5_loss: 0.2864 - binary_output_6_loss: 0.2137 - binary_output_7_loss: 0.2537 - binary_output_8_loss: 0.0023 - binary_output_9_loss: 0.4095 - binary_output_10_loss: 0.4491 - binary_output_11_loss: 0.4564 - binary_output_12_loss: 0.1303 - binary_output_13_loss: 0.3119 - binary_output_14_loss: 0.1984 - binary_output_15_loss: 0.2962 - binary_output_16_loss: 0.4134 - binary_output_17_loss: 0.7788 - binary_output_18_loss: 0.3990 - binary_output_19_loss: 0.3697 - binary_output_20_loss: 0.3537 - binary_output_21_loss: 0.2676 - binary_output_22_loss: 0.0537 - binary_output_23_loss: 0.1065 - binary_output_24_loss: 0.1132 - binary_output_25_loss: 0.0959 - binary_output_26_loss: 0.3627 - binary_output_27_loss: 0.5321 - binary_output_28_loss: 0.3478 - binary_output_29_loss: 0.4014 - binary_output_30_loss: 0.1438 - binary_output_31_loss: 0.5006 - binary_output_32_loss: 0.2002 - binary_output_33_loss: 0.3650 - binary_output_34_loss: 0.7275 - categorical_output_loss: 0.4535 - binary_output_0_binary_accuracy: 0.5664 - binary_output_1_binary_accuracy: 0.9922 - binary_output_2_binary_accuracy: 0.5781 - binary_output_3_binary_accuracy: 0.6309 - binary_output_4_binary_accuracy: 0.7734 - binary_output_5_binary_accuracy: 0.9082 - binary_output_6_binary_accuracy: 0.9629 - binary_output_7_binary_accuracy: 0.9531 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7812 - binary_output_10_binary_accuracy: 0.6699 - binary_output_11_binary_accuracy: 0.7715 - binary_output_12_binary_accuracy: 0.9375 - binary_output_13_binary_accuracy: 0.8867 - binary_output_14_binary_accuracy: 0.9629 - binary_output_15_binary_accuracy: 0.8848 - binary_output_16_binary_accuracy: 0.8184 - binary_output_17_binary_accuracy: 0.3984 - binary_output_18_binary_accuracy: 0.7617 - binary_output_19_binary_accuracy: 0.8262 - binary_output_20_binary_accuracy: 0.8105 - binary_output_21_binary_accuracy: 0.8848 - binary_output_22_binary_accuracy: 0.9941 - binary_output_23_binary_accuracy: 0.9785 - binary_output_24_binary_accuracy: 0.9883 - binary_output_25_binary_accuracy: 0.9629 - binary_output_26_binary_accuracy: 0.8164 - binary_output_27_binary_accuracy: 0.5703 - binary_output_28_binary_accuracy: 0.8105 - binary_output_29_binary_accuracy: 0.6992 - binary_output_30_binary_accuracy: 0.9824 - binary_output_31_binary_accuracy: 0.6406 - binary_output_32_binary_accuracy: 0.8770 - binary_output_33_binary_accuracy: 0.7520 - binary_output_34_binary_accuracy: 0.4277 - categorical_output_sparse_categorical_accuracy: 0.7871\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 1024/22237 [>.............................] - ETA: 6s - loss: 12.1948 - binary_output_0_loss: 0.5770 - binary_output_1_loss: 0.1100 - binary_output_2_loss: 0.6811 - binary_output_3_loss: 0.5598 - binary_output_4_loss: 0.3235 - binary_output_5_loss: 0.2882 - binary_output_6_loss: 0.1855 - binary_output_7_loss: 0.2852 - binary_output_8_loss: 0.0018 - binary_output_9_loss: 0.3443 - binary_output_10_loss: 0.4472 - binary_output_11_loss: 0.4123 - binary_output_12_loss: 0.1292 - binary_output_13_loss: 0.3418 - binary_output_14_loss: 0.1821 - binary_output_15_loss: 0.2765 - binary_output_16_loss: 0.3858 - binary_output_17_loss: 0.7126 - binary_output_18_loss: 0.4037 - binary_output_19_loss: 0.3725 - binary_output_20_loss: 0.3285 - binary_output_21_loss: 0.2462 - binary_output_22_loss: 0.0674 - binary_output_23_loss: 0.1398 - binary_output_24_loss: 0.0817 - binary_output_25_loss: 0.1776 - binary_output_26_loss: 0.3361 - binary_output_27_loss: 0.5361 - binary_output_28_loss: 0.3849 - binary_output_29_loss: 0.5075 - binary_output_30_loss: 0.1826 - binary_output_31_loss: 0.4370 - binary_output_32_loss: 0.1816 - binary_output_33_loss: 0.3934 - binary_output_34_loss: 0.7176 - categorical_output_loss: 0.4564 - binary_output_0_binary_accuracy: 0.6289 - binary_output_1_binary_accuracy: 0.9932 - binary_output_2_binary_accuracy: 0.5996 - binary_output_3_binary_accuracy: 0.6738 - binary_output_4_binary_accuracy: 0.8145 - binary_output_5_binary_accuracy: 0.9023 - binary_output_6_binary_accuracy: 0.9717 - binary_output_7_binary_accuracy: 0.9297 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8057 - binary_output_10_binary_accuracy: 0.7266 - binary_output_11_binary_accuracy: 0.7949 - binary_output_12_binary_accuracy: 0.9512 - binary_output_13_binary_accuracy: 0.9102 - binary_output_14_binary_accuracy: 0.9717 - binary_output_15_binary_accuracy: 0.8857 - binary_output_16_binary_accuracy: 0.8223 - binary_output_17_binary_accuracy: 0.4482 - binary_output_18_binary_accuracy: 0.7812 - binary_output_19_binary_accuracy: 0.8232 - binary_output_20_binary_accuracy: 0.8262 - binary_output_21_binary_accuracy: 0.9082 - binary_output_22_binary_accuracy: 0.9951 - binary_output_23_binary_accuracy: 0.9775 - binary_output_24_binary_accuracy: 0.9912 - binary_output_25_binary_accuracy: 0.9658 - binary_output_26_binary_accuracy: 0.8281 - binary_output_27_binary_accuracy: 0.6475 - binary_output_28_binary_accuracy: 0.8076 - binary_output_29_binary_accuracy: 0.7373 - binary_output_30_binary_accuracy: 0.9814 - binary_output_31_binary_accuracy: 0.7158 - binary_output_32_binary_accuracy: 0.8975 - binary_output_33_binary_accuracy: 0.7529 - binary_output_34_binary_accuracy: 0.5215 - categorical_output_sparse_categorical_accuracy: 0.7705"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22237/22237 [==============================] - 6s 268us/step - loss: 12.4624 - binary_output_0_loss: 0.5658 - binary_output_1_loss: 0.1002 - binary_output_2_loss: 0.6808 - binary_output_3_loss: 0.5419 - binary_output_4_loss: 0.3570 - binary_output_5_loss: 0.3168 - binary_output_6_loss: 0.2716 - binary_output_7_loss: 0.2622 - binary_output_8_loss: 0.0015 - binary_output_9_loss: 0.3626 - binary_output_10_loss: 0.4315 - binary_output_11_loss: 0.3946 - binary_output_12_loss: 0.1591 - binary_output_13_loss: 0.2887 - binary_output_14_loss: 0.1927 - binary_output_15_loss: 0.3166 - binary_output_16_loss: 0.3768 - binary_output_17_loss: 0.7228 - binary_output_18_loss: 0.4203 - binary_output_19_loss: 0.3896 - binary_output_20_loss: 0.3316 - binary_output_21_loss: 0.2462 - binary_output_22_loss: 0.1233 - binary_output_23_loss: 0.1619 - binary_output_24_loss: 0.0967 - binary_output_25_loss: 0.1716 - binary_output_26_loss: 0.3502 - binary_output_27_loss: 0.5569 - binary_output_28_loss: 0.4117 - binary_output_29_loss: 0.4396 - binary_output_30_loss: 0.1773 - binary_output_31_loss: 0.4641 - binary_output_32_loss: 0.2290 - binary_output_33_loss: 0.4324 - binary_output_34_loss: 0.6665 - categorical_output_loss: 0.4527 - binary_output_0_binary_accuracy: 0.6671 - binary_output_1_binary_accuracy: 0.9946 - binary_output_2_binary_accuracy: 0.5862 - binary_output_3_binary_accuracy: 0.6451 - binary_output_4_binary_accuracy: 0.8196 - binary_output_5_binary_accuracy: 0.8705 - binary_output_6_binary_accuracy: 0.9473 - binary_output_7_binary_accuracy: 0.8978 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7922 - binary_output_10_binary_accuracy: 0.7630 - binary_output_11_binary_accuracy: 0.7814 - binary_output_12_binary_accuracy: 0.9448 - binary_output_13_binary_accuracy: 0.9160 - binary_output_14_binary_accuracy: 0.9747 - binary_output_15_binary_accuracy: 0.8449 - binary_output_16_binary_accuracy: 0.8023 - binary_output_17_binary_accuracy: 0.4736 - binary_output_18_binary_accuracy: 0.7533 - binary_output_19_binary_accuracy: 0.7894 - binary_output_20_binary_accuracy: 0.8152 - binary_output_21_binary_accuracy: 0.9175 - binary_output_22_binary_accuracy: 0.9890 - binary_output_23_binary_accuracy: 0.9691 - binary_output_24_binary_accuracy: 0.9924 - binary_output_25_binary_accuracy: 0.9632 - binary_output_26_binary_accuracy: 0.8060 - binary_output_27_binary_accuracy: 0.6683 - binary_output_28_binary_accuracy: 0.7747 - binary_output_29_binary_accuracy: 0.7465 - binary_output_30_binary_accuracy: 0.9770 - binary_output_31_binary_accuracy: 0.7485 - binary_output_32_binary_accuracy: 0.8993 - binary_output_33_binary_accuracy: 0.7338 - binary_output_34_binary_accuracy: 0.5588 - categorical_output_sparse_categorical_accuracy: 0.7693\n",
      "Epoch 14/40\n",
      "22237/22237 [==============================] - 6s 256us/step - loss: 12.2531 - binary_output_0_loss: 0.5590 - binary_output_1_loss: 0.0991 - binary_output_2_loss: 0.6661 - binary_output_3_loss: 0.5297 - binary_output_4_loss: 0.3558 - binary_output_5_loss: 0.3132 - binary_output_6_loss: 0.2644 - binary_output_7_loss: 0.2522 - binary_output_8_loss: 0.0015 - binary_output_9_loss: 0.3599 - binary_output_10_loss: 0.4221 - binary_output_11_loss: 0.3937 - binary_output_12_loss: 0.1562 - binary_output_13_loss: 0.2860 - binary_output_14_loss: 0.1905 - binary_output_15_loss: 0.3098 - binary_output_16_loss: 0.3676 - binary_output_17_loss: 0.7185 - binary_output_18_loss: 0.4120 - binary_output_19_loss: 0.3818 - binary_output_20_loss: 0.3296 - binary_output_21_loss: 0.2458 - binary_output_22_loss: 0.1209 - binary_output_23_loss: 0.1641 - binary_output_24_loss: 0.0970 - binary_output_25_loss: 0.1676 - binary_output_26_loss: 0.3414 - binary_output_27_loss: 0.5440 - binary_output_28_loss: 0.3991 - binary_output_29_loss: 0.4196 - binary_output_30_loss: 0.1673 - binary_output_31_loss: 0.4458 - binary_output_32_loss: 0.2291 - binary_output_33_loss: 0.4282 - binary_output_34_loss: 0.6593 - categorical_output_loss: 0.4452 - binary_output_0_binary_accuracy: 0.6693 - binary_output_1_binary_accuracy: 0.9939 - binary_output_2_binary_accuracy: 0.6015 - binary_output_3_binary_accuracy: 0.6556 - binary_output_4_binary_accuracy: 0.8193 - binary_output_5_binary_accuracy: 0.8691 - binary_output_6_binary_accuracy: 0.9404 - binary_output_7_binary_accuracy: 0.9009 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7973 - binary_output_10_binary_accuracy: 0.7626 - binary_output_11_binary_accuracy: 0.7836 - binary_output_12_binary_accuracy: 0.9506 - binary_output_13_binary_accuracy: 0.9168 - binary_output_14_binary_accuracy: 0.9674 - binary_output_15_binary_accuracy: 0.8435 - binary_output_16_binary_accuracy: 0.8074 - binary_output_17_binary_accuracy: 0.4730 - binary_output_18_binary_accuracy: 0.7541 - binary_output_19_binary_accuracy: 0.7944 - binary_output_20_binary_accuracy: 0.8166 - binary_output_21_binary_accuracy: 0.9189 - binary_output_22_binary_accuracy: 0.9874 - binary_output_23_binary_accuracy: 0.9650 - binary_output_24_binary_accuracy: 0.9917 - binary_output_25_binary_accuracy: 0.9568 - binary_output_26_binary_accuracy: 0.8042 - binary_output_27_binary_accuracy: 0.6867 - binary_output_28_binary_accuracy: 0.7820 - binary_output_29_binary_accuracy: 0.7546 - binary_output_30_binary_accuracy: 0.9764 - binary_output_31_binary_accuracy: 0.7497 - binary_output_32_binary_accuracy: 0.9011 - binary_output_33_binary_accuracy: 0.7340 - binary_output_34_binary_accuracy: 0.5722 - categorical_output_sparse_categorical_accuracy: 0.7713\n",
      "Epoch 15/40\n",
      " 1024/22237 [>.............................] - ETA: 7s - loss: 11.4314 - binary_output_0_loss: 0.5214 - binary_output_1_loss: 0.1575 - binary_output_2_loss: 0.6030 - binary_output_3_loss: 0.4626 - binary_output_4_loss: 0.3334 - binary_output_5_loss: 0.2921 - binary_output_6_loss: 0.2997 - binary_output_7_loss: 0.2020 - binary_output_8_loss: 0.0013 - binary_output_9_loss: 0.3045 - binary_output_10_loss: 0.3996 - binary_output_11_loss: 0.3877 - binary_output_12_loss: 0.2468 - binary_output_13_loss: 0.2985 - binary_output_14_loss: 0.1898 - binary_output_15_loss: 0.2518 - binary_output_16_loss: 0.3410 - binary_output_17_loss: 0.6688 - binary_output_18_loss: 0.4004 - binary_output_19_loss: 0.3695 - binary_output_20_loss: 0.2729 - binary_output_21_loss: 0.1983 - binary_output_22_loss: 0.0848 - binary_output_23_loss: 0.1645 - binary_output_24_loss: 0.0789 - binary_output_25_loss: 0.1182 - binary_output_26_loss: 0.3314 - binary_output_27_loss: 0.4851 - binary_output_28_loss: 0.3668 - binary_output_29_loss: 0.3826 - binary_output_30_loss: 0.1557 - binary_output_31_loss: 0.4185 - binary_output_32_loss: 0.1833 - binary_output_33_loss: 0.3432 - binary_output_34_loss: 0.6880 - categorical_output_loss: 0.4276 - binary_output_0_binary_accuracy: 0.6777 - binary_output_1_binary_accuracy: 0.9902 - binary_output_2_binary_accuracy: 0.6396 - binary_output_3_binary_accuracy: 0.6816 - binary_output_4_binary_accuracy: 0.8184 - binary_output_5_binary_accuracy: 0.8799 - binary_output_6_binary_accuracy: 0.9473 - binary_output_7_binary_accuracy: 0.9238 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7939 - binary_output_10_binary_accuracy: 0.7852 - binary_output_11_binary_accuracy: 0.7842 - binary_output_12_binary_accuracy: 0.9453 - binary_output_13_binary_accuracy: 0.9150 - binary_output_14_binary_accuracy: 0.9619 - binary_output_15_binary_accuracy: 0.8555 - binary_output_16_binary_accuracy: 0.8223 - binary_output_17_binary_accuracy: 0.5264 - binary_output_18_binary_accuracy: 0.7637 - binary_output_19_binary_accuracy: 0.8213 - binary_output_20_binary_accuracy: 0.8164 - binary_output_21_binary_accuracy: 0.8887 - binary_output_22_binary_accuracy: 0.9893 - binary_output_23_binary_accuracy: 0.9648 - binary_output_24_binary_accuracy: 0.9941 - binary_output_25_binary_accuracy: 0.9580 - binary_output_26_binary_accuracy: 0.8154 - binary_output_27_binary_accuracy: 0.7188 - binary_output_28_binary_accuracy: 0.7959 - binary_output_29_binary_accuracy: 0.7598 - binary_output_30_binary_accuracy: 0.9707 - binary_output_31_binary_accuracy: 0.7939 - binary_output_32_binary_accuracy: 0.9023 - binary_output_33_binary_accuracy: 0.7617 - binary_output_34_binary_accuracy: 0.5850 - categorical_output_sparse_categorical_accuracy: 0.741222237/22237 [==============================] - 7s 311us/step - loss: 11.9722 - binary_output_0_loss: 0.5431 - binary_output_1_loss: 0.0954 - binary_output_2_loss: 0.6529 - binary_output_3_loss: 0.5284 - binary_output_4_loss: 0.3471 - binary_output_5_loss: 0.3043 - binary_output_6_loss: 0.2603 - binary_output_7_loss: 0.2399 - binary_output_8_loss: 0.0013 - binary_output_9_loss: 0.3524 - binary_output_10_loss: 0.4143 - binary_output_11_loss: 0.3850 - binary_output_12_loss: 0.1541 - binary_output_13_loss: 0.2816 - binary_output_14_loss: 0.1849 - binary_output_15_loss: 0.3087 - binary_output_16_loss: 0.3645 - binary_output_17_loss: 0.7086 - binary_output_18_loss: 0.4069 - binary_output_19_loss: 0.3776 - binary_output_20_loss: 0.3198 - binary_output_21_loss: 0.2355 - binary_output_22_loss: 0.1190 - binary_output_23_loss: 0.1580 - binary_output_24_loss: 0.0958 - binary_output_25_loss: 0.1648 - binary_output_26_loss: 0.3375 - binary_output_27_loss: 0.5301 - binary_output_28_loss: 0.3924 - binary_output_29_loss: 0.4104 - binary_output_30_loss: 0.1645 - binary_output_31_loss: 0.4256 - binary_output_32_loss: 0.2217 - binary_output_33_loss: 0.4190 - binary_output_34_loss: 0.6436 - categorical_output_loss: 0.4410 - binary_output_0_binary_accuracy: 0.6820 - binary_output_1_binary_accuracy: 0.9935 - binary_output_2_binary_accuracy: 0.6127 - binary_output_3_binary_accuracy: 0.6571 - binary_output_4_binary_accuracy: 0.8176 - binary_output_5_binary_accuracy: 0.8714 - binary_output_6_binary_accuracy: 0.9403 - binary_output_7_binary_accuracy: 0.9072 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7957 - binary_output_10_binary_accuracy: 0.7703 - binary_output_11_binary_accuracy: 0.7848 - binary_output_12_binary_accuracy: 0.9484 - binary_output_13_binary_accuracy: 0.9123 - binary_output_14_binary_accuracy: 0.9712 - binary_output_15_binary_accuracy: 0.8467 - binary_output_16_binary_accuracy: 0.8072 - binary_output_17_binary_accuracy: 0.4865 - binary_output_18_binary_accuracy: 0.7573 - binary_output_19_binary_accuracy: 0.7944 - binary_output_20_binary_accuracy: 0.8197 - binary_output_21_binary_accuracy: 0.9098 - binary_output_22_binary_accuracy: 0.9888 - binary_output_23_binary_accuracy: 0.9656 - binary_output_24_binary_accuracy: 0.9917 - binary_output_25_binary_accuracy: 0.9550 - binary_output_26_binary_accuracy: 0.8049 - binary_output_27_binary_accuracy: 0.6984 - binary_output_28_binary_accuracy: 0.7869 - binary_output_29_binary_accuracy: 0.7571 - binary_output_30_binary_accuracy: 0.9736 - binary_output_31_binary_accuracy: 0.7699 - binary_output_32_binary_accuracy: 0.9004 - binary_output_33_binary_accuracy: 0.7407 - binary_output_34_binary_accuracy: 0.5840 - categorical_output_sparse_categorical_accuracy: 0.7714\n",
      "Epoch 16/40\n",
      "22237/22237 [==============================] - 6s 276us/step - loss: 11.7292 - binary_output_0_loss: 0.5407 - binary_output_1_loss: 0.0937 - binary_output_2_loss: 0.6401 - binary_output_3_loss: 0.5149 - binary_output_4_loss: 0.3437 - binary_output_5_loss: 0.3012 - binary_output_6_loss: 0.2585 - binary_output_7_loss: 0.2297 - binary_output_8_loss: 0.0011 - binary_output_9_loss: 0.3449 - binary_output_10_loss: 0.4042 - binary_output_11_loss: 0.3852 - binary_output_12_loss: 0.1493 - binary_output_13_loss: 0.2707 - binary_output_14_loss: 0.1833 - binary_output_15_loss: 0.3000 - binary_output_16_loss: 0.3527 - binary_output_17_loss: 0.7027 - binary_output_18_loss: 0.3922 - binary_output_19_loss: 0.3740 - binary_output_20_loss: 0.3181 - binary_output_21_loss: 0.2314 - binary_output_22_loss: 0.1162 - binary_output_23_loss: 0.1528 - binary_output_24_loss: 0.0902 - binary_output_25_loss: 0.1645 - binary_output_26_loss: 0.3280 - binary_output_27_loss: 0.5092 - binary_output_28_loss: 0.3854 - binary_output_29_loss: 0.3891 - binary_output_30_loss: 0.1633 - binary_output_31_loss: 0.4007 - binary_output_32_loss: 0.2160 - binary_output_33_loss: 0.4112 - binary_output_34_loss: 0.6406 - categorical_output_loss: 0.4353 - binary_output_0_binary_accuracy: 0.6830 - binary_output_1_binary_accuracy: 0.9935 - binary_output_2_binary_accuracy: 0.6267 - binary_output_3_binary_accuracy: 0.6689 - binary_output_4_binary_accuracy: 0.8255 - binary_output_5_binary_accuracy: 0.8697 - binary_output_6_binary_accuracy: 0.9377 - binary_output_7_binary_accuracy: 0.9096 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8007 - binary_output_10_binary_accuracy: 0.7737 - binary_output_11_binary_accuracy: 0.7877 - binary_output_12_binary_accuracy: 0.9527 - binary_output_13_binary_accuracy: 0.9095 - binary_output_14_binary_accuracy: 0.9717 - binary_output_15_binary_accuracy: 0.8490 - binary_output_16_binary_accuracy: 0.8188 - binary_output_17_binary_accuracy: 0.4929 - binary_output_18_binary_accuracy: 0.7689 - binary_output_19_binary_accuracy: 0.7919 - binary_output_20_binary_accuracy: 0.8224 - binary_output_21_binary_accuracy: 0.9081 - binary_output_22_binary_accuracy: 0.9875 - binary_output_23_binary_accuracy: 0.9633 - binary_output_24_binary_accuracy: 0.9915 - binary_output_25_binary_accuracy: 0.9601 - binary_output_26_binary_accuracy: 0.8108 - binary_output_27_binary_accuracy: 0.7137 - binary_output_28_binary_accuracy: 0.7939 - binary_output_29_binary_accuracy: 0.7711 - binary_output_30_binary_accuracy: 0.9694 - binary_output_31_binary_accuracy: 0.7770 - binary_output_32_binary_accuracy: 0.9039 - binary_output_33_binary_accuracy: 0.7489 - binary_output_34_binary_accuracy: 0.5905 - categorical_output_sparse_categorical_accuracy: 0.7765\n",
      "Epoch 17/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  512/22237 [..............................] - ETA: 5s - loss: 10.7977 - binary_output_0_loss: 0.4930 - binary_output_1_loss: 0.1771 - binary_output_2_loss: 0.6306 - binary_output_3_loss: 0.4677 - binary_output_4_loss: 0.3624 - binary_output_5_loss: 0.3092 - binary_output_6_loss: 0.2313 - binary_output_7_loss: 0.1687 - binary_output_8_loss: 0.0014 - binary_output_9_loss: 0.2964 - binary_output_10_loss: 0.3413 - binary_output_11_loss: 0.3157 - binary_output_12_loss: 0.1927 - binary_output_13_loss: 0.1771 - binary_output_14_loss: 0.1630 - binary_output_15_loss: 0.2245 - binary_output_16_loss: 0.3017 - binary_output_17_loss: 0.7178 - binary_output_18_loss: 0.3441 - binary_output_19_loss: 0.3635 - binary_output_20_loss: 0.2829 - binary_output_21_loss: 0.2296 - binary_output_22_loss: 0.0970 - binary_output_23_loss: 0.1479 - binary_output_24_loss: 0.0785 - binary_output_25_loss: 0.1258 - binary_output_26_loss: 0.2810 - binary_output_27_loss: 0.5389 - binary_output_28_loss: 0.4405 - binary_output_29_loss: 0.2952 - binary_output_30_loss: 0.1519 - binary_output_31_loss: 0.3235 - binary_output_32_loss: 0.1927 - binary_output_33_loss: 0.3518 - binary_output_34_loss: 0.5929 - categorical_output_loss: 0.3882 - binary_output_0_binary_accuracy: 0.6289 - binary_output_1_binary_accuracy: 0.9883 - binary_output_2_binary_accuracy: 0.5547 - binary_output_3_binary_accuracy: 0.6719 - binary_output_4_binary_accuracy: 0.7773 - binary_output_5_binary_accuracy: 0.8789 - binary_output_6_binary_accuracy: 0.9375 - binary_output_7_binary_accuracy: 0.9199 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7891 - binary_output_10_binary_accuracy: 0.7793 - binary_output_11_binary_accuracy: 0.7539 - binary_output_12_binary_accuracy: 0.9219 - binary_output_13_binary_accuracy: 0.9297 - binary_output_14_binary_accuracy: 0.9609 - binary_output_15_binary_accuracy: 0.8496 - binary_output_16_binary_accuracy: 0.8125 - binary_output_17_binary_accuracy: 0.5176 - binary_output_18_binary_accuracy: 0.7617 - binary_output_19_binary_accuracy: 0.7734 - binary_output_20_binary_accuracy: 0.8086 - binary_output_21_binary_accuracy: 0.9023 - binary_output_22_binary_accuracy: 0.9863 - binary_output_23_binary_accuracy: 0.9590 - binary_output_24_binary_accuracy: 0.9883 - binary_output_25_binary_accuracy: 0.9648 - binary_output_26_binary_accuracy: 0.7949 - binary_output_27_binary_accuracy: 0.7207 - binary_output_28_binary_accuracy: 0.7773 - binary_output_29_binary_accuracy: 0.7930 - binary_output_30_binary_accuracy: 0.9668 - binary_output_31_binary_accuracy: 0.8184 - binary_output_32_binary_accuracy: 0.8945 - binary_output_33_binary_accuracy: 0.7480 - binary_output_34_binary_accuracy: 0.5254 - categorical_output_sparse_categorical_accuracy: 0.7832\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 1024/22237 [>.............................] - ETA: 5s - loss: 11.0293 - binary_output_0_loss: 0.4982 - binary_output_1_loss: 0.1284 - binary_output_2_loss: 0.6134 - binary_output_3_loss: 0.4555 - binary_output_4_loss: 0.3399 - binary_output_5_loss: 0.2996 - binary_output_6_loss: 0.1894 - binary_output_7_loss: 0.1868 - binary_output_8_loss: 0.0012 - binary_output_9_loss: 0.3134 - binary_output_10_loss: 0.3593 - binary_output_11_loss: 0.3350 - binary_output_12_loss: 0.1385 - binary_output_13_loss: 0.1998 - binary_output_14_loss: 0.2096 - binary_output_15_loss: 0.2417 - binary_output_16_loss: 0.3122 - binary_output_17_loss: 0.7087 - binary_output_18_loss: 0.3699 - binary_output_19_loss: 0.3514 - binary_output_20_loss: 0.3388 - binary_output_21_loss: 0.2596 - binary_output_22_loss: 0.0935 - binary_output_23_loss: 0.1412 - binary_output_24_loss: 0.1001 - binary_output_25_loss: 0.1566 - binary_output_26_loss: 0.3049 - binary_output_27_loss: 0.4848 - binary_output_28_loss: 0.4113 - binary_output_29_loss: 0.3162 - binary_output_30_loss: 0.1594 - binary_output_31_loss: 0.3693 - binary_output_32_loss: 0.2409 - binary_output_33_loss: 0.3719 - binary_output_34_loss: 0.6253 - categorical_output_loss: 0.4033 - binary_output_0_binary_accuracy: 0.6855 - binary_output_1_binary_accuracy: 0.9922 - binary_output_2_binary_accuracy: 0.6094 - binary_output_3_binary_accuracy: 0.6758 - binary_output_4_binary_accuracy: 0.8135 - binary_output_5_binary_accuracy: 0.8721 - binary_output_6_binary_accuracy: 0.9326 - binary_output_7_binary_accuracy: 0.9062 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8076 - binary_output_10_binary_accuracy: 0.7930 - binary_output_11_binary_accuracy: 0.7891 - binary_output_12_binary_accuracy: 0.9365 - binary_output_13_binary_accuracy: 0.9375 - binary_output_14_binary_accuracy: 0.9590 - binary_output_15_binary_accuracy: 0.8555 - binary_output_16_binary_accuracy: 0.8105 - binary_output_17_binary_accuracy: 0.5361 - binary_output_18_binary_accuracy: 0.7646 - binary_output_19_binary_accuracy: 0.7852 - binary_output_20_binary_accuracy: 0.8076 - binary_output_21_binary_accuracy: 0.9062 - binary_output_22_binary_accuracy: 0.9873 - binary_output_23_binary_accuracy: 0.9619 - binary_output_24_binary_accuracy: 0.9873 - binary_output_25_binary_accuracy: 0.9648 - binary_output_26_binary_accuracy: 0.7930 - binary_output_27_binary_accuracy: 0.7275 - binary_output_28_binary_accuracy: 0.7744 - binary_output_29_binary_accuracy: 0.7832 - binary_output_30_binary_accuracy: 0.9629 - binary_output_31_binary_accuracy: 0.8047 - binary_output_32_binary_accuracy: 0.8887 - binary_output_33_binary_accuracy: 0.7471 - binary_output_34_binary_accuracy: 0.5840 - categorical_output_sparse_categorical_accuracy: 0.7861"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22237/22237 [==============================] - 6s 262us/step - loss: 11.4583 - binary_output_0_loss: 0.5209 - binary_output_1_loss: 0.0925 - binary_output_2_loss: 0.6200 - binary_output_3_loss: 0.5101 - binary_output_4_loss: 0.3263 - binary_output_5_loss: 0.2938 - binary_output_6_loss: 0.2471 - binary_output_7_loss: 0.2207 - binary_output_8_loss: 0.0010 - binary_output_9_loss: 0.3390 - binary_output_10_loss: 0.3912 - binary_output_11_loss: 0.3704 - binary_output_12_loss: 0.1441 - binary_output_13_loss: 0.2674 - binary_output_14_loss: 0.1774 - binary_output_15_loss: 0.2897 - binary_output_16_loss: 0.3519 - binary_output_17_loss: 0.6880 - binary_output_18_loss: 0.3875 - binary_output_19_loss: 0.3627 - binary_output_20_loss: 0.3137 - binary_output_21_loss: 0.2312 - binary_output_22_loss: 0.1181 - binary_output_23_loss: 0.1489 - binary_output_24_loss: 0.0919 - binary_output_25_loss: 0.1553 - binary_output_26_loss: 0.3226 - binary_output_27_loss: 0.4949 - binary_output_28_loss: 0.3725 - binary_output_29_loss: 0.3785 - binary_output_30_loss: 0.1584 - binary_output_31_loss: 0.3813 - binary_output_32_loss: 0.2165 - binary_output_33_loss: 0.4054 - binary_output_34_loss: 0.6203 - categorical_output_loss: 0.4319 - binary_output_0_binary_accuracy: 0.6886 - binary_output_1_binary_accuracy: 0.9932 - binary_output_2_binary_accuracy: 0.6394 - binary_output_3_binary_accuracy: 0.6675 - binary_output_4_binary_accuracy: 0.8252 - binary_output_5_binary_accuracy: 0.8724 - binary_output_6_binary_accuracy: 0.9348 - binary_output_7_binary_accuracy: 0.9143 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8083 - binary_output_10_binary_accuracy: 0.7780 - binary_output_11_binary_accuracy: 0.7916 - binary_output_12_binary_accuracy: 0.9501 - binary_output_13_binary_accuracy: 0.9106 - binary_output_14_binary_accuracy: 0.9676 - binary_output_15_binary_accuracy: 0.8500 - binary_output_16_binary_accuracy: 0.8131 - binary_output_17_binary_accuracy: 0.5132 - binary_output_18_binary_accuracy: 0.7770 - binary_output_19_binary_accuracy: 0.7962 - binary_output_20_binary_accuracy: 0.8187 - binary_output_21_binary_accuracy: 0.9081 - binary_output_22_binary_accuracy: 0.9863 - binary_output_23_binary_accuracy: 0.9604 - binary_output_24_binary_accuracy: 0.9918 - binary_output_25_binary_accuracy: 0.9524 - binary_output_26_binary_accuracy: 0.8143 - binary_output_27_binary_accuracy: 0.7197 - binary_output_28_binary_accuracy: 0.7968 - binary_output_29_binary_accuracy: 0.7816 - binary_output_30_binary_accuracy: 0.9715 - binary_output_31_binary_accuracy: 0.7953 - binary_output_32_binary_accuracy: 0.9011 - binary_output_33_binary_accuracy: 0.7432 - binary_output_34_binary_accuracy: 0.6045 - categorical_output_sparse_categorical_accuracy: 0.7760\n",
      "Epoch 18/40\n",
      "22237/22237 [==============================] - 7s 329us/step - loss: 11.2568 - binary_output_0_loss: 0.5161 - binary_output_1_loss: 0.0917 - binary_output_2_loss: 0.6049 - binary_output_3_loss: 0.5048 - binary_output_4_loss: 0.3284 - binary_output_5_loss: 0.2886 - binary_output_6_loss: 0.2475 - binary_output_7_loss: 0.2091 - binary_output_8_loss: 9.0709e-04 - binary_output_9_loss: 0.3347 - binary_output_10_loss: 0.3856 - binary_output_11_loss: 0.3665 - binary_output_12_loss: 0.1399 - binary_output_13_loss: 0.2621 - binary_output_14_loss: 0.1758 - binary_output_15_loss: 0.2877 - binary_output_16_loss: 0.3436 - binary_output_17_loss: 0.6861 - binary_output_18_loss: 0.3757 - binary_output_19_loss: 0.3572 - binary_output_20_loss: 0.3020 - binary_output_21_loss: 0.2242 - binary_output_22_loss: 0.1106 - binary_output_23_loss: 0.1450 - binary_output_24_loss: 0.0881 - binary_output_25_loss: 0.1528 - binary_output_26_loss: 0.3187 - binary_output_27_loss: 0.4858 - binary_output_28_loss: 0.3645 - binary_output_29_loss: 0.3684 - binary_output_30_loss: 0.1562 - binary_output_31_loss: 0.3721 - binary_output_32_loss: 0.2167 - binary_output_33_loss: 0.3962 - binary_output_34_loss: 0.6140 - categorical_output_loss: 0.4222 - binary_output_0_binary_accuracy: 0.6983 - binary_output_1_binary_accuracy: 0.9937 - binary_output_2_binary_accuracy: 0.6554 - binary_output_3_binary_accuracy: 0.6686 - binary_output_4_binary_accuracy: 0.8264 - binary_output_5_binary_accuracy: 0.8717 - binary_output_6_binary_accuracy: 0.9344 - binary_output_7_binary_accuracy: 0.9155 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8064 - binary_output_10_binary_accuracy: 0.7822 - binary_output_11_binary_accuracy: 0.7968 - binary_output_12_binary_accuracy: 0.9554 - binary_output_13_binary_accuracy: 0.9087 - binary_output_14_binary_accuracy: 0.9664 - binary_output_15_binary_accuracy: 0.8497 - binary_output_16_binary_accuracy: 0.8190 - binary_output_17_binary_accuracy: 0.5155 - binary_output_18_binary_accuracy: 0.7773 - binary_output_19_binary_accuracy: 0.8006 - binary_output_20_binary_accuracy: 0.8286 - binary_output_21_binary_accuracy: 0.9066 - binary_output_22_binary_accuracy: 0.9857 - binary_output_23_binary_accuracy: 0.9621 - binary_output_24_binary_accuracy: 0.9915 - binary_output_25_binary_accuracy: 0.9579 - binary_output_26_binary_accuracy: 0.8161 - binary_output_27_binary_accuracy: 0.7276 - binary_output_28_binary_accuracy: 0.8012 - binary_output_29_binary_accuracy: 0.7921 - binary_output_30_binary_accuracy: 0.9684 - binary_output_31_binary_accuracy: 0.7955 - binary_output_32_binary_accuracy: 0.9043 - binary_output_33_binary_accuracy: 0.7525 - binary_output_34_binary_accuracy: 0.6092 - categorical_output_sparse_categorical_accuracy: 0.7786\n",
      "Epoch 19/40\n",
      " 1024/22237 [>.............................] - ETA: 6s - loss: 10.9719 - binary_output_0_loss: 0.5676 - binary_output_1_loss: 0.1259 - binary_output_2_loss: 0.6100 - binary_output_3_loss: 0.5229 - binary_output_4_loss: 0.3183 - binary_output_5_loss: 0.3150 - binary_output_6_loss: 0.2560 - binary_output_7_loss: 0.2402 - binary_output_8_loss: 8.3525e-04 - binary_output_9_loss: 0.3482 - binary_output_10_loss: 0.3782 - binary_output_11_loss: 0.3658 - binary_output_12_loss: 0.1695 - binary_output_13_loss: 0.1985 - binary_output_14_loss: 0.1822 - binary_output_15_loss: 0.3030 - binary_output_16_loss: 0.2871 - binary_output_17_loss: 0.6882 - binary_output_18_loss: 0.3636 - binary_output_19_loss: 0.3232 - binary_output_20_loss: 0.2940 - binary_output_21_loss: 0.1935 - binary_output_22_loss: 0.1127 - binary_output_23_loss: 0.1498 - binary_output_24_loss: 0.0834 - binary_output_25_loss: 0.1524 - binary_output_26_loss: 0.2905 - binary_output_27_loss: 0.4447 - binary_output_28_loss: 0.3544 - binary_output_29_loss: 0.3125 - binary_output_30_loss: 0.1055 - binary_output_31_loss: 0.3369 - binary_output_32_loss: 0.2272 - binary_output_33_loss: 0.3827 - binary_output_34_loss: 0.5963 - categorical_output_loss: 0.3712 - binary_output_0_binary_accuracy: 0.6631 - binary_output_1_binary_accuracy: 0.9902 - binary_output_2_binary_accuracy: 0.6445 - binary_output_3_binary_accuracy: 0.6719 - binary_output_4_binary_accuracy: 0.8213 - binary_output_5_binary_accuracy: 0.8604 - binary_output_6_binary_accuracy: 0.9209 - binary_output_7_binary_accuracy: 0.9141 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7920 - binary_output_10_binary_accuracy: 0.7764 - binary_output_11_binary_accuracy: 0.7842 - binary_output_12_binary_accuracy: 0.9492 - binary_output_13_binary_accuracy: 0.9141 - binary_output_14_binary_accuracy: 0.9678 - binary_output_15_binary_accuracy: 0.8535 - binary_output_16_binary_accuracy: 0.8311 - binary_output_17_binary_accuracy: 0.5049 - binary_output_18_binary_accuracy: 0.7998 - binary_output_19_binary_accuracy: 0.8203 - binary_output_20_binary_accuracy: 0.8252 - binary_output_21_binary_accuracy: 0.9141 - binary_output_22_binary_accuracy: 0.9834 - binary_output_23_binary_accuracy: 0.9590 - binary_output_24_binary_accuracy: 0.9912 - binary_output_25_binary_accuracy: 0.9453 - binary_output_26_binary_accuracy: 0.8252 - binary_output_27_binary_accuracy: 0.7686 - binary_output_28_binary_accuracy: 0.8311 - binary_output_29_binary_accuracy: 0.8193 - binary_output_30_binary_accuracy: 0.9727 - binary_output_31_binary_accuracy: 0.8379 - binary_output_32_binary_accuracy: 0.8994 - binary_output_33_binary_accuracy: 0.7646 - binary_output_34_binary_accuracy: 0.5859 - categorical_output_sparse_categorical_accuracy: 0.760722237/22237 [==============================] - 6s 276us/step - loss: 11.0373 - binary_output_0_loss: 0.5123 - binary_output_1_loss: 0.0887 - binary_output_2_loss: 0.5961 - binary_output_3_loss: 0.4952 - binary_output_4_loss: 0.3232 - binary_output_5_loss: 0.2829 - binary_output_6_loss: 0.2392 - binary_output_7_loss: 0.2128 - binary_output_8_loss: 7.9219e-04 - binary_output_9_loss: 0.3296 - binary_output_10_loss: 0.3793 - binary_output_11_loss: 0.3573 - binary_output_12_loss: 0.1370 - binary_output_13_loss: 0.2528 - binary_output_14_loss: 0.1696 - binary_output_15_loss: 0.2866 - binary_output_16_loss: 0.3469 - binary_output_17_loss: 0.6798 - binary_output_18_loss: 0.3686 - binary_output_19_loss: 0.3493 - binary_output_20_loss: 0.2997 - binary_output_21_loss: 0.2205 - binary_output_22_loss: 0.1096 - binary_output_23_loss: 0.1388 - binary_output_24_loss: 0.0885 - binary_output_25_loss: 0.1482 - binary_output_26_loss: 0.3111 - binary_output_27_loss: 0.4664 - binary_output_28_loss: 0.3579 - binary_output_29_loss: 0.3540 - binary_output_30_loss: 0.1491 - binary_output_31_loss: 0.3604 - binary_output_32_loss: 0.2111 - binary_output_33_loss: 0.3872 - binary_output_34_loss: 0.6089 - categorical_output_loss: 0.4169 - binary_output_0_binary_accuracy: 0.6971 - binary_output_1_binary_accuracy: 0.9933 - binary_output_2_binary_accuracy: 0.6605 - binary_output_3_binary_accuracy: 0.6831 - binary_output_4_binary_accuracy: 0.8280 - binary_output_5_binary_accuracy: 0.8708 - binary_output_6_binary_accuracy: 0.9284 - binary_output_7_binary_accuracy: 0.9160 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8115 - binary_output_10_binary_accuracy: 0.7860 - binary_output_11_binary_accuracy: 0.8016 - binary_output_12_binary_accuracy: 0.9540 - binary_output_13_binary_accuracy: 0.9137 - binary_output_14_binary_accuracy: 0.9661 - binary_output_15_binary_accuracy: 0.8519 - binary_output_16_binary_accuracy: 0.8187 - binary_output_17_binary_accuracy: 0.5242 - binary_output_18_binary_accuracy: 0.7851 - binary_output_19_binary_accuracy: 0.8048 - binary_output_20_binary_accuracy: 0.8252 - binary_output_21_binary_accuracy: 0.9101 - binary_output_22_binary_accuracy: 0.9856 - binary_output_23_binary_accuracy: 0.9605 - binary_output_24_binary_accuracy: 0.9913 - binary_output_25_binary_accuracy: 0.9547 - binary_output_26_binary_accuracy: 0.8164 - binary_output_27_binary_accuracy: 0.7432 - binary_output_28_binary_accuracy: 0.8065 - binary_output_29_binary_accuracy: 0.8024 - binary_output_30_binary_accuracy: 0.9673 - binary_output_31_binary_accuracy: 0.8144 - binary_output_32_binary_accuracy: 0.9046 - binary_output_33_binary_accuracy: 0.7513 - binary_output_34_binary_accuracy: 0.6175 - categorical_output_sparse_categorical_accuracy: 0.7799\n",
      "Epoch 20/40\n",
      "22237/22237 [==============================] - 6s 280us/step - loss: 10.8784 - binary_output_0_loss: 0.5017 - binary_output_1_loss: 0.0925 - binary_output_2_loss: 0.5775 - binary_output_3_loss: 0.4845 - binary_output_4_loss: 0.3205 - binary_output_5_loss: 0.2794 - binary_output_6_loss: 0.2414 - binary_output_7_loss: 0.2021 - binary_output_8_loss: 7.5034e-04 - binary_output_9_loss: 0.3184 - binary_output_10_loss: 0.3727 - binary_output_11_loss: 0.3530 - binary_output_12_loss: 0.1355 - binary_output_13_loss: 0.2479 - binary_output_14_loss: 0.1713 - binary_output_15_loss: 0.2777 - binary_output_16_loss: 0.3286 - binary_output_17_loss: 0.6730 - binary_output_18_loss: 0.3620 - binary_output_19_loss: 0.3514 - binary_output_20_loss: 0.2971 - binary_output_21_loss: 0.2207 - binary_output_22_loss: 0.1087 - binary_output_23_loss: 0.1409 - binary_output_24_loss: 0.0862 - binary_output_25_loss: 0.1471 - binary_output_26_loss: 0.3056 - binary_output_27_loss: 0.4663 - binary_output_28_loss: 0.3601 - binary_output_29_loss: 0.3573 - binary_output_30_loss: 0.1503 - binary_output_31_loss: 0.3510 - binary_output_32_loss: 0.2102 - binary_output_33_loss: 0.3822 - binary_output_34_loss: 0.6022 - categorical_output_loss: 0.4108 - binary_output_0_binary_accuracy: 0.7032 - binary_output_1_binary_accuracy: 0.9921 - binary_output_2_binary_accuracy: 0.6737 - binary_output_3_binary_accuracy: 0.6915 - binary_output_4_binary_accuracy: 0.8323 - binary_output_5_binary_accuracy: 0.8713 - binary_output_6_binary_accuracy: 0.9320 - binary_output_7_binary_accuracy: 0.9182 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8148 - binary_output_10_binary_accuracy: 0.7903 - binary_output_11_binary_accuracy: 0.8060 - binary_output_12_binary_accuracy: 0.9584 - binary_output_13_binary_accuracy: 0.9121 - binary_output_14_binary_accuracy: 0.9656 - binary_output_15_binary_accuracy: 0.8561 - binary_output_16_binary_accuracy: 0.8268 - binary_output_17_binary_accuracy: 0.5285 - binary_output_18_binary_accuracy: 0.7861 - binary_output_19_binary_accuracy: 0.8001 - binary_output_20_binary_accuracy: 0.8300 - binary_output_21_binary_accuracy: 0.9121 - binary_output_22_binary_accuracy: 0.9843 - binary_output_23_binary_accuracy: 0.9587 - binary_output_24_binary_accuracy: 0.9909 - binary_output_25_binary_accuracy: 0.9501 - binary_output_26_binary_accuracy: 0.8194 - binary_output_27_binary_accuracy: 0.7431 - binary_output_28_binary_accuracy: 0.8051 - binary_output_29_binary_accuracy: 0.8084 - binary_output_30_binary_accuracy: 0.9656 - binary_output_31_binary_accuracy: 0.8129 - binary_output_32_binary_accuracy: 0.9042 - binary_output_33_binary_accuracy: 0.7588 - binary_output_34_binary_accuracy: 0.6233 - categorical_output_sparse_categorical_accuracy: 0.7824\n",
      "Epoch 21/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  512/22237 [..............................] - ETA: 5s - loss: 10.5306 - binary_output_0_loss: 0.4700 - binary_output_1_loss: 0.0613 - binary_output_2_loss: 0.5592 - binary_output_3_loss: 0.4685 - binary_output_4_loss: 0.3283 - binary_output_5_loss: 0.3244 - binary_output_6_loss: 0.2566 - binary_output_7_loss: 0.1296 - binary_output_8_loss: 0.0011 - binary_output_9_loss: 0.2975 - binary_output_10_loss: 0.3502 - binary_output_11_loss: 0.4697 - binary_output_12_loss: 0.1548 - binary_output_13_loss: 0.2121 - binary_output_14_loss: 0.1551 - binary_output_15_loss: 0.3211 - binary_output_16_loss: 0.3060 - binary_output_17_loss: 0.6300 - binary_output_18_loss: 0.3041 - binary_output_19_loss: 0.2852 - binary_output_20_loss: 0.2995 - binary_output_21_loss: 0.2292 - binary_output_22_loss: 0.1179 - binary_output_23_loss: 0.1705 - binary_output_24_loss: 0.0480 - binary_output_25_loss: 0.1149 - binary_output_26_loss: 0.2655 - binary_output_27_loss: 0.4516 - binary_output_28_loss: 0.2774 - binary_output_29_loss: 0.3385 - binary_output_30_loss: 0.2022 - binary_output_31_loss: 0.3642 - binary_output_32_loss: 0.2007 - binary_output_33_loss: 0.3237 - binary_output_34_loss: 0.6281 - categorical_output_loss: 0.4138 - binary_output_0_binary_accuracy: 0.6230 - binary_output_1_binary_accuracy: 0.9941 - binary_output_2_binary_accuracy: 0.6328 - binary_output_3_binary_accuracy: 0.6523 - binary_output_4_binary_accuracy: 0.7676 - binary_output_5_binary_accuracy: 0.8574 - binary_output_6_binary_accuracy: 0.9199 - binary_output_7_binary_accuracy: 0.9102 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7793 - binary_output_10_binary_accuracy: 0.7754 - binary_output_11_binary_accuracy: 0.7812 - binary_output_12_binary_accuracy: 0.9258 - binary_output_13_binary_accuracy: 0.9023 - binary_output_14_binary_accuracy: 0.9648 - binary_output_15_binary_accuracy: 0.8223 - binary_output_16_binary_accuracy: 0.8145 - binary_output_17_binary_accuracy: 0.5059 - binary_output_18_binary_accuracy: 0.7695 - binary_output_19_binary_accuracy: 0.7793 - binary_output_20_binary_accuracy: 0.8242 - binary_output_21_binary_accuracy: 0.8906 - binary_output_22_binary_accuracy: 0.9883 - binary_output_23_binary_accuracy: 0.9492 - binary_output_24_binary_accuracy: 0.9941 - binary_output_25_binary_accuracy: 0.9434 - binary_output_26_binary_accuracy: 0.7969 - binary_output_27_binary_accuracy: 0.7969 - binary_output_28_binary_accuracy: 0.8105 - binary_output_29_binary_accuracy: 0.8301 - binary_output_30_binary_accuracy: 0.9609 - binary_output_31_binary_accuracy: 0.8613 - binary_output_32_binary_accuracy: 0.8984 - binary_output_33_binary_accuracy: 0.7754 - binary_output_34_binary_accuracy: 0.5078 - categorical_output_sparse_categorical_accuracy: 0.7715\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 1024/22237 [>.............................] - ETA: 5s - loss: 10.7872 - binary_output_0_loss: 0.5041 - binary_output_1_loss: 0.1201 - binary_output_2_loss: 0.5883 - binary_output_3_loss: 0.5028 - binary_output_4_loss: 0.3005 - binary_output_5_loss: 0.3471 - binary_output_6_loss: 0.2413 - binary_output_7_loss: 0.1687 - binary_output_8_loss: 9.8072e-04 - binary_output_9_loss: 0.2933 - binary_output_10_loss: 0.3850 - binary_output_11_loss: 0.4354 - binary_output_12_loss: 0.1878 - binary_output_13_loss: 0.2217 - binary_output_14_loss: 0.1553 - binary_output_15_loss: 0.2984 - binary_output_16_loss: 0.3213 - binary_output_17_loss: 0.6748 - binary_output_18_loss: 0.3064 - binary_output_19_loss: 0.3064 - binary_output_20_loss: 0.3003 - binary_output_21_loss: 0.2235 - binary_output_22_loss: 0.1072 - binary_output_23_loss: 0.1453 - binary_output_24_loss: 0.0834 - binary_output_25_loss: 0.1039 - binary_output_26_loss: 0.2639 - binary_output_27_loss: 0.4458 - binary_output_28_loss: 0.3071 - binary_output_29_loss: 0.3734 - binary_output_30_loss: 0.2077 - binary_output_31_loss: 0.3394 - binary_output_32_loss: 0.2053 - binary_output_33_loss: 0.3451 - binary_output_34_loss: 0.6262 - categorical_output_loss: 0.3500 - binary_output_0_binary_accuracy: 0.6426 - binary_output_1_binary_accuracy: 0.9912 - binary_output_2_binary_accuracy: 0.6865 - binary_output_3_binary_accuracy: 0.6807 - binary_output_4_binary_accuracy: 0.8047 - binary_output_5_binary_accuracy: 0.8604 - binary_output_6_binary_accuracy: 0.9287 - binary_output_7_binary_accuracy: 0.9238 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8096 - binary_output_10_binary_accuracy: 0.7930 - binary_output_11_binary_accuracy: 0.7754 - binary_output_12_binary_accuracy: 0.9385 - binary_output_13_binary_accuracy: 0.9121 - binary_output_14_binary_accuracy: 0.9648 - binary_output_15_binary_accuracy: 0.8467 - binary_output_16_binary_accuracy: 0.8252 - binary_output_17_binary_accuracy: 0.5293 - binary_output_18_binary_accuracy: 0.7744 - binary_output_19_binary_accuracy: 0.7949 - binary_output_20_binary_accuracy: 0.8154 - binary_output_21_binary_accuracy: 0.8994 - binary_output_22_binary_accuracy: 0.9844 - binary_output_23_binary_accuracy: 0.9609 - binary_output_24_binary_accuracy: 0.9902 - binary_output_25_binary_accuracy: 0.9531 - binary_output_26_binary_accuracy: 0.8027 - binary_output_27_binary_accuracy: 0.7725 - binary_output_28_binary_accuracy: 0.8193 - binary_output_29_binary_accuracy: 0.8096 - binary_output_30_binary_accuracy: 0.9658 - binary_output_31_binary_accuracy: 0.8291 - binary_output_32_binary_accuracy: 0.8965 - binary_output_33_binary_accuracy: 0.7676 - binary_output_34_binary_accuracy: 0.5576 - categorical_output_sparse_categorical_accuracy: 0.7891"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22237/22237 [==============================] - 6s 266us/step - loss: 10.6986 - binary_output_0_loss: 0.5012 - binary_output_1_loss: 0.0870 - binary_output_2_loss: 0.5688 - binary_output_3_loss: 0.4863 - binary_output_4_loss: 0.3080 - binary_output_5_loss: 0.2776 - binary_output_6_loss: 0.2353 - binary_output_7_loss: 0.1974 - binary_output_8_loss: 7.7631e-04 - binary_output_9_loss: 0.3054 - binary_output_10_loss: 0.3658 - binary_output_11_loss: 0.3509 - binary_output_12_loss: 0.1332 - binary_output_13_loss: 0.2447 - binary_output_14_loss: 0.1688 - binary_output_15_loss: 0.2771 - binary_output_16_loss: 0.3245 - binary_output_17_loss: 0.6670 - binary_output_18_loss: 0.3528 - binary_output_19_loss: 0.3417 - binary_output_20_loss: 0.2950 - binary_output_21_loss: 0.2123 - binary_output_22_loss: 0.1091 - binary_output_23_loss: 0.1421 - binary_output_24_loss: 0.0857 - binary_output_25_loss: 0.1464 - binary_output_26_loss: 0.2961 - binary_output_27_loss: 0.4483 - binary_output_28_loss: 0.3468 - binary_output_29_loss: 0.3395 - binary_output_30_loss: 0.1488 - binary_output_31_loss: 0.3479 - binary_output_32_loss: 0.2077 - binary_output_33_loss: 0.3790 - binary_output_34_loss: 0.5966 - categorical_output_loss: 0.4044 - binary_output_0_binary_accuracy: 0.7084 - binary_output_1_binary_accuracy: 0.9918 - binary_output_2_binary_accuracy: 0.6857 - binary_output_3_binary_accuracy: 0.6890 - binary_output_4_binary_accuracy: 0.8365 - binary_output_5_binary_accuracy: 0.8701 - binary_output_6_binary_accuracy: 0.9280 - binary_output_7_binary_accuracy: 0.9190 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8220 - binary_output_10_binary_accuracy: 0.7930 - binary_output_11_binary_accuracy: 0.8002 - binary_output_12_binary_accuracy: 0.9570 - binary_output_13_binary_accuracy: 0.9110 - binary_output_14_binary_accuracy: 0.9632 - binary_output_15_binary_accuracy: 0.8548 - binary_output_16_binary_accuracy: 0.8301 - binary_output_17_binary_accuracy: 0.5422 - binary_output_18_binary_accuracy: 0.7927 - binary_output_19_binary_accuracy: 0.8062 - binary_output_20_binary_accuracy: 0.8337 - binary_output_21_binary_accuracy: 0.9103 - binary_output_22_binary_accuracy: 0.9832 - binary_output_23_binary_accuracy: 0.9589 - binary_output_24_binary_accuracy: 0.9910 - binary_output_25_binary_accuracy: 0.9519 - binary_output_26_binary_accuracy: 0.8211 - binary_output_27_binary_accuracy: 0.7552 - binary_output_28_binary_accuracy: 0.8103 - binary_output_29_binary_accuracy: 0.8153 - binary_output_30_binary_accuracy: 0.9647 - binary_output_31_binary_accuracy: 0.8188 - binary_output_32_binary_accuracy: 0.9014 - binary_output_33_binary_accuracy: 0.7624 - binary_output_34_binary_accuracy: 0.6260 - categorical_output_sparse_categorical_accuracy: 0.7827\n",
      "Epoch 22/40\n",
      "22237/22237 [==============================] - 7s 313us/step - loss: 10.4827 - binary_output_0_loss: 0.4876 - binary_output_1_loss: 0.0868 - binary_output_2_loss: 0.5546 - binary_output_3_loss: 0.4724 - binary_output_4_loss: 0.3027 - binary_output_5_loss: 0.2745 - binary_output_6_loss: 0.2298 - binary_output_7_loss: 0.1860 - binary_output_8_loss: 6.7163e-04 - binary_output_9_loss: 0.2949 - binary_output_10_loss: 0.3622 - binary_output_11_loss: 0.3481 - binary_output_12_loss: 0.1277 - binary_output_13_loss: 0.2370 - binary_output_14_loss: 0.1638 - binary_output_15_loss: 0.2744 - binary_output_16_loss: 0.3229 - binary_output_17_loss: 0.6582 - binary_output_18_loss: 0.3486 - binary_output_19_loss: 0.3371 - binary_output_20_loss: 0.2977 - binary_output_21_loss: 0.2121 - binary_output_22_loss: 0.1025 - binary_output_23_loss: 0.1324 - binary_output_24_loss: 0.0812 - binary_output_25_loss: 0.1471 - binary_output_26_loss: 0.2953 - binary_output_27_loss: 0.4380 - binary_output_28_loss: 0.3356 - binary_output_29_loss: 0.3375 - binary_output_30_loss: 0.1416 - binary_output_31_loss: 0.3323 - binary_output_32_loss: 0.2027 - binary_output_33_loss: 0.3774 - binary_output_34_loss: 0.5847 - categorical_output_loss: 0.3988 - binary_output_0_binary_accuracy: 0.7130 - binary_output_1_binary_accuracy: 0.9918 - binary_output_2_binary_accuracy: 0.6962 - binary_output_3_binary_accuracy: 0.6945 - binary_output_4_binary_accuracy: 0.8380 - binary_output_5_binary_accuracy: 0.8776 - binary_output_6_binary_accuracy: 0.9267 - binary_output_7_binary_accuracy: 0.9186 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8314 - binary_output_10_binary_accuracy: 0.7990 - binary_output_11_binary_accuracy: 0.8051 - binary_output_12_binary_accuracy: 0.9568 - binary_output_13_binary_accuracy: 0.9160 - binary_output_14_binary_accuracy: 0.9639 - binary_output_15_binary_accuracy: 0.8575 - binary_output_16_binary_accuracy: 0.8326 - binary_output_17_binary_accuracy: 0.5405 - binary_output_18_binary_accuracy: 0.7965 - binary_output_19_binary_accuracy: 0.8045 - binary_output_20_binary_accuracy: 0.8318 - binary_output_21_binary_accuracy: 0.9086 - binary_output_22_binary_accuracy: 0.9825 - binary_output_23_binary_accuracy: 0.9592 - binary_output_24_binary_accuracy: 0.9909 - binary_output_25_binary_accuracy: 0.9521 - binary_output_26_binary_accuracy: 0.8265 - binary_output_27_binary_accuracy: 0.7597 - binary_output_28_binary_accuracy: 0.8153 - binary_output_29_binary_accuracy: 0.8209 - binary_output_30_binary_accuracy: 0.9671 - binary_output_31_binary_accuracy: 0.8203 - binary_output_32_binary_accuracy: 0.9053 - binary_output_33_binary_accuracy: 0.7616 - binary_output_34_binary_accuracy: 0.6404 - categorical_output_sparse_categorical_accuracy: 0.7862\n",
      "Epoch 23/40\n",
      " 1024/22237 [>.............................] - ETA: 5s - loss: 9.9411 - binary_output_0_loss: 0.4991 - binary_output_1_loss: 0.0644 - binary_output_2_loss: 0.5123 - binary_output_3_loss: 0.4936 - binary_output_4_loss: 0.2631 - binary_output_5_loss: 0.2493 - binary_output_6_loss: 0.2083 - binary_output_7_loss: 0.2201 - binary_output_8_loss: 7.5846e-04 - binary_output_9_loss: 0.2712 - binary_output_10_loss: 0.3388 - binary_output_11_loss: 0.3410 - binary_output_12_loss: 0.1408 - binary_output_13_loss: 0.2643 - binary_output_14_loss: 0.1551 - binary_output_15_loss: 0.2823 - binary_output_16_loss: 0.3919 - binary_output_17_loss: 0.6498 - binary_output_18_loss: 0.3002 - binary_output_19_loss: 0.3420 - binary_output_20_loss: 0.2709 - binary_output_21_loss: 0.1788 - binary_output_22_loss: 0.0993 - binary_output_23_loss: 0.1585 - binary_output_24_loss: 0.0643 - binary_output_25_loss: 0.1369 - binary_output_26_loss: 0.2453 - binary_output_27_loss: 0.4181 - binary_output_28_loss: 0.2983 - binary_output_29_loss: 0.2760 - binary_output_30_loss: 0.1122 - binary_output_31_loss: 0.2900 - binary_output_32_loss: 0.1256 - binary_output_33_loss: 0.3512 - binary_output_34_loss: 0.5565 - categorical_output_loss: 0.3707 - binary_output_0_binary_accuracy: 0.6943 - binary_output_1_binary_accuracy: 0.9922 - binary_output_2_binary_accuracy: 0.7227 - binary_output_3_binary_accuracy: 0.6719 - binary_output_4_binary_accuracy: 0.8369 - binary_output_5_binary_accuracy: 0.8730 - binary_output_6_binary_accuracy: 0.9180 - binary_output_7_binary_accuracy: 0.9121 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8369 - binary_output_10_binary_accuracy: 0.7998 - binary_output_11_binary_accuracy: 0.8125 - binary_output_12_binary_accuracy: 0.9609 - binary_output_13_binary_accuracy: 0.9111 - binary_output_14_binary_accuracy: 0.9619 - binary_output_15_binary_accuracy: 0.8555 - binary_output_16_binary_accuracy: 0.8252 - binary_output_17_binary_accuracy: 0.5215 - binary_output_18_binary_accuracy: 0.8066 - binary_output_19_binary_accuracy: 0.8281 - binary_output_20_binary_accuracy: 0.8379 - binary_output_21_binary_accuracy: 0.9072 - binary_output_22_binary_accuracy: 0.9795 - binary_output_23_binary_accuracy: 0.9482 - binary_output_24_binary_accuracy: 0.9902 - binary_output_25_binary_accuracy: 0.9521 - binary_output_26_binary_accuracy: 0.8486 - binary_output_27_binary_accuracy: 0.7842 - binary_output_28_binary_accuracy: 0.8213 - binary_output_29_binary_accuracy: 0.8291 - binary_output_30_binary_accuracy: 0.9609 - binary_output_31_binary_accuracy: 0.8428 - binary_output_32_binary_accuracy: 0.9131 - binary_output_33_binary_accuracy: 0.7842 - binary_output_34_binary_accuracy: 0.6533 - categorical_output_sparse_categorical_accuracy: 0.787122237/22237 [==============================] - 6s 268us/step - loss: 10.3084 - binary_output_0_loss: 0.4801 - binary_output_1_loss: 0.0830 - binary_output_2_loss: 0.5418 - binary_output_3_loss: 0.4713 - binary_output_4_loss: 0.3034 - binary_output_5_loss: 0.2642 - binary_output_6_loss: 0.2258 - binary_output_7_loss: 0.1849 - binary_output_8_loss: 7.6923e-04 - binary_output_9_loss: 0.2836 - binary_output_10_loss: 0.3524 - binary_output_11_loss: 0.3377 - binary_output_12_loss: 0.1259 - binary_output_13_loss: 0.2303 - binary_output_14_loss: 0.1575 - binary_output_15_loss: 0.2703 - binary_output_16_loss: 0.3174 - binary_output_17_loss: 0.6529 - binary_output_18_loss: 0.3438 - binary_output_19_loss: 0.3299 - binary_output_20_loss: 0.2895 - binary_output_21_loss: 0.2060 - binary_output_22_loss: 0.1018 - binary_output_23_loss: 0.1342 - binary_output_24_loss: 0.0816 - binary_output_25_loss: 0.1455 - binary_output_26_loss: 0.2907 - binary_output_27_loss: 0.4307 - binary_output_28_loss: 0.3327 - binary_output_29_loss: 0.3305 - binary_output_30_loss: 0.1401 - binary_output_31_loss: 0.3293 - binary_output_32_loss: 0.1963 - binary_output_33_loss: 0.3680 - binary_output_34_loss: 0.5803 - categorical_output_loss: 0.3902 - binary_output_0_binary_accuracy: 0.7183 - binary_output_1_binary_accuracy: 0.9918 - binary_output_2_binary_accuracy: 0.7009 - binary_output_3_binary_accuracy: 0.7036 - binary_output_4_binary_accuracy: 0.8422 - binary_output_5_binary_accuracy: 0.8743 - binary_output_6_binary_accuracy: 0.9264 - binary_output_7_binary_accuracy: 0.9215 - binary_output_8_binary_accuracy: 0.9999 - binary_output_9_binary_accuracy: 0.8391 - binary_output_10_binary_accuracy: 0.8025 - binary_output_11_binary_accuracy: 0.8122 - binary_output_12_binary_accuracy: 0.9597 - binary_output_13_binary_accuracy: 0.9186 - binary_output_14_binary_accuracy: 0.9613 - binary_output_15_binary_accuracy: 0.8581 - binary_output_16_binary_accuracy: 0.8365 - binary_output_17_binary_accuracy: 0.5504 - binary_output_18_binary_accuracy: 0.7984 - binary_output_19_binary_accuracy: 0.8101 - binary_output_20_binary_accuracy: 0.8310 - binary_output_21_binary_accuracy: 0.9135 - binary_output_22_binary_accuracy: 0.9804 - binary_output_23_binary_accuracy: 0.9578 - binary_output_24_binary_accuracy: 0.9909 - binary_output_25_binary_accuracy: 0.9536 - binary_output_26_binary_accuracy: 0.8261 - binary_output_27_binary_accuracy: 0.7665 - binary_output_28_binary_accuracy: 0.8171 - binary_output_29_binary_accuracy: 0.8225 - binary_output_30_binary_accuracy: 0.9644 - binary_output_31_binary_accuracy: 0.8279 - binary_output_32_binary_accuracy: 0.9029 - binary_output_33_binary_accuracy: 0.7647 - binary_output_34_binary_accuracy: 0.6394 - categorical_output_sparse_categorical_accuracy: 0.7829\n",
      "Epoch 24/40\n",
      "22237/22237 [==============================] - 6s 258us/step - loss: 10.1331 - binary_output_0_loss: 0.4669 - binary_output_1_loss: 0.0841 - binary_output_2_loss: 0.5278 - binary_output_3_loss: 0.4594 - binary_output_4_loss: 0.2994 - binary_output_5_loss: 0.2633 - binary_output_6_loss: 0.2234 - binary_output_7_loss: 0.1823 - binary_output_8_loss: 6.9824e-04 - binary_output_9_loss: 0.2720 - binary_output_10_loss: 0.3428 - binary_output_11_loss: 0.3356 - binary_output_12_loss: 0.1240 - binary_output_13_loss: 0.2305 - binary_output_14_loss: 0.1585 - binary_output_15_loss: 0.2704 - binary_output_16_loss: 0.3116 - binary_output_17_loss: 0.6441 - binary_output_18_loss: 0.3368 - binary_output_19_loss: 0.3294 - binary_output_20_loss: 0.2816 - binary_output_21_loss: 0.2068 - binary_output_22_loss: 0.1004 - binary_output_23_loss: 0.1265 - binary_output_24_loss: 0.0803 - binary_output_25_loss: 0.1391 - binary_output_26_loss: 0.2896 - binary_output_27_loss: 0.4189 - binary_output_28_loss: 0.3306 - binary_output_29_loss: 0.3261 - binary_output_30_loss: 0.1358 - binary_output_31_loss: 0.3145 - binary_output_32_loss: 0.1996 - binary_output_33_loss: 0.3660 - binary_output_34_loss: 0.5725 - categorical_output_loss: 0.3891 - binary_output_0_binary_accuracy: 0.7249 - binary_output_1_binary_accuracy: 0.9902 - binary_output_2_binary_accuracy: 0.7131 - binary_output_3_binary_accuracy: 0.7079 - binary_output_4_binary_accuracy: 0.8461 - binary_output_5_binary_accuracy: 0.8739 - binary_output_6_binary_accuracy: 0.9273 - binary_output_7_binary_accuracy: 0.9225 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8479 - binary_output_10_binary_accuracy: 0.8100 - binary_output_11_binary_accuracy: 0.8117 - binary_output_12_binary_accuracy: 0.9614 - binary_output_13_binary_accuracy: 0.9169 - binary_output_14_binary_accuracy: 0.9641 - binary_output_15_binary_accuracy: 0.8594 - binary_output_16_binary_accuracy: 0.8388 - binary_output_17_binary_accuracy: 0.5572 - binary_output_18_binary_accuracy: 0.8068 - binary_output_19_binary_accuracy: 0.8096 - binary_output_20_binary_accuracy: 0.8394 - binary_output_21_binary_accuracy: 0.9093 - binary_output_22_binary_accuracy: 0.9800 - binary_output_23_binary_accuracy: 0.9588 - binary_output_24_binary_accuracy: 0.9883 - binary_output_25_binary_accuracy: 0.9508 - binary_output_26_binary_accuracy: 0.8316 - binary_output_27_binary_accuracy: 0.7725 - binary_output_28_binary_accuracy: 0.8227 - binary_output_29_binary_accuracy: 0.8289 - binary_output_30_binary_accuracy: 0.9648 - binary_output_31_binary_accuracy: 0.8358 - binary_output_32_binary_accuracy: 0.9054 - binary_output_33_binary_accuracy: 0.7736 - binary_output_34_binary_accuracy: 0.6456 - categorical_output_sparse_categorical_accuracy: 0.7868\n",
      "Epoch 25/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  512/22237 [..............................] - ETA: 5s - loss: 9.8445 - binary_output_0_loss: 0.4577 - binary_output_1_loss: 0.0853 - binary_output_2_loss: 0.5257 - binary_output_3_loss: 0.4264 - binary_output_4_loss: 0.2573 - binary_output_5_loss: 0.2712 - binary_output_6_loss: 0.1674 - binary_output_7_loss: 0.1842 - binary_output_8_loss: 4.7581e-04 - binary_output_9_loss: 0.2968 - binary_output_10_loss: 0.3199 - binary_output_11_loss: 0.4086 - binary_output_12_loss: 0.1724 - binary_output_13_loss: 0.2253 - binary_output_14_loss: 0.1804 - binary_output_15_loss: 0.2184 - binary_output_16_loss: 0.2991 - binary_output_17_loss: 0.6227 - binary_output_18_loss: 0.2732 - binary_output_19_loss: 0.3559 - binary_output_20_loss: 0.2289 - binary_output_21_loss: 0.1994 - binary_output_22_loss: 0.0729 - binary_output_23_loss: 0.1326 - binary_output_24_loss: 0.0836 - binary_output_25_loss: 0.1155 - binary_output_26_loss: 0.2533 - binary_output_27_loss: 0.4126 - binary_output_28_loss: 0.3255 - binary_output_29_loss: 0.3118 - binary_output_30_loss: 0.2008 - binary_output_31_loss: 0.2625 - binary_output_32_loss: 0.2171 - binary_output_33_loss: 0.3365 - binary_output_34_loss: 0.5741 - categorical_output_loss: 0.3692 - binary_output_0_binary_accuracy: 0.6562 - binary_output_1_binary_accuracy: 0.9941 - binary_output_2_binary_accuracy: 0.6641 - binary_output_3_binary_accuracy: 0.6641 - binary_output_4_binary_accuracy: 0.8281 - binary_output_5_binary_accuracy: 0.8750 - binary_output_6_binary_accuracy: 0.9219 - binary_output_7_binary_accuracy: 0.9141 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.7949 - binary_output_10_binary_accuracy: 0.7637 - binary_output_11_binary_accuracy: 0.8047 - binary_output_12_binary_accuracy: 0.9648 - binary_output_13_binary_accuracy: 0.8867 - binary_output_14_binary_accuracy: 0.9629 - binary_output_15_binary_accuracy: 0.8691 - binary_output_16_binary_accuracy: 0.8496 - binary_output_17_binary_accuracy: 0.5117 - binary_output_18_binary_accuracy: 0.7969 - binary_output_19_binary_accuracy: 0.8008 - binary_output_20_binary_accuracy: 0.8574 - binary_output_21_binary_accuracy: 0.9238 - binary_output_22_binary_accuracy: 0.9902 - binary_output_23_binary_accuracy: 0.9492 - binary_output_24_binary_accuracy: 0.9922 - binary_output_25_binary_accuracy: 0.9570 - binary_output_26_binary_accuracy: 0.8301 - binary_output_27_binary_accuracy: 0.7773 - binary_output_28_binary_accuracy: 0.7910 - binary_output_29_binary_accuracy: 0.8320 - binary_output_30_binary_accuracy: 0.9707 - binary_output_31_binary_accuracy: 0.7949 - binary_output_32_binary_accuracy: 0.9219 - binary_output_33_binary_accuracy: 0.7305 - binary_output_34_binary_accuracy: 0.6055 - categorical_output_sparse_categorical_accuracy: 0.8242\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 1024/22237 [>.............................] - ETA: 5s - loss: 9.8958 - binary_output_0_loss: 0.4633 - binary_output_1_loss: 0.0533 - binary_output_2_loss: 0.5635 - binary_output_3_loss: 0.4262 - binary_output_4_loss: 0.2606 - binary_output_5_loss: 0.2749 - binary_output_6_loss: 0.1728 - binary_output_7_loss: 0.1639 - binary_output_8_loss: 5.9005e-04 - binary_output_9_loss: 0.2646 - binary_output_10_loss: 0.3648 - binary_output_11_loss: 0.3413 - binary_output_12_loss: 0.1291 - binary_output_13_loss: 0.2503 - binary_output_14_loss: 0.1702 - binary_output_15_loss: 0.2374 - binary_output_16_loss: 0.3678 - binary_output_17_loss: 0.6053 - binary_output_18_loss: 0.2737 - binary_output_19_loss: 0.3616 - binary_output_20_loss: 0.2223 - binary_output_21_loss: 0.1847 - binary_output_22_loss: 0.0670 - binary_output_23_loss: 0.1535 - binary_output_24_loss: 0.0649 - binary_output_25_loss: 0.1358 - binary_output_26_loss: 0.2407 - binary_output_27_loss: 0.3711 - binary_output_28_loss: 0.3230 - binary_output_29_loss: 0.3025 - binary_output_30_loss: 0.2093 - binary_output_31_loss: 0.2477 - binary_output_32_loss: 0.1772 - binary_output_33_loss: 0.3195 - binary_output_34_loss: 0.6433 - categorical_output_loss: 0.4879 - binary_output_0_binary_accuracy: 0.7158 - binary_output_1_binary_accuracy: 0.9951 - binary_output_2_binary_accuracy: 0.7197 - binary_output_3_binary_accuracy: 0.7188 - binary_output_4_binary_accuracy: 0.8584 - binary_output_5_binary_accuracy: 0.8848 - binary_output_6_binary_accuracy: 0.9287 - binary_output_7_binary_accuracy: 0.9111 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8340 - binary_output_10_binary_accuracy: 0.8223 - binary_output_11_binary_accuracy: 0.8408 - binary_output_12_binary_accuracy: 0.9746 - binary_output_13_binary_accuracy: 0.9121 - binary_output_14_binary_accuracy: 0.9609 - binary_output_15_binary_accuracy: 0.8818 - binary_output_16_binary_accuracy: 0.8535 - binary_output_17_binary_accuracy: 0.5625 - binary_output_18_binary_accuracy: 0.8330 - binary_output_19_binary_accuracy: 0.8330 - binary_output_20_binary_accuracy: 0.8721 - binary_output_21_binary_accuracy: 0.9219 - binary_output_22_binary_accuracy: 0.9902 - binary_output_23_binary_accuracy: 0.9561 - binary_output_24_binary_accuracy: 0.9922 - binary_output_25_binary_accuracy: 0.9609 - binary_output_26_binary_accuracy: 0.8555 - binary_output_27_binary_accuracy: 0.7646 - binary_output_28_binary_accuracy: 0.8135 - binary_output_29_binary_accuracy: 0.8232 - binary_output_30_binary_accuracy: 0.9619 - binary_output_31_binary_accuracy: 0.8330 - binary_output_32_binary_accuracy: 0.9189 - binary_output_33_binary_accuracy: 0.7627 - binary_output_34_binary_accuracy: 0.6445 - categorical_output_sparse_categorical_accuracy: 0.7783"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22237/22237 [==============================] - 7s 308us/step - loss: 9.9884 - binary_output_0_loss: 0.4720 - binary_output_1_loss: 0.0819 - binary_output_2_loss: 0.5202 - binary_output_3_loss: 0.4550 - binary_output_4_loss: 0.2902 - binary_output_5_loss: 0.2593 - binary_output_6_loss: 0.2160 - binary_output_7_loss: 0.1753 - binary_output_8_loss: 6.4407e-04 - binary_output_9_loss: 0.2658 - binary_output_10_loss: 0.3379 - binary_output_11_loss: 0.3342 - binary_output_12_loss: 0.1190 - binary_output_13_loss: 0.2221 - binary_output_14_loss: 0.1543 - binary_output_15_loss: 0.2644 - binary_output_16_loss: 0.3104 - binary_output_17_loss: 0.6415 - binary_output_18_loss: 0.3271 - binary_output_19_loss: 0.3276 - binary_output_20_loss: 0.2779 - binary_output_21_loss: 0.2002 - binary_output_22_loss: 0.1012 - binary_output_23_loss: 0.1251 - binary_output_24_loss: 0.0771 - binary_output_25_loss: 0.1389 - binary_output_26_loss: 0.2794 - binary_output_27_loss: 0.4101 - binary_output_28_loss: 0.3266 - binary_output_29_loss: 0.3228 - binary_output_30_loss: 0.1366 - binary_output_31_loss: 0.3098 - binary_output_32_loss: 0.1921 - binary_output_33_loss: 0.3631 - binary_output_34_loss: 0.5657 - categorical_output_loss: 0.3883 - binary_output_0_binary_accuracy: 0.7152 - binary_output_1_binary_accuracy: 0.9907 - binary_output_2_binary_accuracy: 0.7183 - binary_output_3_binary_accuracy: 0.7145 - binary_output_4_binary_accuracy: 0.8468 - binary_output_5_binary_accuracy: 0.8750 - binary_output_6_binary_accuracy: 0.9251 - binary_output_7_binary_accuracy: 0.9231 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8544 - binary_output_10_binary_accuracy: 0.8122 - binary_output_11_binary_accuracy: 0.8165 - binary_output_12_binary_accuracy: 0.9638 - binary_output_13_binary_accuracy: 0.9148 - binary_output_14_binary_accuracy: 0.9600 - binary_output_15_binary_accuracy: 0.8571 - binary_output_16_binary_accuracy: 0.8391 - binary_output_17_binary_accuracy: 0.5601 - binary_output_18_binary_accuracy: 0.8087 - binary_output_19_binary_accuracy: 0.8123 - binary_output_20_binary_accuracy: 0.8410 - binary_output_21_binary_accuracy: 0.9141 - binary_output_22_binary_accuracy: 0.9806 - binary_output_23_binary_accuracy: 0.9593 - binary_output_24_binary_accuracy: 0.9895 - binary_output_25_binary_accuracy: 0.9491 - binary_output_26_binary_accuracy: 0.8310 - binary_output_27_binary_accuracy: 0.7747 - binary_output_28_binary_accuracy: 0.8190 - binary_output_29_binary_accuracy: 0.8281 - binary_output_30_binary_accuracy: 0.9620 - binary_output_31_binary_accuracy: 0.8361 - binary_output_32_binary_accuracy: 0.9081 - binary_output_33_binary_accuracy: 0.7707 - binary_output_34_binary_accuracy: 0.6478 - categorical_output_sparse_categorical_accuracy: 0.7863\n",
      "Epoch 26/40\n",
      "22237/22237 [==============================] - 6s 277us/step - loss: 9.8798 - binary_output_0_loss: 0.4598 - binary_output_1_loss: 0.0815 - binary_output_2_loss: 0.5146 - binary_output_3_loss: 0.4532 - binary_output_4_loss: 0.2849 - binary_output_5_loss: 0.2601 - binary_output_6_loss: 0.2153 - binary_output_7_loss: 0.1731 - binary_output_8_loss: 6.5397e-04 - binary_output_9_loss: 0.2581 - binary_output_10_loss: 0.3348 - binary_output_11_loss: 0.3262 - binary_output_12_loss: 0.1240 - binary_output_13_loss: 0.2184 - binary_output_14_loss: 0.1534 - binary_output_15_loss: 0.2594 - binary_output_16_loss: 0.3026 - binary_output_17_loss: 0.6330 - binary_output_18_loss: 0.3243 - binary_output_19_loss: 0.3204 - binary_output_20_loss: 0.2822 - binary_output_21_loss: 0.1938 - binary_output_22_loss: 0.0977 - binary_output_23_loss: 0.1255 - binary_output_24_loss: 0.0755 - binary_output_25_loss: 0.1387 - binary_output_26_loss: 0.2758 - binary_output_27_loss: 0.4097 - binary_output_28_loss: 0.3216 - binary_output_29_loss: 0.3170 - binary_output_30_loss: 0.1326 - binary_output_31_loss: 0.3052 - binary_output_32_loss: 0.1903 - binary_output_33_loss: 0.3633 - binary_output_34_loss: 0.5590 - categorical_output_loss: 0.3810 - binary_output_0_binary_accuracy: 0.7331 - binary_output_1_binary_accuracy: 0.9897 - binary_output_2_binary_accuracy: 0.7246 - binary_output_3_binary_accuracy: 0.7147 - binary_output_4_binary_accuracy: 0.8477 - binary_output_5_binary_accuracy: 0.8762 - binary_output_6_binary_accuracy: 0.9244 - binary_output_7_binary_accuracy: 0.9264 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8610 - binary_output_10_binary_accuracy: 0.8156 - binary_output_11_binary_accuracy: 0.8202 - binary_output_12_binary_accuracy: 0.9622 - binary_output_13_binary_accuracy: 0.9187 - binary_output_14_binary_accuracy: 0.9578 - binary_output_15_binary_accuracy: 0.8628 - binary_output_16_binary_accuracy: 0.8414 - binary_output_17_binary_accuracy: 0.5693 - binary_output_18_binary_accuracy: 0.8120 - binary_output_19_binary_accuracy: 0.8143 - binary_output_20_binary_accuracy: 0.8415 - binary_output_21_binary_accuracy: 0.9157 - binary_output_22_binary_accuracy: 0.9779 - binary_output_23_binary_accuracy: 0.9581 - binary_output_24_binary_accuracy: 0.9891 - binary_output_25_binary_accuracy: 0.9497 - binary_output_26_binary_accuracy: 0.8370 - binary_output_27_binary_accuracy: 0.7768 - binary_output_28_binary_accuracy: 0.8213 - binary_output_29_binary_accuracy: 0.8326 - binary_output_30_binary_accuracy: 0.9638 - binary_output_31_binary_accuracy: 0.8342 - binary_output_32_binary_accuracy: 0.9066 - binary_output_33_binary_accuracy: 0.7723 - binary_output_34_binary_accuracy: 0.6501 - categorical_output_sparse_categorical_accuracy: 0.7901\n",
      "Epoch 27/40\n",
      " 1024/22237 [>.............................] - ETA: 5s - loss: 9.6128 - binary_output_0_loss: 0.4588 - binary_output_1_loss: 0.0887 - binary_output_2_loss: 0.4883 - binary_output_3_loss: 0.4597 - binary_output_4_loss: 0.2872 - binary_output_5_loss: 0.2515 - binary_output_6_loss: 0.2435 - binary_output_7_loss: 0.2116 - binary_output_8_loss: 9.1242e-04 - binary_output_9_loss: 0.3083 - binary_output_10_loss: 0.3357 - binary_output_11_loss: 0.3177 - binary_output_12_loss: 0.1580 - binary_output_13_loss: 0.2122 - binary_output_14_loss: 0.1772 - binary_output_15_loss: 0.2803 - binary_output_16_loss: 0.3462 - binary_output_17_loss: 0.6169 - binary_output_18_loss: 0.3240 - binary_output_19_loss: 0.2270 - binary_output_20_loss: 0.2590 - binary_output_21_loss: 0.1540 - binary_output_22_loss: 0.1246 - binary_output_23_loss: 0.1210 - binary_output_24_loss: 0.0791 - binary_output_25_loss: 0.1144 - binary_output_26_loss: 0.2721 - binary_output_27_loss: 0.3188 - binary_output_28_loss: 0.2759 - binary_output_29_loss: 0.2669 - binary_output_30_loss: 0.1248 - binary_output_31_loss: 0.2218 - binary_output_32_loss: 0.2124 - binary_output_33_loss: 0.3713 - binary_output_34_loss: 0.5338 - categorical_output_loss: 0.3692 - binary_output_0_binary_accuracy: 0.7588 - binary_output_1_binary_accuracy: 0.9883 - binary_output_2_binary_accuracy: 0.7539 - binary_output_3_binary_accuracy: 0.7275 - binary_output_4_binary_accuracy: 0.8340 - binary_output_5_binary_accuracy: 0.8984 - binary_output_6_binary_accuracy: 0.9131 - binary_output_7_binary_accuracy: 0.9131 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8926 - binary_output_10_binary_accuracy: 0.8281 - binary_output_11_binary_accuracy: 0.7891 - binary_output_12_binary_accuracy: 0.9512 - binary_output_13_binary_accuracy: 0.9219 - binary_output_14_binary_accuracy: 0.9551 - binary_output_15_binary_accuracy: 0.8633 - binary_output_16_binary_accuracy: 0.8467 - binary_output_17_binary_accuracy: 0.5830 - binary_output_18_binary_accuracy: 0.8145 - binary_output_19_binary_accuracy: 0.8418 - binary_output_20_binary_accuracy: 0.8467 - binary_output_21_binary_accuracy: 0.9287 - binary_output_22_binary_accuracy: 0.9717 - binary_output_23_binary_accuracy: 0.9492 - binary_output_24_binary_accuracy: 0.9893 - binary_output_25_binary_accuracy: 0.9551 - binary_output_26_binary_accuracy: 0.8516 - binary_output_27_binary_accuracy: 0.8135 - binary_output_28_binary_accuracy: 0.8525 - binary_output_29_binary_accuracy: 0.8613 - binary_output_30_binary_accuracy: 0.9668 - binary_output_31_binary_accuracy: 0.8691 - binary_output_32_binary_accuracy: 0.9121 - binary_output_33_binary_accuracy: 0.7852 - binary_output_34_binary_accuracy: 0.6914 - categorical_output_sparse_categorical_accuracy: 0.805722237/22237 [==============================] - 7s 301us/step - loss: 9.7205 - binary_output_0_loss: 0.4513 - binary_output_1_loss: 0.0814 - binary_output_2_loss: 0.5022 - binary_output_3_loss: 0.4441 - binary_output_4_loss: 0.2865 - binary_output_5_loss: 0.2567 - binary_output_6_loss: 0.2113 - binary_output_7_loss: 0.1734 - binary_output_8_loss: 6.0565e-04 - binary_output_9_loss: 0.2477 - binary_output_10_loss: 0.3312 - binary_output_11_loss: 0.3183 - binary_output_12_loss: 0.1164 - binary_output_13_loss: 0.2114 - binary_output_14_loss: 0.1518 - binary_output_15_loss: 0.2571 - binary_output_16_loss: 0.2988 - binary_output_17_loss: 0.6318 - binary_output_18_loss: 0.3242 - binary_output_19_loss: 0.3170 - binary_output_20_loss: 0.2787 - binary_output_21_loss: 0.1918 - binary_output_22_loss: 0.0962 - binary_output_23_loss: 0.1257 - binary_output_24_loss: 0.0746 - binary_output_25_loss: 0.1355 - binary_output_26_loss: 0.2764 - binary_output_27_loss: 0.3962 - binary_output_28_loss: 0.3161 - binary_output_29_loss: 0.3155 - binary_output_30_loss: 0.1315 - binary_output_31_loss: 0.2947 - binary_output_32_loss: 0.1873 - binary_output_33_loss: 0.3539 - binary_output_34_loss: 0.5477 - categorical_output_loss: 0.3743 - binary_output_0_binary_accuracy: 0.7324 - binary_output_1_binary_accuracy: 0.9903 - binary_output_2_binary_accuracy: 0.7324 - binary_output_3_binary_accuracy: 0.7157 - binary_output_4_binary_accuracy: 0.8512 - binary_output_5_binary_accuracy: 0.8781 - binary_output_6_binary_accuracy: 0.9241 - binary_output_7_binary_accuracy: 0.9253 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8695 - binary_output_10_binary_accuracy: 0.8181 - binary_output_11_binary_accuracy: 0.8222 - binary_output_12_binary_accuracy: 0.9612 - binary_output_13_binary_accuracy: 0.9213 - binary_output_14_binary_accuracy: 0.9589 - binary_output_15_binary_accuracy: 0.8614 - binary_output_16_binary_accuracy: 0.8455 - binary_output_17_binary_accuracy: 0.5725 - binary_output_18_binary_accuracy: 0.8132 - binary_output_19_binary_accuracy: 0.8177 - binary_output_20_binary_accuracy: 0.8410 - binary_output_21_binary_accuracy: 0.9194 - binary_output_22_binary_accuracy: 0.9774 - binary_output_23_binary_accuracy: 0.9600 - binary_output_24_binary_accuracy: 0.9892 - binary_output_25_binary_accuracy: 0.9517 - binary_output_26_binary_accuracy: 0.8343 - binary_output_27_binary_accuracy: 0.7894 - binary_output_28_binary_accuracy: 0.8264 - binary_output_29_binary_accuracy: 0.8346 - binary_output_30_binary_accuracy: 0.9615 - binary_output_31_binary_accuracy: 0.8490 - binary_output_32_binary_accuracy: 0.9105 - binary_output_33_binary_accuracy: 0.7743 - binary_output_34_binary_accuracy: 0.6621 - categorical_output_sparse_categorical_accuracy: 0.7912\n",
      "Epoch 28/40\n",
      "22237/22237 [==============================] - 6s 249us/step - loss: 9.5745 - binary_output_0_loss: 0.4561 - binary_output_1_loss: 0.0821 - binary_output_2_loss: 0.4917 - binary_output_3_loss: 0.4386 - binary_output_4_loss: 0.2780 - binary_output_5_loss: 0.2564 - binary_output_6_loss: 0.2102 - binary_output_7_loss: 0.1657 - binary_output_8_loss: 5.3152e-04 - binary_output_9_loss: 0.2454 - binary_output_10_loss: 0.3205 - binary_output_11_loss: 0.3149 - binary_output_12_loss: 0.1157 - binary_output_13_loss: 0.2058 - binary_output_14_loss: 0.1516 - binary_output_15_loss: 0.2532 - binary_output_16_loss: 0.3025 - binary_output_17_loss: 0.6236 - binary_output_18_loss: 0.3191 - binary_output_19_loss: 0.3119 - binary_output_20_loss: 0.2719 - binary_output_21_loss: 0.1893 - binary_output_22_loss: 0.0955 - binary_output_23_loss: 0.1227 - binary_output_24_loss: 0.0721 - binary_output_25_loss: 0.1396 - binary_output_26_loss: 0.2706 - binary_output_27_loss: 0.3876 - binary_output_28_loss: 0.3115 - binary_output_29_loss: 0.3090 - binary_output_30_loss: 0.1302 - binary_output_31_loss: 0.3014 - binary_output_32_loss: 0.1875 - binary_output_33_loss: 0.3482 - binary_output_34_loss: 0.5451 - categorical_output_loss: 0.3709 - binary_output_0_binary_accuracy: 0.7337 - binary_output_1_binary_accuracy: 0.9885 - binary_output_2_binary_accuracy: 0.7366 - binary_output_3_binary_accuracy: 0.7272 - binary_output_4_binary_accuracy: 0.8561 - binary_output_5_binary_accuracy: 0.8741 - binary_output_6_binary_accuracy: 0.9246 - binary_output_7_binary_accuracy: 0.9284 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8747 - binary_output_10_binary_accuracy: 0.8260 - binary_output_11_binary_accuracy: 0.8291 - binary_output_12_binary_accuracy: 0.9616 - binary_output_13_binary_accuracy: 0.9198 - binary_output_14_binary_accuracy: 0.9571 - binary_output_15_binary_accuracy: 0.8652 - binary_output_16_binary_accuracy: 0.8422 - binary_output_17_binary_accuracy: 0.5760 - binary_output_18_binary_accuracy: 0.8165 - binary_output_19_binary_accuracy: 0.8183 - binary_output_20_binary_accuracy: 0.8433 - binary_output_21_binary_accuracy: 0.9200 - binary_output_22_binary_accuracy: 0.9794 - binary_output_23_binary_accuracy: 0.9589 - binary_output_24_binary_accuracy: 0.9885 - binary_output_25_binary_accuracy: 0.9492 - binary_output_26_binary_accuracy: 0.8373 - binary_output_27_binary_accuracy: 0.7917 - binary_output_28_binary_accuracy: 0.8249 - binary_output_29_binary_accuracy: 0.8345 - binary_output_30_binary_accuracy: 0.9599 - binary_output_31_binary_accuracy: 0.8376 - binary_output_32_binary_accuracy: 0.9101 - binary_output_33_binary_accuracy: 0.7779 - binary_output_34_binary_accuracy: 0.6613 - categorical_output_sparse_categorical_accuracy: 0.7937\n",
      "Epoch 29/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  512/22237 [..............................] - ETA: 5s - loss: 9.4225 - binary_output_0_loss: 0.4151 - binary_output_1_loss: 0.0934 - binary_output_2_loss: 0.5312 - binary_output_3_loss: 0.3888 - binary_output_4_loss: 0.2132 - binary_output_5_loss: 0.2028 - binary_output_6_loss: 0.2032 - binary_output_7_loss: 0.1044 - binary_output_8_loss: 6.7116e-04 - binary_output_9_loss: 0.2122 - binary_output_10_loss: 0.2591 - binary_output_11_loss: 0.3092 - binary_output_12_loss: 0.1169 - binary_output_13_loss: 0.1301 - binary_output_14_loss: 0.1886 - binary_output_15_loss: 0.2251 - binary_output_16_loss: 0.3157 - binary_output_17_loss: 0.6033 - binary_output_18_loss: 0.3552 - binary_output_19_loss: 0.2915 - binary_output_20_loss: 0.3780 - binary_output_21_loss: 0.1688 - binary_output_22_loss: 0.0879 - binary_output_23_loss: 0.0756 - binary_output_24_loss: 0.1148 - binary_output_25_loss: 0.1365 - binary_output_26_loss: 0.2857 - binary_output_27_loss: 0.3720 - binary_output_28_loss: 0.3235 - binary_output_29_loss: 0.3364 - binary_output_30_loss: 0.1070 - binary_output_31_loss: 0.3612 - binary_output_32_loss: 0.1852 - binary_output_33_loss: 0.3714 - binary_output_34_loss: 0.5646 - categorical_output_loss: 0.3942 - binary_output_0_binary_accuracy: 0.7129 - binary_output_1_binary_accuracy: 0.9961 - binary_output_2_binary_accuracy: 0.6445 - binary_output_3_binary_accuracy: 0.7070 - binary_output_4_binary_accuracy: 0.8516 - binary_output_5_binary_accuracy: 0.8359 - binary_output_6_binary_accuracy: 0.8965 - binary_output_7_binary_accuracy: 0.9414 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.9082 - binary_output_10_binary_accuracy: 0.8340 - binary_output_11_binary_accuracy: 0.7812 - binary_output_12_binary_accuracy: 0.9512 - binary_output_13_binary_accuracy: 0.9355 - binary_output_14_binary_accuracy: 0.9434 - binary_output_15_binary_accuracy: 0.8145 - binary_output_16_binary_accuracy: 0.7812 - binary_output_17_binary_accuracy: 0.5527 - binary_output_18_binary_accuracy: 0.7734 - binary_output_19_binary_accuracy: 0.7734 - binary_output_20_binary_accuracy: 0.8027 - binary_output_21_binary_accuracy: 0.9043 - binary_output_22_binary_accuracy: 0.9785 - binary_output_23_binary_accuracy: 0.9648 - binary_output_24_binary_accuracy: 0.9824 - binary_output_25_binary_accuracy: 0.9434 - binary_output_26_binary_accuracy: 0.8086 - binary_output_27_binary_accuracy: 0.7734 - binary_output_28_binary_accuracy: 0.7891 - binary_output_29_binary_accuracy: 0.8281 - binary_output_30_binary_accuracy: 0.9551 - binary_output_31_binary_accuracy: 0.8398 - binary_output_32_binary_accuracy: 0.8633 - binary_output_33_binary_accuracy: 0.7148 - binary_output_34_binary_accuracy: 0.6289 - categorical_output_sparse_categorical_accuracy: 0.7930\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 1024/22237 [>.............................] - ETA: 5s - loss: 9.1543 - binary_output_0_loss: 0.4207 - binary_output_1_loss: 0.0831 - binary_output_2_loss: 0.4961 - binary_output_3_loss: 0.3846 - binary_output_4_loss: 0.2237 - binary_output_5_loss: 0.2452 - binary_output_6_loss: 0.1805 - binary_output_7_loss: 0.1095 - binary_output_8_loss: 5.4112e-04 - binary_output_9_loss: 0.2242 - binary_output_10_loss: 0.2805 - binary_output_11_loss: 0.2798 - binary_output_12_loss: 0.1327 - binary_output_13_loss: 0.1802 - binary_output_14_loss: 0.1410 - binary_output_15_loss: 0.2389 - binary_output_16_loss: 0.3097 - binary_output_17_loss: 0.5960 - binary_output_18_loss: 0.2998 - binary_output_19_loss: 0.2857 - binary_output_20_loss: 0.2807 - binary_output_21_loss: 0.1462 - binary_output_22_loss: 0.0856 - binary_output_23_loss: 0.1065 - binary_output_24_loss: 0.0736 - binary_output_25_loss: 0.1163 - binary_output_26_loss: 0.2512 - binary_output_27_loss: 0.3832 - binary_output_28_loss: 0.3018 - binary_output_29_loss: 0.3342 - binary_output_30_loss: 0.1136 - binary_output_31_loss: 0.3325 - binary_output_32_loss: 0.2042 - binary_output_33_loss: 0.3737 - binary_output_34_loss: 0.5250 - categorical_output_loss: 0.4135 - binary_output_0_binary_accuracy: 0.7402 - binary_output_1_binary_accuracy: 0.9932 - binary_output_2_binary_accuracy: 0.7119 - binary_output_3_binary_accuracy: 0.7197 - binary_output_4_binary_accuracy: 0.8613 - binary_output_5_binary_accuracy: 0.8691 - binary_output_6_binary_accuracy: 0.9121 - binary_output_7_binary_accuracy: 0.9395 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8906 - binary_output_10_binary_accuracy: 0.8516 - binary_output_11_binary_accuracy: 0.8154 - binary_output_12_binary_accuracy: 0.9590 - binary_output_13_binary_accuracy: 0.9404 - binary_output_14_binary_accuracy: 0.9600 - binary_output_15_binary_accuracy: 0.8428 - binary_output_16_binary_accuracy: 0.8135 - binary_output_17_binary_accuracy: 0.5889 - binary_output_18_binary_accuracy: 0.8135 - binary_output_19_binary_accuracy: 0.8037 - binary_output_20_binary_accuracy: 0.8359 - binary_output_21_binary_accuracy: 0.9180 - binary_output_22_binary_accuracy: 0.9844 - binary_output_23_binary_accuracy: 0.9697 - binary_output_24_binary_accuracy: 0.9883 - binary_output_25_binary_accuracy: 0.9590 - binary_output_26_binary_accuracy: 0.8369 - binary_output_27_binary_accuracy: 0.8193 - binary_output_28_binary_accuracy: 0.8242 - binary_output_29_binary_accuracy: 0.8447 - binary_output_30_binary_accuracy: 0.9648 - binary_output_31_binary_accuracy: 0.8467 - binary_output_32_binary_accuracy: 0.8887 - binary_output_33_binary_accuracy: 0.7676 - binary_output_34_binary_accuracy: 0.6631 - categorical_output_sparse_categorical_accuracy: 0.7871"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22237/22237 [==============================] - 6s 255us/step - loss: 9.4683 - binary_output_0_loss: 0.4449 - binary_output_1_loss: 0.0793 - binary_output_2_loss: 0.4893 - binary_output_3_loss: 0.4310 - binary_output_4_loss: 0.2721 - binary_output_5_loss: 0.2518 - binary_output_6_loss: 0.2114 - binary_output_7_loss: 0.1694 - binary_output_8_loss: 5.3354e-04 - binary_output_9_loss: 0.2365 - binary_output_10_loss: 0.3205 - binary_output_11_loss: 0.3105 - binary_output_12_loss: 0.1143 - binary_output_13_loss: 0.2032 - binary_output_14_loss: 0.1453 - binary_output_15_loss: 0.2502 - binary_output_16_loss: 0.2921 - binary_output_17_loss: 0.6183 - binary_output_18_loss: 0.3115 - binary_output_19_loss: 0.3137 - binary_output_20_loss: 0.2723 - binary_output_21_loss: 0.1861 - binary_output_22_loss: 0.0940 - binary_output_23_loss: 0.1143 - binary_output_24_loss: 0.0742 - binary_output_25_loss: 0.1296 - binary_output_26_loss: 0.2696 - binary_output_27_loss: 0.3910 - binary_output_28_loss: 0.3066 - binary_output_29_loss: 0.3139 - binary_output_30_loss: 0.1274 - binary_output_31_loss: 0.2901 - binary_output_32_loss: 0.1851 - binary_output_33_loss: 0.3445 - binary_output_34_loss: 0.5402 - categorical_output_loss: 0.3658 - binary_output_0_binary_accuracy: 0.7397 - binary_output_1_binary_accuracy: 0.9891 - binary_output_2_binary_accuracy: 0.7367 - binary_output_3_binary_accuracy: 0.7299 - binary_output_4_binary_accuracy: 0.8547 - binary_output_5_binary_accuracy: 0.8713 - binary_output_6_binary_accuracy: 0.9215 - binary_output_7_binary_accuracy: 0.9295 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8820 - binary_output_10_binary_accuracy: 0.8259 - binary_output_11_binary_accuracy: 0.8266 - binary_output_12_binary_accuracy: 0.9623 - binary_output_13_binary_accuracy: 0.9179 - binary_output_14_binary_accuracy: 0.9578 - binary_output_15_binary_accuracy: 0.8651 - binary_output_16_binary_accuracy: 0.8417 - binary_output_17_binary_accuracy: 0.5776 - binary_output_18_binary_accuracy: 0.8229 - binary_output_19_binary_accuracy: 0.8170 - binary_output_20_binary_accuracy: 0.8466 - binary_output_21_binary_accuracy: 0.9194 - binary_output_22_binary_accuracy: 0.9808 - binary_output_23_binary_accuracy: 0.9589 - binary_output_24_binary_accuracy: 0.9879 - binary_output_25_binary_accuracy: 0.9493 - binary_output_26_binary_accuracy: 0.8407 - binary_output_27_binary_accuracy: 0.7926 - binary_output_28_binary_accuracy: 0.8322 - binary_output_29_binary_accuracy: 0.8352 - binary_output_30_binary_accuracy: 0.9631 - binary_output_31_binary_accuracy: 0.8502 - binary_output_32_binary_accuracy: 0.9081 - binary_output_33_binary_accuracy: 0.7789 - binary_output_34_binary_accuracy: 0.6654 - categorical_output_sparse_categorical_accuracy: 0.7957\n",
      "Epoch 30/40\n",
      "22237/22237 [==============================] - 6s 273us/step - loss: 9.3457 - binary_output_0_loss: 0.4364 - binary_output_1_loss: 0.0783 - binary_output_2_loss: 0.4767 - binary_output_3_loss: 0.4244 - binary_output_4_loss: 0.2735 - binary_output_5_loss: 0.2426 - binary_output_6_loss: 0.2048 - binary_output_7_loss: 0.1638 - binary_output_8_loss: 5.4471e-04 - binary_output_9_loss: 0.2273 - binary_output_10_loss: 0.3191 - binary_output_11_loss: 0.3056 - binary_output_12_loss: 0.1122 - binary_output_13_loss: 0.1980 - binary_output_14_loss: 0.1492 - binary_output_15_loss: 0.2459 - binary_output_16_loss: 0.2900 - binary_output_17_loss: 0.6190 - binary_output_18_loss: 0.3068 - binary_output_19_loss: 0.3057 - binary_output_20_loss: 0.2652 - binary_output_21_loss: 0.1864 - binary_output_22_loss: 0.0901 - binary_output_23_loss: 0.1124 - binary_output_24_loss: 0.0730 - binary_output_25_loss: 0.1278 - binary_output_26_loss: 0.2663 - binary_output_27_loss: 0.3834 - binary_output_28_loss: 0.3065 - binary_output_29_loss: 0.3047 - binary_output_30_loss: 0.1265 - binary_output_31_loss: 0.2850 - binary_output_32_loss: 0.1794 - binary_output_33_loss: 0.3476 - binary_output_34_loss: 0.5406 - categorical_output_loss: 0.3668 - binary_output_0_binary_accuracy: 0.7422 - binary_output_1_binary_accuracy: 0.9888 - binary_output_2_binary_accuracy: 0.7448 - binary_output_3_binary_accuracy: 0.7383 - binary_output_4_binary_accuracy: 0.8582 - binary_output_5_binary_accuracy: 0.8802 - binary_output_6_binary_accuracy: 0.9209 - binary_output_7_binary_accuracy: 0.9271 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8812 - binary_output_10_binary_accuracy: 0.8278 - binary_output_11_binary_accuracy: 0.8339 - binary_output_12_binary_accuracy: 0.9648 - binary_output_13_binary_accuracy: 0.9246 - binary_output_14_binary_accuracy: 0.9551 - binary_output_15_binary_accuracy: 0.8663 - binary_output_16_binary_accuracy: 0.8492 - binary_output_17_binary_accuracy: 0.5810 - binary_output_18_binary_accuracy: 0.8226 - binary_output_19_binary_accuracy: 0.8252 - binary_output_20_binary_accuracy: 0.8481 - binary_output_21_binary_accuracy: 0.9186 - binary_output_22_binary_accuracy: 0.9791 - binary_output_23_binary_accuracy: 0.9607 - binary_output_24_binary_accuracy: 0.9863 - binary_output_25_binary_accuracy: 0.9505 - binary_output_26_binary_accuracy: 0.8432 - binary_output_27_binary_accuracy: 0.7940 - binary_output_28_binary_accuracy: 0.8321 - binary_output_29_binary_accuracy: 0.8396 - binary_output_30_binary_accuracy: 0.9598 - binary_output_31_binary_accuracy: 0.8495 - binary_output_32_binary_accuracy: 0.9114 - binary_output_33_binary_accuracy: 0.7806 - binary_output_34_binary_accuracy: 0.6708 - categorical_output_sparse_categorical_accuracy: 0.7937\n",
      "Epoch 31/40\n",
      " 1024/22237 [>.............................] - ETA: 5s - loss: 9.2915 - binary_output_0_loss: 0.4121 - binary_output_1_loss: 0.0716 - binary_output_2_loss: 0.4011 - binary_output_3_loss: 0.4212 - binary_output_4_loss: 0.3249 - binary_output_5_loss: 0.2460 - binary_output_6_loss: 0.2124 - binary_output_7_loss: 0.1336 - binary_output_8_loss: 4.8092e-04 - binary_output_9_loss: 0.2150 - binary_output_10_loss: 0.3232 - binary_output_11_loss: 0.3414 - binary_output_12_loss: 0.1090 - binary_output_13_loss: 0.1586 - binary_output_14_loss: 0.1709 - binary_output_15_loss: 0.3353 - binary_output_16_loss: 0.3160 - binary_output_17_loss: 0.5564 - binary_output_18_loss: 0.3210 - binary_output_19_loss: 0.2901 - binary_output_20_loss: 0.2511 - binary_output_21_loss: 0.1780 - binary_output_22_loss: 0.1107 - binary_output_23_loss: 0.1220 - binary_output_24_loss: 0.0784 - binary_output_25_loss: 0.1356 - binary_output_26_loss: 0.2974 - binary_output_27_loss: 0.3552 - binary_output_28_loss: 0.2802 - binary_output_29_loss: 0.3053 - binary_output_30_loss: 0.1491 - binary_output_31_loss: 0.2493 - binary_output_32_loss: 0.2127 - binary_output_33_loss: 0.3096 - binary_output_34_loss: 0.4986 - categorical_output_loss: 0.3979 - binary_output_0_binary_accuracy: 0.7334 - binary_output_1_binary_accuracy: 0.9863 - binary_output_2_binary_accuracy: 0.7676 - binary_output_3_binary_accuracy: 0.7295 - binary_output_4_binary_accuracy: 0.8330 - binary_output_5_binary_accuracy: 0.8604 - binary_output_6_binary_accuracy: 0.9053 - binary_output_7_binary_accuracy: 0.9131 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8984 - binary_output_10_binary_accuracy: 0.8164 - binary_output_11_binary_accuracy: 0.8232 - binary_output_12_binary_accuracy: 0.9590 - binary_output_13_binary_accuracy: 0.9131 - binary_output_14_binary_accuracy: 0.9541 - binary_output_15_binary_accuracy: 0.8516 - binary_output_16_binary_accuracy: 0.8154 - binary_output_17_binary_accuracy: 0.5898 - binary_output_18_binary_accuracy: 0.8184 - binary_output_19_binary_accuracy: 0.7979 - binary_output_20_binary_accuracy: 0.8564 - binary_output_21_binary_accuracy: 0.9229 - binary_output_22_binary_accuracy: 0.9697 - binary_output_23_binary_accuracy: 0.9600 - binary_output_24_binary_accuracy: 0.9854 - binary_output_25_binary_accuracy: 0.9434 - binary_output_26_binary_accuracy: 0.8359 - binary_output_27_binary_accuracy: 0.8096 - binary_output_28_binary_accuracy: 0.8154 - binary_output_29_binary_accuracy: 0.8359 - binary_output_30_binary_accuracy: 0.9580 - binary_output_31_binary_accuracy: 0.8691 - binary_output_32_binary_accuracy: 0.9053 - binary_output_33_binary_accuracy: 0.7812 - binary_output_34_binary_accuracy: 0.6602 - categorical_output_sparse_categorical_accuracy: 0.813522237/22237 [==============================] - 6s 258us/step - loss: 9.2525 - binary_output_0_loss: 0.4369 - binary_output_1_loss: 0.0747 - binary_output_2_loss: 0.4725 - binary_output_3_loss: 0.4258 - binary_output_4_loss: 0.2668 - binary_output_5_loss: 0.2427 - binary_output_6_loss: 0.2027 - binary_output_7_loss: 0.1528 - binary_output_8_loss: 5.0200e-04 - binary_output_9_loss: 0.2247 - binary_output_10_loss: 0.3189 - binary_output_11_loss: 0.3034 - binary_output_12_loss: 0.1104 - binary_output_13_loss: 0.1913 - binary_output_14_loss: 0.1443 - binary_output_15_loss: 0.2513 - binary_output_16_loss: 0.2900 - binary_output_17_loss: 0.6082 - binary_output_18_loss: 0.3074 - binary_output_19_loss: 0.3059 - binary_output_20_loss: 0.2629 - binary_output_21_loss: 0.1818 - binary_output_22_loss: 0.0919 - binary_output_23_loss: 0.1094 - binary_output_24_loss: 0.0701 - binary_output_25_loss: 0.1305 - binary_output_26_loss: 0.2671 - binary_output_27_loss: 0.3777 - binary_output_28_loss: 0.3041 - binary_output_29_loss: 0.3032 - binary_output_30_loss: 0.1291 - binary_output_31_loss: 0.2804 - binary_output_32_loss: 0.1821 - binary_output_33_loss: 0.3397 - binary_output_34_loss: 0.5351 - categorical_output_loss: 0.3616 - binary_output_0_binary_accuracy: 0.7421 - binary_output_1_binary_accuracy: 0.9878 - binary_output_2_binary_accuracy: 0.7493 - binary_output_3_binary_accuracy: 0.7405 - binary_output_4_binary_accuracy: 0.8610 - binary_output_5_binary_accuracy: 0.8800 - binary_output_6_binary_accuracy: 0.9229 - binary_output_7_binary_accuracy: 0.9273 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8902 - binary_output_10_binary_accuracy: 0.8272 - binary_output_11_binary_accuracy: 0.8310 - binary_output_12_binary_accuracy: 0.9644 - binary_output_13_binary_accuracy: 0.9220 - binary_output_14_binary_accuracy: 0.9585 - binary_output_15_binary_accuracy: 0.8654 - binary_output_16_binary_accuracy: 0.8503 - binary_output_17_binary_accuracy: 0.5856 - binary_output_18_binary_accuracy: 0.8240 - binary_output_19_binary_accuracy: 0.8236 - binary_output_20_binary_accuracy: 0.8517 - binary_output_21_binary_accuracy: 0.9219 - binary_output_22_binary_accuracy: 0.9772 - binary_output_23_binary_accuracy: 0.9605 - binary_output_24_binary_accuracy: 0.9869 - binary_output_25_binary_accuracy: 0.9481 - binary_output_26_binary_accuracy: 0.8406 - binary_output_27_binary_accuracy: 0.7982 - binary_output_28_binary_accuracy: 0.8322 - binary_output_29_binary_accuracy: 0.8390 - binary_output_30_binary_accuracy: 0.9607 - binary_output_31_binary_accuracy: 0.8543 - binary_output_32_binary_accuracy: 0.9121 - binary_output_33_binary_accuracy: 0.7848 - binary_output_34_binary_accuracy: 0.6723 - categorical_output_sparse_categorical_accuracy: 0.7984\n",
      "Epoch 32/40\n",
      "22237/22237 [==============================] - 6s 250us/step - loss: 9.1044 - binary_output_0_loss: 0.4317 - binary_output_1_loss: 0.0762 - binary_output_2_loss: 0.4640 - binary_output_3_loss: 0.4198 - binary_output_4_loss: 0.2632 - binary_output_5_loss: 0.2423 - binary_output_6_loss: 0.1989 - binary_output_7_loss: 0.1558 - binary_output_8_loss: 5.4981e-04 - binary_output_9_loss: 0.2276 - binary_output_10_loss: 0.3068 - binary_output_11_loss: 0.3059 - binary_output_12_loss: 0.1062 - binary_output_13_loss: 0.1877 - binary_output_14_loss: 0.1379 - binary_output_15_loss: 0.2461 - binary_output_16_loss: 0.2810 - binary_output_17_loss: 0.6106 - binary_output_18_loss: 0.2977 - binary_output_19_loss: 0.3026 - binary_output_20_loss: 0.2583 - binary_output_21_loss: 0.1774 - binary_output_22_loss: 0.0925 - binary_output_23_loss: 0.1105 - binary_output_24_loss: 0.0684 - binary_output_25_loss: 0.1267 - binary_output_26_loss: 0.2581 - binary_output_27_loss: 0.3627 - binary_output_28_loss: 0.2946 - binary_output_29_loss: 0.2978 - binary_output_30_loss: 0.1228 - binary_output_31_loss: 0.2710 - binary_output_32_loss: 0.1756 - binary_output_33_loss: 0.3393 - binary_output_34_loss: 0.5277 - categorical_output_loss: 0.3597 - binary_output_0_binary_accuracy: 0.7452 - binary_output_1_binary_accuracy: 0.9875 - binary_output_2_binary_accuracy: 0.7517 - binary_output_3_binary_accuracy: 0.7383 - binary_output_4_binary_accuracy: 0.8630 - binary_output_5_binary_accuracy: 0.8764 - binary_output_6_binary_accuracy: 0.9236 - binary_output_7_binary_accuracy: 0.9285 - binary_output_8_binary_accuracy: 0.9999 - binary_output_9_binary_accuracy: 0.8896 - binary_output_10_binary_accuracy: 0.8364 - binary_output_11_binary_accuracy: 0.8367 - binary_output_12_binary_accuracy: 0.9649 - binary_output_13_binary_accuracy: 0.9253 - binary_output_14_binary_accuracy: 0.9588 - binary_output_15_binary_accuracy: 0.8692 - binary_output_16_binary_accuracy: 0.8556 - binary_output_17_binary_accuracy: 0.5902 - binary_output_18_binary_accuracy: 0.8266 - binary_output_19_binary_accuracy: 0.8286 - binary_output_20_binary_accuracy: 0.8547 - binary_output_21_binary_accuracy: 0.9222 - binary_output_22_binary_accuracy: 0.9758 - binary_output_23_binary_accuracy: 0.9589 - binary_output_24_binary_accuracy: 0.9868 - binary_output_25_binary_accuracy: 0.9502 - binary_output_26_binary_accuracy: 0.8402 - binary_output_27_binary_accuracy: 0.8076 - binary_output_28_binary_accuracy: 0.8377 - binary_output_29_binary_accuracy: 0.8447 - binary_output_30_binary_accuracy: 0.9617 - binary_output_31_binary_accuracy: 0.8554 - binary_output_32_binary_accuracy: 0.9144 - binary_output_33_binary_accuracy: 0.7832 - binary_output_34_binary_accuracy: 0.6762 - categorical_output_sparse_categorical_accuracy: 0.7946\n",
      "Epoch 33/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  512/22237 [..............................] - ETA: 5s - loss: 9.0920 - binary_output_0_loss: 0.4146 - binary_output_1_loss: 0.0225 - binary_output_2_loss: 0.4570 - binary_output_3_loss: 0.4173 - binary_output_4_loss: 0.2328 - binary_output_5_loss: 0.2377 - binary_output_6_loss: 0.1774 - binary_output_7_loss: 0.1571 - binary_output_8_loss: 3.1010e-04 - binary_output_9_loss: 0.3202 - binary_output_10_loss: 0.2946 - binary_output_11_loss: 0.3222 - binary_output_12_loss: 0.0753 - binary_output_13_loss: 0.1693 - binary_output_14_loss: 0.1183 - binary_output_15_loss: 0.2491 - binary_output_16_loss: 0.2497 - binary_output_17_loss: 0.5330 - binary_output_18_loss: 0.3319 - binary_output_19_loss: 0.2639 - binary_output_20_loss: 0.3928 - binary_output_21_loss: 0.1571 - binary_output_22_loss: 0.0366 - binary_output_23_loss: 0.1414 - binary_output_24_loss: 0.0791 - binary_output_25_loss: 0.1637 - binary_output_26_loss: 0.2847 - binary_output_27_loss: 0.3624 - binary_output_28_loss: 0.2029 - binary_output_29_loss: 0.3071 - binary_output_30_loss: 0.1747 - binary_output_31_loss: 0.2690 - binary_output_32_loss: 0.2761 - binary_output_33_loss: 0.3116 - binary_output_34_loss: 0.5265 - categorical_output_loss: 0.3624 - binary_output_0_binary_accuracy: 0.7344 - binary_output_1_binary_accuracy: 0.9961 - binary_output_2_binary_accuracy: 0.7812 - binary_output_3_binary_accuracy: 0.7383 - binary_output_4_binary_accuracy: 0.8711 - binary_output_5_binary_accuracy: 0.8770 - binary_output_6_binary_accuracy: 0.9395 - binary_output_7_binary_accuracy: 0.9473 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8652 - binary_output_10_binary_accuracy: 0.7949 - binary_output_11_binary_accuracy: 0.8457 - binary_output_12_binary_accuracy: 0.9648 - binary_output_13_binary_accuracy: 0.9258 - binary_output_14_binary_accuracy: 0.9590 - binary_output_15_binary_accuracy: 0.8945 - binary_output_16_binary_accuracy: 0.8633 - binary_output_17_binary_accuracy: 0.5996 - binary_output_18_binary_accuracy: 0.8574 - binary_output_19_binary_accuracy: 0.8105 - binary_output_20_binary_accuracy: 0.8672 - binary_output_21_binary_accuracy: 0.8984 - binary_output_22_binary_accuracy: 0.9746 - binary_output_23_binary_accuracy: 0.9648 - binary_output_24_binary_accuracy: 0.9883 - binary_output_25_binary_accuracy: 0.9492 - binary_output_26_binary_accuracy: 0.8613 - binary_output_27_binary_accuracy: 0.7617 - binary_output_28_binary_accuracy: 0.8457 - binary_output_29_binary_accuracy: 0.8047 - binary_output_30_binary_accuracy: 0.9453 - binary_output_31_binary_accuracy: 0.8594 - binary_output_32_binary_accuracy: 0.8965 - binary_output_33_binary_accuracy: 0.7715 - binary_output_34_binary_accuracy: 0.6719 - categorical_output_sparse_categorical_accuracy: 0.7910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 1024/22237 [>.............................] - ETA: 5s - loss: 9.2292 - binary_output_0_loss: 0.4241 - binary_output_1_loss: 0.0471 - binary_output_2_loss: 0.4793 - binary_output_3_loss: 0.4520 - binary_output_4_loss: 0.2490 - binary_output_5_loss: 0.2246 - binary_output_6_loss: 0.1574 - binary_output_7_loss: 0.1447 - binary_output_8_loss: 4.0748e-04 - binary_output_9_loss: 0.2476 - binary_output_10_loss: 0.3139 - binary_output_11_loss: 0.3244 - binary_output_12_loss: 0.1075 - binary_output_13_loss: 0.1903 - binary_output_14_loss: 0.1197 - binary_output_15_loss: 0.2468 - binary_output_16_loss: 0.2645 - binary_output_17_loss: 0.5430 - binary_output_18_loss: 0.3367 - binary_output_19_loss: 0.2833 - binary_output_20_loss: 0.3689 - binary_output_21_loss: 0.2035 - binary_output_22_loss: 0.0677 - binary_output_23_loss: 0.1337 - binary_output_24_loss: 0.0814 - binary_output_25_loss: 0.1802 - binary_output_26_loss: 0.2940 - binary_output_27_loss: 0.3419 - binary_output_28_loss: 0.2418 - binary_output_29_loss: 0.3255 - binary_output_30_loss: 0.1464 - binary_output_31_loss: 0.2531 - binary_output_32_loss: 0.2219 - binary_output_33_loss: 0.3420 - binary_output_34_loss: 0.5372 - categorical_output_loss: 0.3336 - binary_output_0_binary_accuracy: 0.7451 - binary_output_1_binary_accuracy: 0.9951 - binary_output_2_binary_accuracy: 0.7480 - binary_output_3_binary_accuracy: 0.7266 - binary_output_4_binary_accuracy: 0.8770 - binary_output_5_binary_accuracy: 0.8730 - binary_output_6_binary_accuracy: 0.9316 - binary_output_7_binary_accuracy: 0.9326 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8926 - binary_output_10_binary_accuracy: 0.8311 - binary_output_11_binary_accuracy: 0.8398 - binary_output_12_binary_accuracy: 0.9688 - binary_output_13_binary_accuracy: 0.9277 - binary_output_14_binary_accuracy: 0.9551 - binary_output_15_binary_accuracy: 0.8770 - binary_output_16_binary_accuracy: 0.8447 - binary_output_17_binary_accuracy: 0.5898 - binary_output_18_binary_accuracy: 0.8398 - binary_output_19_binary_accuracy: 0.8076 - binary_output_20_binary_accuracy: 0.8457 - binary_output_21_binary_accuracy: 0.9072 - binary_output_22_binary_accuracy: 0.9756 - binary_output_23_binary_accuracy: 0.9609 - binary_output_24_binary_accuracy: 0.9893 - binary_output_25_binary_accuracy: 0.9482 - binary_output_26_binary_accuracy: 0.8447 - binary_output_27_binary_accuracy: 0.7793 - binary_output_28_binary_accuracy: 0.8447 - binary_output_29_binary_accuracy: 0.8213 - binary_output_30_binary_accuracy: 0.9463 - binary_output_31_binary_accuracy: 0.8516 - binary_output_32_binary_accuracy: 0.8916 - binary_output_33_binary_accuracy: 0.7676 - binary_output_34_binary_accuracy: 0.6797 - categorical_output_sparse_categorical_accuracy: 0.7939"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22237/22237 [==============================] - 6s 250us/step - loss: 9.0198 - binary_output_0_loss: 0.4281 - binary_output_1_loss: 0.0747 - binary_output_2_loss: 0.4620 - binary_output_3_loss: 0.4103 - binary_output_4_loss: 0.2576 - binary_output_5_loss: 0.2385 - binary_output_6_loss: 0.1954 - binary_output_7_loss: 0.1519 - binary_output_8_loss: 4.9309e-04 - binary_output_9_loss: 0.2241 - binary_output_10_loss: 0.3040 - binary_output_11_loss: 0.2978 - binary_output_12_loss: 0.1058 - binary_output_13_loss: 0.1856 - binary_output_14_loss: 0.1413 - binary_output_15_loss: 0.2349 - binary_output_16_loss: 0.2794 - binary_output_17_loss: 0.6025 - binary_output_18_loss: 0.2981 - binary_output_19_loss: 0.2975 - binary_output_20_loss: 0.2587 - binary_output_21_loss: 0.1774 - binary_output_22_loss: 0.0881 - binary_output_23_loss: 0.1088 - binary_output_24_loss: 0.0686 - binary_output_25_loss: 0.1217 - binary_output_26_loss: 0.2596 - binary_output_27_loss: 0.3605 - binary_output_28_loss: 0.2909 - binary_output_29_loss: 0.2996 - binary_output_30_loss: 0.1214 - binary_output_31_loss: 0.2692 - binary_output_32_loss: 0.1745 - binary_output_33_loss: 0.3348 - binary_output_34_loss: 0.5263 - categorical_output_loss: 0.3581 - binary_output_0_binary_accuracy: 0.7472 - binary_output_1_binary_accuracy: 0.9891 - binary_output_2_binary_accuracy: 0.7605 - binary_output_3_binary_accuracy: 0.7432 - binary_output_4_binary_accuracy: 0.8653 - binary_output_5_binary_accuracy: 0.8801 - binary_output_6_binary_accuracy: 0.9223 - binary_output_7_binary_accuracy: 0.9323 - binary_output_8_binary_accuracy: 0.9999 - binary_output_9_binary_accuracy: 0.8902 - binary_output_10_binary_accuracy: 0.8322 - binary_output_11_binary_accuracy: 0.8403 - binary_output_12_binary_accuracy: 0.9665 - binary_output_13_binary_accuracy: 0.9262 - binary_output_14_binary_accuracy: 0.9565 - binary_output_15_binary_accuracy: 0.8707 - binary_output_16_binary_accuracy: 0.8543 - binary_output_17_binary_accuracy: 0.5963 - binary_output_18_binary_accuracy: 0.8310 - binary_output_19_binary_accuracy: 0.8258 - binary_output_20_binary_accuracy: 0.8515 - binary_output_21_binary_accuracy: 0.9214 - binary_output_22_binary_accuracy: 0.9761 - binary_output_23_binary_accuracy: 0.9593 - binary_output_24_binary_accuracy: 0.9873 - binary_output_25_binary_accuracy: 0.9515 - binary_output_26_binary_accuracy: 0.8489 - binary_output_27_binary_accuracy: 0.8080 - binary_output_28_binary_accuracy: 0.8393 - binary_output_29_binary_accuracy: 0.8424 - binary_output_30_binary_accuracy: 0.9600 - binary_output_31_binary_accuracy: 0.8576 - binary_output_32_binary_accuracy: 0.9155 - binary_output_33_binary_accuracy: 0.7886 - binary_output_34_binary_accuracy: 0.6781 - categorical_output_sparse_categorical_accuracy: 0.7962\n",
      "Epoch 34/40\n",
      "22237/22237 [==============================] - 6s 251us/step - loss: 8.9119 - binary_output_0_loss: 0.4261 - binary_output_1_loss: 0.0750 - binary_output_2_loss: 0.4526 - binary_output_3_loss: 0.4089 - binary_output_4_loss: 0.2546 - binary_output_5_loss: 0.2396 - binary_output_6_loss: 0.1932 - binary_output_7_loss: 0.1563 - binary_output_8_loss: 4.6528e-04 - binary_output_9_loss: 0.2152 - binary_output_10_loss: 0.3000 - binary_output_11_loss: 0.2919 - binary_output_12_loss: 0.0995 - binary_output_13_loss: 0.1784 - binary_output_14_loss: 0.1367 - binary_output_15_loss: 0.2382 - binary_output_16_loss: 0.2806 - binary_output_17_loss: 0.5963 - binary_output_18_loss: 0.2926 - binary_output_19_loss: 0.2992 - binary_output_20_loss: 0.2596 - binary_output_21_loss: 0.1715 - binary_output_22_loss: 0.0849 - binary_output_23_loss: 0.1107 - binary_output_24_loss: 0.0684 - binary_output_25_loss: 0.1230 - binary_output_26_loss: 0.2515 - binary_output_27_loss: 0.3553 - binary_output_28_loss: 0.2927 - binary_output_29_loss: 0.2922 - binary_output_30_loss: 0.1208 - binary_output_31_loss: 0.2663 - binary_output_32_loss: 0.1720 - binary_output_33_loss: 0.3320 - binary_output_34_loss: 0.5197 - categorical_output_loss: 0.3540 - binary_output_0_binary_accuracy: 0.7534 - binary_output_1_binary_accuracy: 0.9876 - binary_output_2_binary_accuracy: 0.7628 - binary_output_3_binary_accuracy: 0.7473 - binary_output_4_binary_accuracy: 0.8680 - binary_output_5_binary_accuracy: 0.8804 - binary_output_6_binary_accuracy: 0.9254 - binary_output_7_binary_accuracy: 0.9307 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8937 - binary_output_10_binary_accuracy: 0.8350 - binary_output_11_binary_accuracy: 0.8432 - binary_output_12_binary_accuracy: 0.9651 - binary_output_13_binary_accuracy: 0.9256 - binary_output_14_binary_accuracy: 0.9546 - binary_output_15_binary_accuracy: 0.8749 - binary_output_16_binary_accuracy: 0.8516 - binary_output_17_binary_accuracy: 0.5945 - binary_output_18_binary_accuracy: 0.8325 - binary_output_19_binary_accuracy: 0.8278 - binary_output_20_binary_accuracy: 0.8573 - binary_output_21_binary_accuracy: 0.9218 - binary_output_22_binary_accuracy: 0.9767 - binary_output_23_binary_accuracy: 0.9590 - binary_output_24_binary_accuracy: 0.9864 - binary_output_25_binary_accuracy: 0.9525 - binary_output_26_binary_accuracy: 0.8489 - binary_output_27_binary_accuracy: 0.8109 - binary_output_28_binary_accuracy: 0.8404 - binary_output_29_binary_accuracy: 0.8485 - binary_output_30_binary_accuracy: 0.9595 - binary_output_31_binary_accuracy: 0.8592 - binary_output_32_binary_accuracy: 0.9135 - binary_output_33_binary_accuracy: 0.7912 - binary_output_34_binary_accuracy: 0.6847 - categorical_output_sparse_categorical_accuracy: 0.7988\n",
      "Epoch 35/40\n",
      " 1024/22237 [>.............................] - ETA: 5s - loss: 9.5924 - binary_output_0_loss: 0.4589 - binary_output_1_loss: 0.0700 - binary_output_2_loss: 0.4398 - binary_output_3_loss: 0.4315 - binary_output_4_loss: 0.2675 - binary_output_5_loss: 0.3127 - binary_output_6_loss: 0.2234 - binary_output_7_loss: 0.2261 - binary_output_8_loss: 9.7411e-04 - binary_output_9_loss: 0.2346 - binary_output_10_loss: 0.3099 - binary_output_11_loss: 0.3585 - binary_output_12_loss: 0.1212 - binary_output_13_loss: 0.2148 - binary_output_14_loss: 0.1408 - binary_output_15_loss: 0.2332 - binary_output_16_loss: 0.2857 - binary_output_17_loss: 0.6476 - binary_output_18_loss: 0.2838 - binary_output_19_loss: 0.3219 - binary_output_20_loss: 0.2740 - binary_output_21_loss: 0.2449 - binary_output_22_loss: 0.1006 - binary_output_23_loss: 0.0735 - binary_output_24_loss: 0.0464 - binary_output_25_loss: 0.1342 - binary_output_26_loss: 0.2384 - binary_output_27_loss: 0.3433 - binary_output_28_loss: 0.3500 - binary_output_29_loss: 0.3161 - binary_output_30_loss: 0.1699 - binary_output_31_loss: 0.2350 - binary_output_32_loss: 0.1765 - binary_output_33_loss: 0.3337 - binary_output_34_loss: 0.6024 - categorical_output_loss: 0.3708 - binary_output_0_binary_accuracy: 0.7217 - binary_output_1_binary_accuracy: 0.9883 - binary_output_2_binary_accuracy: 0.7461 - binary_output_3_binary_accuracy: 0.7393 - binary_output_4_binary_accuracy: 0.8682 - binary_output_5_binary_accuracy: 0.8828 - binary_output_6_binary_accuracy: 0.9062 - binary_output_7_binary_accuracy: 0.9004 - binary_output_8_binary_accuracy: 0.9990 - binary_output_9_binary_accuracy: 0.8857 - binary_output_10_binary_accuracy: 0.8496 - binary_output_11_binary_accuracy: 0.8281 - binary_output_12_binary_accuracy: 0.9609 - binary_output_13_binary_accuracy: 0.9248 - binary_output_14_binary_accuracy: 0.9482 - binary_output_15_binary_accuracy: 0.8555 - binary_output_16_binary_accuracy: 0.8398 - binary_output_17_binary_accuracy: 0.5869 - binary_output_18_binary_accuracy: 0.8086 - binary_output_19_binary_accuracy: 0.8203 - binary_output_20_binary_accuracy: 0.8330 - binary_output_21_binary_accuracy: 0.9160 - binary_output_22_binary_accuracy: 0.9727 - binary_output_23_binary_accuracy: 0.9600 - binary_output_24_binary_accuracy: 0.9854 - binary_output_25_binary_accuracy: 0.9336 - binary_output_26_binary_accuracy: 0.8271 - binary_output_27_binary_accuracy: 0.8096 - binary_output_28_binary_accuracy: 0.8213 - binary_output_29_binary_accuracy: 0.8486 - binary_output_30_binary_accuracy: 0.9629 - binary_output_31_binary_accuracy: 0.8750 - binary_output_32_binary_accuracy: 0.9102 - binary_output_33_binary_accuracy: 0.8057 - binary_output_34_binary_accuracy: 0.6572 - categorical_output_sparse_categorical_accuracy: 0.798822237/22237 [==============================] - 6s 278us/step - loss: 8.7986 - binary_output_0_loss: 0.4191 - binary_output_1_loss: 0.0711 - binary_output_2_loss: 0.4463 - binary_output_3_loss: 0.4035 - binary_output_4_loss: 0.2499 - binary_output_5_loss: 0.2346 - binary_output_6_loss: 0.1904 - binary_output_7_loss: 0.1508 - binary_output_8_loss: 4.8015e-04 - binary_output_9_loss: 0.2157 - binary_output_10_loss: 0.2988 - binary_output_11_loss: 0.2896 - binary_output_12_loss: 0.1040 - binary_output_13_loss: 0.1793 - binary_output_14_loss: 0.1341 - binary_output_15_loss: 0.2343 - binary_output_16_loss: 0.2714 - binary_output_17_loss: 0.5916 - binary_output_18_loss: 0.2920 - binary_output_19_loss: 0.2927 - binary_output_20_loss: 0.2642 - binary_output_21_loss: 0.1688 - binary_output_22_loss: 0.0844 - binary_output_23_loss: 0.1097 - binary_output_24_loss: 0.0700 - binary_output_25_loss: 0.1231 - binary_output_26_loss: 0.2516 - binary_output_27_loss: 0.3422 - binary_output_28_loss: 0.2885 - binary_output_29_loss: 0.2903 - binary_output_30_loss: 0.1170 - binary_output_31_loss: 0.2635 - binary_output_32_loss: 0.1678 - binary_output_33_loss: 0.3272 - binary_output_34_loss: 0.5120 - categorical_output_loss: 0.3479 - binary_output_0_binary_accuracy: 0.7530 - binary_output_1_binary_accuracy: 0.9885 - binary_output_2_binary_accuracy: 0.7653 - binary_output_3_binary_accuracy: 0.7539 - binary_output_4_binary_accuracy: 0.8699 - binary_output_5_binary_accuracy: 0.8807 - binary_output_6_binary_accuracy: 0.9206 - binary_output_7_binary_accuracy: 0.9319 - binary_output_8_binary_accuracy: 0.9999 - binary_output_9_binary_accuracy: 0.8923 - binary_output_10_binary_accuracy: 0.8420 - binary_output_11_binary_accuracy: 0.8436 - binary_output_12_binary_accuracy: 0.9663 - binary_output_13_binary_accuracy: 0.9271 - binary_output_14_binary_accuracy: 0.9568 - binary_output_15_binary_accuracy: 0.8712 - binary_output_16_binary_accuracy: 0.8599 - binary_output_17_binary_accuracy: 0.5977 - binary_output_18_binary_accuracy: 0.8335 - binary_output_19_binary_accuracy: 0.8301 - binary_output_20_binary_accuracy: 0.8545 - binary_output_21_binary_accuracy: 0.9262 - binary_output_22_binary_accuracy: 0.9766 - binary_output_23_binary_accuracy: 0.9600 - binary_output_24_binary_accuracy: 0.9859 - binary_output_25_binary_accuracy: 0.9508 - binary_output_26_binary_accuracy: 0.8466 - binary_output_27_binary_accuracy: 0.8163 - binary_output_28_binary_accuracy: 0.8387 - binary_output_29_binary_accuracy: 0.8476 - binary_output_30_binary_accuracy: 0.9595 - binary_output_31_binary_accuracy: 0.8620 - binary_output_32_binary_accuracy: 0.9171 - binary_output_33_binary_accuracy: 0.7911 - binary_output_34_binary_accuracy: 0.6876 - categorical_output_sparse_categorical_accuracy: 0.7975\n",
      "Epoch 36/40\n",
      "22237/22237 [==============================] - 6s 280us/step - loss: 8.7596 - binary_output_0_loss: 0.4156 - binary_output_1_loss: 0.0701 - binary_output_2_loss: 0.4374 - binary_output_3_loss: 0.4094 - binary_output_4_loss: 0.2549 - binary_output_5_loss: 0.2338 - binary_output_6_loss: 0.1878 - binary_output_7_loss: 0.1515 - binary_output_8_loss: 4.2957e-04 - binary_output_9_loss: 0.2065 - binary_output_10_loss: 0.2893 - binary_output_11_loss: 0.2844 - binary_output_12_loss: 0.1033 - binary_output_13_loss: 0.1744 - binary_output_14_loss: 0.1359 - binary_output_15_loss: 0.2406 - binary_output_16_loss: 0.2723 - binary_output_17_loss: 0.5935 - binary_output_18_loss: 0.2851 - binary_output_19_loss: 0.2999 - binary_output_20_loss: 0.2580 - binary_output_21_loss: 0.1725 - binary_output_22_loss: 0.0872 - binary_output_23_loss: 0.1055 - binary_output_24_loss: 0.0688 - binary_output_25_loss: 0.1171 - binary_output_26_loss: 0.2486 - binary_output_27_loss: 0.3519 - binary_output_28_loss: 0.2958 - binary_output_29_loss: 0.2887 - binary_output_30_loss: 0.1236 - binary_output_31_loss: 0.2559 - binary_output_32_loss: 0.1711 - binary_output_33_loss: 0.3298 - binary_output_34_loss: 0.5043 - categorical_output_loss: 0.3446 - binary_output_0_binary_accuracy: 0.7579 - binary_output_1_binary_accuracy: 0.9880 - binary_output_2_binary_accuracy: 0.7686 - binary_output_3_binary_accuracy: 0.7555 - binary_output_4_binary_accuracy: 0.8713 - binary_output_5_binary_accuracy: 0.8811 - binary_output_6_binary_accuracy: 0.9240 - binary_output_7_binary_accuracy: 0.9307 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8981 - binary_output_10_binary_accuracy: 0.8451 - binary_output_11_binary_accuracy: 0.8452 - binary_output_12_binary_accuracy: 0.9655 - binary_output_13_binary_accuracy: 0.9328 - binary_output_14_binary_accuracy: 0.9532 - binary_output_15_binary_accuracy: 0.8737 - binary_output_16_binary_accuracy: 0.8583 - binary_output_17_binary_accuracy: 0.6040 - binary_output_18_binary_accuracy: 0.8371 - binary_output_19_binary_accuracy: 0.8288 - binary_output_20_binary_accuracy: 0.8539 - binary_output_21_binary_accuracy: 0.9255 - binary_output_22_binary_accuracy: 0.9756 - binary_output_23_binary_accuracy: 0.9597 - binary_output_24_binary_accuracy: 0.9852 - binary_output_25_binary_accuracy: 0.9526 - binary_output_26_binary_accuracy: 0.8507 - binary_output_27_binary_accuracy: 0.8157 - binary_output_28_binary_accuracy: 0.8377 - binary_output_29_binary_accuracy: 0.8483 - binary_output_30_binary_accuracy: 0.9586 - binary_output_31_binary_accuracy: 0.8645 - binary_output_32_binary_accuracy: 0.9168 - binary_output_33_binary_accuracy: 0.7874 - binary_output_34_binary_accuracy: 0.6948 - categorical_output_sparse_categorical_accuracy: 0.7983\n",
      "Epoch 37/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  512/22237 [..............................] - ETA: 4s - loss: 9.7857 - binary_output_0_loss: 0.4398 - binary_output_1_loss: 0.1747 - binary_output_2_loss: 0.4917 - binary_output_3_loss: 0.4412 - binary_output_4_loss: 0.2907 - binary_output_5_loss: 0.2152 - binary_output_6_loss: 0.2259 - binary_output_7_loss: 0.2318 - binary_output_8_loss: 3.0762e-04 - binary_output_9_loss: 0.2288 - binary_output_10_loss: 0.2934 - binary_output_11_loss: 0.3378 - binary_output_12_loss: 0.0554 - binary_output_13_loss: 0.1552 - binary_output_14_loss: 0.1835 - binary_output_15_loss: 0.2267 - binary_output_16_loss: 0.3271 - binary_output_17_loss: 0.6656 - binary_output_18_loss: 0.3549 - binary_output_19_loss: 0.3533 - binary_output_20_loss: 0.3006 - binary_output_21_loss: 0.1390 - binary_output_22_loss: 0.1024 - binary_output_23_loss: 0.0977 - binary_output_24_loss: 0.1181 - binary_output_25_loss: 0.2129 - binary_output_26_loss: 0.2493 - binary_output_27_loss: 0.4579 - binary_output_28_loss: 0.3292 - binary_output_29_loss: 0.2588 - binary_output_30_loss: 0.1144 - binary_output_31_loss: 0.3585 - binary_output_32_loss: 0.2174 - binary_output_33_loss: 0.3463 - binary_output_34_loss: 0.4786 - categorical_output_loss: 0.3117 - binary_output_0_binary_accuracy: 0.7695 - binary_output_1_binary_accuracy: 0.9883 - binary_output_2_binary_accuracy: 0.7598 - binary_output_3_binary_accuracy: 0.7520 - binary_output_4_binary_accuracy: 0.8770 - binary_output_5_binary_accuracy: 0.8750 - binary_output_6_binary_accuracy: 0.9102 - binary_output_7_binary_accuracy: 0.9258 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.9004 - binary_output_10_binary_accuracy: 0.8516 - binary_output_11_binary_accuracy: 0.8477 - binary_output_12_binary_accuracy: 0.9668 - binary_output_13_binary_accuracy: 0.9551 - binary_output_14_binary_accuracy: 0.9414 - binary_output_15_binary_accuracy: 0.8613 - binary_output_16_binary_accuracy: 0.8164 - binary_output_17_binary_accuracy: 0.6055 - binary_output_18_binary_accuracy: 0.8086 - binary_output_19_binary_accuracy: 0.8008 - binary_output_20_binary_accuracy: 0.8457 - binary_output_21_binary_accuracy: 0.9141 - binary_output_22_binary_accuracy: 0.9805 - binary_output_23_binary_accuracy: 0.9629 - binary_output_24_binary_accuracy: 0.9824 - binary_output_25_binary_accuracy: 0.9531 - binary_output_26_binary_accuracy: 0.8242 - binary_output_27_binary_accuracy: 0.8027 - binary_output_28_binary_accuracy: 0.8223 - binary_output_29_binary_accuracy: 0.8496 - binary_output_30_binary_accuracy: 0.9512 - binary_output_31_binary_accuracy: 0.8633 - binary_output_32_binary_accuracy: 0.8945 - binary_output_33_binary_accuracy: 0.7871 - binary_output_34_binary_accuracy: 0.6719 - categorical_output_sparse_categorical_accuracy: 0.7969\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 1024/22237 [>.............................] - ETA: 5s - loss: 9.1361 - binary_output_0_loss: 0.4424 - binary_output_1_loss: 0.1094 - binary_output_2_loss: 0.4604 - binary_output_3_loss: 0.4007 - binary_output_4_loss: 0.2540 - binary_output_5_loss: 0.2195 - binary_output_6_loss: 0.2045 - binary_output_7_loss: 0.1710 - binary_output_8_loss: 3.7515e-04 - binary_output_9_loss: 0.2066 - binary_output_10_loss: 0.2930 - binary_output_11_loss: 0.3368 - binary_output_12_loss: 0.0887 - binary_output_13_loss: 0.1431 - binary_output_14_loss: 0.1832 - binary_output_15_loss: 0.2435 - binary_output_16_loss: 0.3187 - binary_output_17_loss: 0.5998 - binary_output_18_loss: 0.3198 - binary_output_19_loss: 0.3065 - binary_output_20_loss: 0.2743 - binary_output_21_loss: 0.1331 - binary_output_22_loss: 0.1062 - binary_output_23_loss: 0.0778 - binary_output_24_loss: 0.1100 - binary_output_25_loss: 0.1372 - binary_output_26_loss: 0.2557 - binary_output_27_loss: 0.4058 - binary_output_28_loss: 0.2872 - binary_output_29_loss: 0.2671 - binary_output_30_loss: 0.1268 - binary_output_31_loss: 0.3263 - binary_output_32_loss: 0.1750 - binary_output_33_loss: 0.3143 - binary_output_34_loss: 0.4978 - categorical_output_loss: 0.3396 - binary_output_0_binary_accuracy: 0.7520 - binary_output_1_binary_accuracy: 0.9854 - binary_output_2_binary_accuracy: 0.7578 - binary_output_3_binary_accuracy: 0.7422 - binary_output_4_binary_accuracy: 0.8730 - binary_output_5_binary_accuracy: 0.8730 - binary_output_6_binary_accuracy: 0.9189 - binary_output_7_binary_accuracy: 0.9277 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8916 - binary_output_10_binary_accuracy: 0.8496 - binary_output_11_binary_accuracy: 0.8379 - binary_output_12_binary_accuracy: 0.9590 - binary_output_13_binary_accuracy: 0.9326 - binary_output_14_binary_accuracy: 0.9473 - binary_output_15_binary_accuracy: 0.8613 - binary_output_16_binary_accuracy: 0.8389 - binary_output_17_binary_accuracy: 0.5967 - binary_output_18_binary_accuracy: 0.8223 - binary_output_19_binary_accuracy: 0.8174 - binary_output_20_binary_accuracy: 0.8525 - binary_output_21_binary_accuracy: 0.9307 - binary_output_22_binary_accuracy: 0.9814 - binary_output_23_binary_accuracy: 0.9658 - binary_output_24_binary_accuracy: 0.9844 - binary_output_25_binary_accuracy: 0.9512 - binary_output_26_binary_accuracy: 0.8389 - binary_output_27_binary_accuracy: 0.7783 - binary_output_28_binary_accuracy: 0.8369 - binary_output_29_binary_accuracy: 0.8467 - binary_output_30_binary_accuracy: 0.9570 - binary_output_31_binary_accuracy: 0.8252 - binary_output_32_binary_accuracy: 0.9023 - binary_output_33_binary_accuracy: 0.7832 - binary_output_34_binary_accuracy: 0.6621 - categorical_output_sparse_categorical_accuracy: 0.8027"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22237/22237 [==============================] - 6s 252us/step - loss: 8.6451 - binary_output_0_loss: 0.4084 - binary_output_1_loss: 0.0710 - binary_output_2_loss: 0.4401 - binary_output_3_loss: 0.3962 - binary_output_4_loss: 0.2443 - binary_output_5_loss: 0.2321 - binary_output_6_loss: 0.1888 - binary_output_7_loss: 0.1431 - binary_output_8_loss: 4.4738e-04 - binary_output_9_loss: 0.2063 - binary_output_10_loss: 0.2907 - binary_output_11_loss: 0.2802 - binary_output_12_loss: 0.1025 - binary_output_13_loss: 0.1689 - binary_output_14_loss: 0.1331 - binary_output_15_loss: 0.2305 - binary_output_16_loss: 0.2679 - binary_output_17_loss: 0.5910 - binary_output_18_loss: 0.2859 - binary_output_19_loss: 0.2949 - binary_output_20_loss: 0.2509 - binary_output_21_loss: 0.1721 - binary_output_22_loss: 0.0840 - binary_output_23_loss: 0.1024 - binary_output_24_loss: 0.0669 - binary_output_25_loss: 0.1177 - binary_output_26_loss: 0.2496 - binary_output_27_loss: 0.3426 - binary_output_28_loss: 0.2808 - binary_output_29_loss: 0.2868 - binary_output_30_loss: 0.1160 - binary_output_31_loss: 0.2565 - binary_output_32_loss: 0.1672 - binary_output_33_loss: 0.3227 - binary_output_34_loss: 0.5067 - categorical_output_loss: 0.3427 - binary_output_0_binary_accuracy: 0.7587 - binary_output_1_binary_accuracy: 0.9875 - binary_output_2_binary_accuracy: 0.7703 - binary_output_3_binary_accuracy: 0.7591 - binary_output_4_binary_accuracy: 0.8739 - binary_output_5_binary_accuracy: 0.8848 - binary_output_6_binary_accuracy: 0.9233 - binary_output_7_binary_accuracy: 0.9329 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.9001 - binary_output_10_binary_accuracy: 0.8441 - binary_output_11_binary_accuracy: 0.8477 - binary_output_12_binary_accuracy: 0.9646 - binary_output_13_binary_accuracy: 0.9313 - binary_output_14_binary_accuracy: 0.9546 - binary_output_15_binary_accuracy: 0.8746 - binary_output_16_binary_accuracy: 0.8600 - binary_output_17_binary_accuracy: 0.6009 - binary_output_18_binary_accuracy: 0.8391 - binary_output_19_binary_accuracy: 0.8304 - binary_output_20_binary_accuracy: 0.8610 - binary_output_21_binary_accuracy: 0.9278 - binary_output_22_binary_accuracy: 0.9758 - binary_output_23_binary_accuracy: 0.9591 - binary_output_24_binary_accuracy: 0.9844 - binary_output_25_binary_accuracy: 0.9535 - binary_output_26_binary_accuracy: 0.8512 - binary_output_27_binary_accuracy: 0.8160 - binary_output_28_binary_accuracy: 0.8431 - binary_output_29_binary_accuracy: 0.8498 - binary_output_30_binary_accuracy: 0.9602 - binary_output_31_binary_accuracy: 0.8644 - binary_output_32_binary_accuracy: 0.9161 - binary_output_33_binary_accuracy: 0.7945 - binary_output_34_binary_accuracy: 0.6908 - categorical_output_sparse_categorical_accuracy: 0.7988\n",
      "Epoch 38/40\n",
      "22237/22237 [==============================] - 5s 246us/step - loss: 8.5238 - binary_output_0_loss: 0.4085 - binary_output_1_loss: 0.0707 - binary_output_2_loss: 0.4265 - binary_output_3_loss: 0.3893 - binary_output_4_loss: 0.2426 - binary_output_5_loss: 0.2256 - binary_output_6_loss: 0.1855 - binary_output_7_loss: 0.1418 - binary_output_8_loss: 4.6124e-04 - binary_output_9_loss: 0.1993 - binary_output_10_loss: 0.2806 - binary_output_11_loss: 0.2822 - binary_output_12_loss: 0.1024 - binary_output_13_loss: 0.1725 - binary_output_14_loss: 0.1277 - binary_output_15_loss: 0.2324 - binary_output_16_loss: 0.2634 - binary_output_17_loss: 0.5816 - binary_output_18_loss: 0.2838 - binary_output_19_loss: 0.2900 - binary_output_20_loss: 0.2456 - binary_output_21_loss: 0.1615 - binary_output_22_loss: 0.0816 - binary_output_23_loss: 0.1060 - binary_output_24_loss: 0.0677 - binary_output_25_loss: 0.1220 - binary_output_26_loss: 0.2422 - binary_output_27_loss: 0.3366 - binary_output_28_loss: 0.2759 - binary_output_29_loss: 0.2863 - binary_output_30_loss: 0.1136 - binary_output_31_loss: 0.2478 - binary_output_32_loss: 0.1656 - binary_output_33_loss: 0.3193 - binary_output_34_loss: 0.5011 - categorical_output_loss: 0.3423 - binary_output_0_binary_accuracy: 0.7624 - binary_output_1_binary_accuracy: 0.9871 - binary_output_2_binary_accuracy: 0.7790 - binary_output_3_binary_accuracy: 0.7618 - binary_output_4_binary_accuracy: 0.8730 - binary_output_5_binary_accuracy: 0.8827 - binary_output_6_binary_accuracy: 0.9242 - binary_output_7_binary_accuracy: 0.9348 - binary_output_8_binary_accuracy: 0.9999 - binary_output_9_binary_accuracy: 0.9034 - binary_output_10_binary_accuracy: 0.8507 - binary_output_11_binary_accuracy: 0.8508 - binary_output_12_binary_accuracy: 0.9637 - binary_output_13_binary_accuracy: 0.9298 - binary_output_14_binary_accuracy: 0.9569 - binary_output_15_binary_accuracy: 0.8758 - binary_output_16_binary_accuracy: 0.8647 - binary_output_17_binary_accuracy: 0.6090 - binary_output_18_binary_accuracy: 0.8406 - binary_output_19_binary_accuracy: 0.8339 - binary_output_20_binary_accuracy: 0.8618 - binary_output_21_binary_accuracy: 0.9303 - binary_output_22_binary_accuracy: 0.9764 - binary_output_23_binary_accuracy: 0.9583 - binary_output_24_binary_accuracy: 0.9841 - binary_output_25_binary_accuracy: 0.9516 - binary_output_26_binary_accuracy: 0.8526 - binary_output_27_binary_accuracy: 0.8221 - binary_output_28_binary_accuracy: 0.8488 - binary_output_29_binary_accuracy: 0.8490 - binary_output_30_binary_accuracy: 0.9618 - binary_output_31_binary_accuracy: 0.8717 - binary_output_32_binary_accuracy: 0.9223 - binary_output_33_binary_accuracy: 0.7983 - binary_output_34_binary_accuracy: 0.6947 - categorical_output_sparse_categorical_accuracy: 0.8001\n",
      "Epoch 39/40\n",
      " 1024/22237 [>.............................] - ETA: 5s - loss: 8.5147 - binary_output_0_loss: 0.3626 - binary_output_1_loss: 0.1067 - binary_output_2_loss: 0.3638 - binary_output_3_loss: 0.3563 - binary_output_4_loss: 0.2543 - binary_output_5_loss: 0.2286 - binary_output_6_loss: 0.2398 - binary_output_7_loss: 0.1596 - binary_output_8_loss: 4.3253e-04 - binary_output_9_loss: 0.2201 - binary_output_10_loss: 0.3133 - binary_output_11_loss: 0.3169 - binary_output_12_loss: 0.1079 - binary_output_13_loss: 0.1455 - binary_output_14_loss: 0.1352 - binary_output_15_loss: 0.2039 - binary_output_16_loss: 0.2588 - binary_output_17_loss: 0.5490 - binary_output_18_loss: 0.2875 - binary_output_19_loss: 0.2701 - binary_output_20_loss: 0.2313 - binary_output_21_loss: 0.1991 - binary_output_22_loss: 0.0842 - binary_output_23_loss: 0.0791 - binary_output_24_loss: 0.0688 - binary_output_25_loss: 0.1171 - binary_output_26_loss: 0.2622 - binary_output_27_loss: 0.3638 - binary_output_28_loss: 0.2101 - binary_output_29_loss: 0.2961 - binary_output_30_loss: 0.1249 - binary_output_31_loss: 0.2439 - binary_output_32_loss: 0.1805 - binary_output_33_loss: 0.3468 - binary_output_34_loss: 0.4748 - categorical_output_loss: 0.3519 - binary_output_0_binary_accuracy: 0.7881 - binary_output_1_binary_accuracy: 0.9863 - binary_output_2_binary_accuracy: 0.7920 - binary_output_3_binary_accuracy: 0.7549 - binary_output_4_binary_accuracy: 0.8477 - binary_output_5_binary_accuracy: 0.9062 - binary_output_6_binary_accuracy: 0.9229 - binary_output_7_binary_accuracy: 0.9365 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.8838 - binary_output_10_binary_accuracy: 0.8438 - binary_output_11_binary_accuracy: 0.8242 - binary_output_12_binary_accuracy: 0.9580 - binary_output_13_binary_accuracy: 0.9375 - binary_output_14_binary_accuracy: 0.9639 - binary_output_15_binary_accuracy: 0.8838 - binary_output_16_binary_accuracy: 0.8516 - binary_output_17_binary_accuracy: 0.6221 - binary_output_18_binary_accuracy: 0.8408 - binary_output_19_binary_accuracy: 0.8564 - binary_output_20_binary_accuracy: 0.8740 - binary_output_21_binary_accuracy: 0.9277 - binary_output_22_binary_accuracy: 0.9766 - binary_output_23_binary_accuracy: 0.9580 - binary_output_24_binary_accuracy: 0.9873 - binary_output_25_binary_accuracy: 0.9473 - binary_output_26_binary_accuracy: 0.8525 - binary_output_27_binary_accuracy: 0.8525 - binary_output_28_binary_accuracy: 0.8828 - binary_output_29_binary_accuracy: 0.8516 - binary_output_30_binary_accuracy: 0.9570 - binary_output_31_binary_accuracy: 0.8916 - binary_output_32_binary_accuracy: 0.9043 - binary_output_33_binary_accuracy: 0.7881 - binary_output_34_binary_accuracy: 0.7334 - categorical_output_sparse_categorical_accuracy: 0.792022237/22237 [==============================] - 5s 245us/step - loss: 8.4383 - binary_output_0_loss: 0.3991 - binary_output_1_loss: 0.0713 - binary_output_2_loss: 0.4270 - binary_output_3_loss: 0.3876 - binary_output_4_loss: 0.2427 - binary_output_5_loss: 0.2284 - binary_output_6_loss: 0.1885 - binary_output_7_loss: 0.1402 - binary_output_8_loss: 4.2608e-04 - binary_output_9_loss: 0.1975 - binary_output_10_loss: 0.2809 - binary_output_11_loss: 0.2787 - binary_output_12_loss: 0.1011 - binary_output_13_loss: 0.1662 - binary_output_14_loss: 0.1295 - binary_output_15_loss: 0.2240 - binary_output_16_loss: 0.2655 - binary_output_17_loss: 0.5751 - binary_output_18_loss: 0.2772 - binary_output_19_loss: 0.2852 - binary_output_20_loss: 0.2479 - binary_output_21_loss: 0.1613 - binary_output_22_loss: 0.0841 - binary_output_23_loss: 0.1034 - binary_output_24_loss: 0.0643 - binary_output_25_loss: 0.1149 - binary_output_26_loss: 0.2421 - binary_output_27_loss: 0.3271 - binary_output_28_loss: 0.2732 - binary_output_29_loss: 0.2827 - binary_output_30_loss: 0.1218 - binary_output_31_loss: 0.2454 - binary_output_32_loss: 0.1619 - binary_output_33_loss: 0.3156 - binary_output_34_loss: 0.4949 - categorical_output_loss: 0.3374 - binary_output_0_binary_accuracy: 0.7640 - binary_output_1_binary_accuracy: 0.9869 - binary_output_2_binary_accuracy: 0.7769 - binary_output_3_binary_accuracy: 0.7696 - binary_output_4_binary_accuracy: 0.8757 - binary_output_5_binary_accuracy: 0.8878 - binary_output_6_binary_accuracy: 0.9230 - binary_output_7_binary_accuracy: 0.9351 - binary_output_8_binary_accuracy: 1.0000 - binary_output_9_binary_accuracy: 0.9031 - binary_output_10_binary_accuracy: 0.8471 - binary_output_11_binary_accuracy: 0.8532 - binary_output_12_binary_accuracy: 0.9652 - binary_output_13_binary_accuracy: 0.9311 - binary_output_14_binary_accuracy: 0.9576 - binary_output_15_binary_accuracy: 0.8750 - binary_output_16_binary_accuracy: 0.8618 - binary_output_17_binary_accuracy: 0.6110 - binary_output_18_binary_accuracy: 0.8417 - binary_output_19_binary_accuracy: 0.8351 - binary_output_20_binary_accuracy: 0.8645 - binary_output_21_binary_accuracy: 0.9298 - binary_output_22_binary_accuracy: 0.9771 - binary_output_23_binary_accuracy: 0.9599 - binary_output_24_binary_accuracy: 0.9843 - binary_output_25_binary_accuracy: 0.9521 - binary_output_26_binary_accuracy: 0.8538 - binary_output_27_binary_accuracy: 0.8272 - binary_output_28_binary_accuracy: 0.8518 - binary_output_29_binary_accuracy: 0.8509 - binary_output_30_binary_accuracy: 0.9580 - binary_output_31_binary_accuracy: 0.8717 - binary_output_32_binary_accuracy: 0.9191 - binary_output_33_binary_accuracy: 0.7957 - binary_output_34_binary_accuracy: 0.7059 - categorical_output_sparse_categorical_accuracy: 0.8018\n",
      "Epoch 40/40\n",
      "22237/22237 [==============================] - 6s 281us/step - loss: 8.3634 - binary_output_0_loss: 0.4025 - binary_output_1_loss: 0.0683 - binary_output_2_loss: 0.4256 - binary_output_3_loss: 0.3832 - binary_output_4_loss: 0.2363 - binary_output_5_loss: 0.2319 - binary_output_6_loss: 0.1787 - binary_output_7_loss: 0.1414 - binary_output_8_loss: 4.7907e-04 - binary_output_9_loss: 0.1941 - binary_output_10_loss: 0.2833 - binary_output_11_loss: 0.2809 - binary_output_12_loss: 0.0992 - binary_output_13_loss: 0.1681 - binary_output_14_loss: 0.1282 - binary_output_15_loss: 0.2251 - binary_output_16_loss: 0.2553 - binary_output_17_loss: 0.5735 - binary_output_18_loss: 0.2747 - binary_output_19_loss: 0.2819 - binary_output_20_loss: 0.2458 - binary_output_21_loss: 0.1542 - binary_output_22_loss: 0.0828 - binary_output_23_loss: 0.1013 - binary_output_24_loss: 0.0640 - binary_output_25_loss: 0.1132 - binary_output_26_loss: 0.2436 - binary_output_27_loss: 0.3289 - binary_output_28_loss: 0.2741 - binary_output_29_loss: 0.2828 - binary_output_30_loss: 0.1110 - binary_output_31_loss: 0.2484 - binary_output_32_loss: 0.1573 - binary_output_33_loss: 0.3196 - binary_output_34_loss: 0.4858 - categorical_output_loss: 0.3307 - binary_output_0_binary_accuracy: 0.7620 - binary_output_1_binary_accuracy: 0.9862 - binary_output_2_binary_accuracy: 0.7766 - binary_output_3_binary_accuracy: 0.7726 - binary_output_4_binary_accuracy: 0.8785 - binary_output_5_binary_accuracy: 0.8844 - binary_output_6_binary_accuracy: 0.9236 - binary_output_7_binary_accuracy: 0.9356 - binary_output_8_binary_accuracy: 0.9999 - binary_output_9_binary_accuracy: 0.9052 - binary_output_10_binary_accuracy: 0.8483 - binary_output_11_binary_accuracy: 0.8516 - binary_output_12_binary_accuracy: 0.9654 - binary_output_13_binary_accuracy: 0.9291 - binary_output_14_binary_accuracy: 0.9546 - binary_output_15_binary_accuracy: 0.8776 - binary_output_16_binary_accuracy: 0.8657 - binary_output_17_binary_accuracy: 0.6124 - binary_output_18_binary_accuracy: 0.8448 - binary_output_19_binary_accuracy: 0.8340 - binary_output_20_binary_accuracy: 0.8659 - binary_output_21_binary_accuracy: 0.9365 - binary_output_22_binary_accuracy: 0.9766 - binary_output_23_binary_accuracy: 0.9619 - binary_output_24_binary_accuracy: 0.9843 - binary_output_25_binary_accuracy: 0.9553 - binary_output_26_binary_accuracy: 0.8564 - binary_output_27_binary_accuracy: 0.8261 - binary_output_28_binary_accuracy: 0.8501 - binary_output_29_binary_accuracy: 0.8538 - binary_output_30_binary_accuracy: 0.9591 - binary_output_31_binary_accuracy: 0.8732 - binary_output_32_binary_accuracy: 0.9231 - binary_output_33_binary_accuracy: 0.7997 - binary_output_34_binary_accuracy: 0.7054 - categorical_output_sparse_categorical_accuracy: 0.8043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x176bd7fd0>"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train_output,\n",
    "          epochs=40, batch_size=512,\n",
    "         class_weight=classes_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.5 # threshold between classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.67      0.78      3237\n",
      "           1       0.34      0.81      0.48       688\n",
      "\n",
      "    accuracy                           0.70      3925\n",
      "   macro avg       0.64      0.74      0.63      3925\n",
      "weighted avg       0.84      0.70      0.73      3925\n",
      "\n",
      "offer accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3903\n",
      "           1       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.99      3925\n",
      "   macro avg       0.50      0.50      0.50      3925\n",
      "weighted avg       0.99      0.99      0.99      3925\n",
      "\n",
      "aid_related accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.47      0.60      2310\n",
      "           1       0.53      0.86      0.66      1615\n",
      "\n",
      "    accuracy                           0.63      3925\n",
      "   macro avg       0.68      0.66      0.63      3925\n",
      "weighted avg       0.70      0.63      0.62      3925\n",
      "\n",
      "medical_help accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.73      0.83      3635\n",
      "           1       0.16      0.65      0.26       290\n",
      "\n",
      "    accuracy                           0.73      3925\n",
      "   macro avg       0.56      0.69      0.55      3925\n",
      "weighted avg       0.90      0.73      0.79      3925\n",
      "\n",
      "medical_products accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.86      0.92      3739\n",
      "           1       0.19      0.63      0.29       186\n",
      "\n",
      "    accuracy                           0.85      3925\n",
      "   macro avg       0.58      0.75      0.60      3925\n",
      "weighted avg       0.94      0.85      0.89      3925\n",
      "\n",
      "search_and_rescue accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.93      3824\n",
      "           1       0.08      0.37      0.13       101\n",
      "\n",
      "    accuracy                           0.88      3925\n",
      "   macro avg       0.53      0.63      0.53      3925\n",
      "weighted avg       0.96      0.88      0.91      3925\n",
      "\n",
      "security accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97      3869\n",
      "           1       0.03      0.11      0.05        56\n",
      "\n",
      "    accuracy                           0.94      3925\n",
      "   macro avg       0.51      0.53      0.51      3925\n",
      "weighted avg       0.97      0.94      0.95      3925\n",
      "\n",
      "military accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      3795\n",
      "           1       0.24      0.45      0.32       130\n",
      "\n",
      "    accuracy                           0.94      3925\n",
      "   macro avg       0.61      0.70      0.64      3925\n",
      "weighted avg       0.96      0.94      0.94      3925\n",
      "\n",
      "child_alone accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3925\n",
      "\n",
      "    accuracy                           1.00      3925\n",
      "   macro avg       1.00      1.00      1.00      3925\n",
      "weighted avg       1.00      1.00      1.00      3925\n",
      "\n",
      "water accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.93      3677\n",
      "           1       0.31      0.75      0.44       248\n",
      "\n",
      "    accuracy                           0.88      3925\n",
      "   macro avg       0.64      0.82      0.68      3925\n",
      "weighted avg       0.94      0.88      0.90      3925\n",
      "\n",
      "food accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.80      0.88      3505\n",
      "           1       0.33      0.84      0.48       420\n",
      "\n",
      "    accuracy                           0.80      3925\n",
      "   macro avg       0.65      0.82      0.68      3925\n",
      "weighted avg       0.91      0.80      0.83      3925\n",
      "\n",
      "shelter accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.83      0.90      3569\n",
      "           1       0.31      0.76      0.44       356\n",
      "\n",
      "    accuracy                           0.83      3925\n",
      "   macro avg       0.64      0.80      0.67      3925\n",
      "weighted avg       0.91      0.83      0.86      3925\n",
      "\n",
      "clothing accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      3863\n",
      "           1       0.25      0.60      0.35        62\n",
      "\n",
      "    accuracy                           0.96      3925\n",
      "   macro avg       0.62      0.78      0.66      3925\n",
      "weighted avg       0.98      0.96      0.97      3925\n",
      "\n",
      "money accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96      3833\n",
      "           1       0.18      0.54      0.27        92\n",
      "\n",
      "    accuracy                           0.93      3925\n",
      "   macro avg       0.58      0.74      0.62      3925\n",
      "weighted avg       0.97      0.93      0.95      3925\n",
      "\n",
      "missing_people accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      3892\n",
      "           1       0.08      0.33      0.13        33\n",
      "\n",
      "    accuracy                           0.96      3925\n",
      "   macro avg       0.54      0.65      0.56      3925\n",
      "weighted avg       0.99      0.96      0.97      3925\n",
      "\n",
      "refugees accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.88      0.93      3797\n",
      "           1       0.12      0.48      0.19       128\n",
      "\n",
      "    accuracy                           0.87      3925\n",
      "   macro avg       0.55      0.68      0.56      3925\n",
      "weighted avg       0.95      0.87      0.91      3925\n",
      "\n",
      "death accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.93      3752\n",
      "           1       0.19      0.58      0.29       173\n",
      "\n",
      "    accuracy                           0.88      3925\n",
      "   macro avg       0.59      0.73      0.61      3925\n",
      "weighted avg       0.94      0.88      0.90      3925\n",
      "\n",
      "other_aid accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.51      0.66      3390\n",
      "           1       0.19      0.73      0.30       535\n",
      "\n",
      "    accuracy                           0.54      3925\n",
      "   macro avg       0.56      0.62      0.48      3925\n",
      "weighted avg       0.82      0.54      0.61      3925\n",
      "\n",
      "infrastructure_related accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.80      0.87      3692\n",
      "           1       0.12      0.45      0.20       233\n",
      "\n",
      "    accuracy                           0.78      3925\n",
      "   macro avg       0.54      0.63      0.53      3925\n",
      "weighted avg       0.91      0.78      0.83      3925\n",
      "\n",
      "transport accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.83      0.89      3751\n",
      "           1       0.12      0.49      0.19       174\n",
      "\n",
      "    accuracy                           0.81      3925\n",
      "   macro avg       0.54      0.66      0.54      3925\n",
      "weighted avg       0.93      0.81      0.86      3925\n",
      "\n",
      "buildings accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.85      0.91      3735\n",
      "           1       0.18      0.66      0.29       190\n",
      "\n",
      "    accuracy                           0.84      3925\n",
      "   macro avg       0.58      0.75      0.60      3925\n",
      "weighted avg       0.94      0.84      0.88      3925\n",
      "\n",
      "electricity accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      3838\n",
      "           1       0.12      0.26      0.16        87\n",
      "\n",
      "    accuracy                           0.94      3925\n",
      "   macro avg       0.55      0.61      0.56      3925\n",
      "weighted avg       0.96      0.94      0.95      3925\n",
      "\n",
      "tools accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      3906\n",
      "           1       0.00      0.00      0.00        19\n",
      "\n",
      "    accuracy                           0.98      3925\n",
      "   macro avg       0.50      0.49      0.50      3925\n",
      "weighted avg       0.99      0.98      0.99      3925\n",
      "\n",
      "hospitals accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      3890\n",
      "           1       0.03      0.09      0.04        35\n",
      "\n",
      "    accuracy                           0.96      3925\n",
      "   macro avg       0.51      0.53      0.51      3925\n",
      "weighted avg       0.98      0.96      0.97      3925\n",
      "\n",
      "shops accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3908\n",
      "           1       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.99      3925\n",
      "   macro avg       0.50      0.50      0.50      3925\n",
      "weighted avg       0.99      0.99      0.99      3925\n",
      "\n",
      "aid_centers accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98      3885\n",
      "           1       0.02      0.07      0.03        40\n",
      "\n",
      "    accuracy                           0.95      3925\n",
      "   macro avg       0.51      0.52      0.50      3925\n",
      "weighted avg       0.98      0.95      0.97      3925\n",
      "\n",
      "other_infrastructure accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.83      0.90      3766\n",
      "           1       0.10      0.45      0.17       159\n",
      "\n",
      "    accuracy                           0.82      3925\n",
      "   macro avg       0.54      0.64      0.53      3925\n",
      "weighted avg       0.94      0.82      0.87      3925\n",
      "\n",
      "weather_related accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.65      0.76      2858\n",
      "           1       0.47      0.85      0.61      1067\n",
      "\n",
      "    accuracy                           0.70      3925\n",
      "   macro avg       0.70      0.75      0.68      3925\n",
      "weighted avg       0.80      0.70      0.72      3925\n",
      "\n",
      "floods accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.81      0.89      3604\n",
      "           1       0.26      0.73      0.38       321\n",
      "\n",
      "    accuracy                           0.81      3925\n",
      "   macro avg       0.62      0.77      0.63      3925\n",
      "weighted avg       0.91      0.81      0.84      3925\n",
      "\n",
      "storm accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.83      0.90      3572\n",
      "           1       0.32      0.80      0.46       353\n",
      "\n",
      "    accuracy                           0.83      3925\n",
      "   macro avg       0.65      0.82      0.68      3925\n",
      "weighted avg       0.92      0.83      0.86      3925\n",
      "\n",
      "fire accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      3881\n",
      "           1       0.14      0.25      0.18        44\n",
      "\n",
      "    accuracy                           0.97      3925\n",
      "   macro avg       0.56      0.62      0.58      3925\n",
      "weighted avg       0.98      0.97      0.98      3925\n",
      "\n",
      "earthquake accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.84      0.90      3572\n",
      "           1       0.32      0.80      0.46       353\n",
      "\n",
      "    accuracy                           0.83      3925\n",
      "   macro avg       0.65      0.82      0.68      3925\n",
      "weighted avg       0.92      0.83      0.86      3925\n",
      "\n",
      "cold accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97      3844\n",
      "           1       0.13      0.38      0.19        81\n",
      "\n",
      "    accuracy                           0.93      3925\n",
      "   macro avg       0.56      0.66      0.58      3925\n",
      "weighted avg       0.97      0.93      0.95      3925\n",
      "\n",
      "other_weather accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.77      0.86      3730\n",
      "           1       0.12      0.61      0.20       195\n",
      "\n",
      "    accuracy                           0.76      3925\n",
      "   macro avg       0.55      0.69      0.53      3925\n",
      "weighted avg       0.93      0.76      0.83      3925\n",
      "\n",
      "direct_report accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.58      0.71      3134\n",
      "           1       0.32      0.78      0.45       791\n",
      "\n",
      "    accuracy                           0.62      3925\n",
      "   macro avg       0.62      0.68      0.58      3925\n",
      "weighted avg       0.79      0.62      0.66      3925\n",
      "\n",
      "related accuracy \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.73      0.59       947\n",
      "           1       0.89      0.76      0.82      2949\n",
      "           2       0.06      0.03      0.04        29\n",
      "\n",
      "    accuracy                           0.75      3925\n",
      "   macro avg       0.48      0.51      0.48      3925\n",
      "weighted avg       0.79      0.75      0.76      3925\n",
      "\n",
      "Total : 21.325938038252296\n"
     ]
    }
   ],
   "source": [
    "f1_score_results = []\n",
    "# Binary Outputs\n",
    "for col_idx, col in enumerate(output_columns_binary):\n",
    "    print(f'{col} accuracy \\n')\n",
    "    \n",
    "    # Transform array of probabilities to class: 0 or 1\n",
    "    y_pred[col_idx][y_pred[col_idx]>=THRESHOLD] = 1\n",
    "    y_pred[col_idx][y_pred[col_idx]<THRESHOLD] = 0\n",
    "    f1_score_results.append(f1_score(y_test[col], y_pred[col_idx], average='macro'))\n",
    "    print(classification_report(y_test[col], y_pred[col_idx]))\n",
    "\n",
    "# Multi Class Output\n",
    "for col_idx, col in enumerate(output_columns_categorical):\n",
    "    print(f'{col} accuracy \\n')\n",
    "    \n",
    "    # Select class with higher probability from the softmax output: 0, 1 or 2\n",
    "    y_pred_2 = np.argmax(y_pred[-1], axis=-1)\n",
    "    f1_score_results.append(f1_score(y_test[col], y_pred_2, average='macro'))\n",
    "    print(classification_report(y_test[col], y_pred_2))\n",
    "print('Total :',np.sum(f1_score_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cor",
   "language": "python",
   "name": "cor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
